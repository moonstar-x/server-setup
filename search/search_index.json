{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 This is a simple guide that focuses on the installation and configuration process of my little home server that runs multiple services for various purposes. The server now uses Docker for most of its services. This is an improved version of the previous server guide , some of the services from the previous version are present here, some are gone for good.","title":"Home"},{"location":"#introduction","text":"This is a simple guide that focuses on the installation and configuration process of my little home server that runs multiple services for various purposes. The server now uses Docker for most of its services. This is an improved version of the previous server guide , some of the services from the previous version are present here, some are gone for good.","title":"Introduction"},{"location":"discord-bots/","text":"Initialization \u00b6 All the bots inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the bots, we'll create a folder on the main user's home folder dedicated to Discord bots. mkdir ~/discord For each bot created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"discord-bots/#initialization","text":"All the bots inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the bots, we'll create a folder on the main user's home folder dedicated to Discord bots. mkdir ~/discord For each bot created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"discord-bots/free-games-notifier/","text":"Free Games Notifier \u00b6 discord-free-games-notifier is a bot that notifies a channel whenever there's a free game on Steam or Epic Games. This bot has an image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-free-games-notifier Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-free-games-notifier:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - PREFIX=! - OWNER_ID=<OWNER_ID_HERE> - INVITE_URL=<INVITE_URL_HERE> - TZ=America/Guayaquil Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Free Games Notifier"},{"location":"discord-bots/free-games-notifier/#free-games-notifier","text":"discord-free-games-notifier is a bot that notifies a channel whenever there's a free game on Steam or Epic Games. This bot has an image available on Docker Hub which we'll use.","title":"Free Games Notifier"},{"location":"discord-bots/free-games-notifier/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-free-games-notifier","title":"Pre-Installation"},{"location":"discord-bots/free-games-notifier/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-free-games-notifier:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - PREFIX=! - OWNER_ID=<OWNER_ID_HERE> - INVITE_URL=<INVITE_URL_HERE> - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"discord-bots/free-games-notifier/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/jda-music-bot/","text":"JDA Music Bot \u00b6 jagrosh's MusicBot is a very powerful music bot written in Java with JDA. This bot does not have an official Docker image so we'll create a Dockerfile for this one. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/jda-music-bot We'll also need to download the latest version of the jar from here which will be downloaded inside an app folder where all the bot's data will be stored. cd ~/discord/jda-music-bot && mkdir app && cd app wget https://github.com/jagrosh/MusicBot/releases/download/0.3.4/JMusicBot-0.3.4.jar mv JMusicBot-0.3.4.jar JMusicBot.jar Now, we should have a JMusicBot.jar file inside of ~/discord/jda-music-bot/app . Configuration \u00b6 This bot requires its configuration to be saved in a text file. We'll create a file called config.txt with: nano ~/discord/jda-music-bot/app/config.txt And its content should be as follows: token=<DISCORD_TOKEN_HERE> owner=<OWNER_ID_HERE> prefix=% game=\"DEFAULT\" status=ONLINE songinstatus=true altprefix=\"NONE\" stayinchannel=true maxtime=0 updatealerts=false Dockerfile \u00b6 Since the bot does not have an official Docker image, we'll create a Dockerfile to run any java jar file through volumes. The content of the Dockerfile file is as follows: FROM openjdk:8 WORKDIR /opt/app VOLUME /opt/app CMD [ \"java\" , \"-Dnogui=true\" , \"-jar\" , \"JMusicBot.jar\" ] Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : build : . restart : unless-stopped network_mode : host volumes : - ./app:/opt/app environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"JDA Music Bot"},{"location":"discord-bots/jda-music-bot/#jda-music-bot","text":"jagrosh's MusicBot is a very powerful music bot written in Java with JDA. This bot does not have an official Docker image so we'll create a Dockerfile for this one.","title":"JDA Music Bot"},{"location":"discord-bots/jda-music-bot/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/jda-music-bot We'll also need to download the latest version of the jar from here which will be downloaded inside an app folder where all the bot's data will be stored. cd ~/discord/jda-music-bot && mkdir app && cd app wget https://github.com/jagrosh/MusicBot/releases/download/0.3.4/JMusicBot-0.3.4.jar mv JMusicBot-0.3.4.jar JMusicBot.jar Now, we should have a JMusicBot.jar file inside of ~/discord/jda-music-bot/app .","title":"Pre-Installation"},{"location":"discord-bots/jda-music-bot/#configuration","text":"This bot requires its configuration to be saved in a text file. We'll create a file called config.txt with: nano ~/discord/jda-music-bot/app/config.txt And its content should be as follows: token=<DISCORD_TOKEN_HERE> owner=<OWNER_ID_HERE> prefix=% game=\"DEFAULT\" status=ONLINE songinstatus=true altprefix=\"NONE\" stayinchannel=true maxtime=0 updatealerts=false","title":"Configuration"},{"location":"discord-bots/jda-music-bot/#dockerfile","text":"Since the bot does not have an official Docker image, we'll create a Dockerfile to run any java jar file through volumes. The content of the Dockerfile file is as follows: FROM openjdk:8 WORKDIR /opt/app VOLUME /opt/app CMD [ \"java\" , \"-Dnogui=true\" , \"-jar\" , \"JMusicBot.jar\" ]","title":"Dockerfile"},{"location":"discord-bots/jda-music-bot/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : build : . restart : unless-stopped network_mode : host volumes : - ./app:/opt/app environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build","title":"Docker Compose"},{"location":"discord-bots/jda-music-bot/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/music-24-7/","text":"Music 24/7 Bot \u00b6 discord-music-24-7 is a music bot with auto-pause capabilities that pauses the music playback when nobody is in the channel. It can play music from YouTube, SoundCloud and local files. This bot has an image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-music-24-7 Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-music-24-7:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - PREFIX=s! - CHANNEL_ID=<CHANNEL_ID_HERE> - OWNER_ID=<OWNER_ID_HERE> - TZ=America/Guayaquil Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Music 24/7 Bot"},{"location":"discord-bots/music-24-7/#music-247-bot","text":"discord-music-24-7 is a music bot with auto-pause capabilities that pauses the music playback when nobody is in the channel. It can play music from YouTube, SoundCloud and local files. This bot has an image available on Docker Hub which we'll use.","title":"Music 24/7 Bot"},{"location":"discord-bots/music-24-7/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-music-24-7","title":"Pre-Installation"},{"location":"discord-bots/music-24-7/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-music-24-7:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - PREFIX=s! - CHANNEL_ID=<CHANNEL_ID_HERE> - OWNER_ID=<OWNER_ID_HERE> - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"discord-bots/music-24-7/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/tts-bot/","text":"Text-to-Speech Bot \u00b6 discord-tts-bot is a bot that uses the Google Translate API to utter the messages you send to the bot in any language. This bot has an image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-tts-bot Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-tts-bot:latest restart : unless-stopped network_mode : host environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - PREFIX=$$ - TZ=America/Guayaquil Note The prefix in this case is $ , Docker Compose requires to escape any $ symbol with another $ . Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Text-to-Speech Bot"},{"location":"discord-bots/tts-bot/#text-to-speech-bot","text":"discord-tts-bot is a bot that uses the Google Translate API to utter the messages you send to the bot in any language. This bot has an image available on Docker Hub which we'll use.","title":"Text-to-Speech Bot"},{"location":"discord-bots/tts-bot/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-tts-bot","title":"Pre-Installation"},{"location":"discord-bots/tts-bot/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-tts-bot:latest restart : unless-stopped network_mode : host environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - PREFIX=$$ - TZ=America/Guayaquil Note The prefix in this case is $ , Docker Compose requires to escape any $ symbol with another $ .","title":"Docker Compose"},{"location":"discord-bots/tts-bot/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/cloudflared/","text":"Cloudflared (Native) \u00b6 Cloudflared is a daemon that allows to manage Cloudflare Argo Tunnel . We'll use this to expose our web services through Cloudflare without the need to port forward and expose our home network directly. Installation \u00b6 To install Cloudflared : wget -q https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.deb sudo dpkg -i cloudflared-stable-linux-amd64.deb Authenticating \u00b6 We now need to authenticate with Cloudflare, for this run: cloudflared tunnel login A link will be displayed on the console. Visit it on any browser, login and select the zone you wish to enable Argo Tunnel for. This will create a cert.pem file inside ~/.cloudflared . Creating a Tunnel \u00b6 We can create as many tunnels as we want. Generally one tunnel per DNS zone should suffice. To create a tunnel, run: cloudflared tunnel create <NAME> Note Replace <NAME> with the desired name for your tunnel. Once done, this will create a .json file inside ~/.cloudflared that contains the tunnel credentials. Pre-Configuration \u00b6 Since we'll create two different tunnels for two different domains, we'll create a folder in ~/.cloudflared with the name of the tunnel lower-cased, where we'll move cert.pem and UUID.json files. Configuration \u00b6 Inside ~/.cloudflared/<name> we'll create a config.yml file with the configuration of our tunnel. tunnel : TUNNEL_ID credentials-file : /home/USER/.cloudflared/NAME/TUNNEL_ID.json ingress : - hostname : subdomain.domain.com service : http://localhost:port - hostname : subdomain.domain.com service : http://localhost:port - service : http_status:404 Note You can add as many hostname/service pairs as you want. Running \u00b6 You can run the tunnel with: cloudflared tunnel --config ~/.cloudflared/name/config.yml --origincert ~/.cloudflared/name/cert.pem run Auto-starting \u00b6 To auto-start the tunnel, create a service file: sudo nano /etc/systemd/system/cloudflared_name.service And add the following: [Unit] Description=Cloudflared Tunnel for $NAME After=network.target [Service] Type=simple User=$USER WorkingDirectory=/home/$USER/.cloudflared/$NAME ExecStart=/usr/local/bin/cloudflared tunnel --config ./config.yml --origincert ./cert.pem run Restart=always [Install] WantedBy=multi-user.target Note Replace $USER and $NAME with the correct values for your tunnel. Once saved, start and enable the service. sudo systemctl start cloudflared_name.service sudo systemctl enable cloudflared_name.service Last Words \u00b6 Repeat the process from Authenticating for each tunnel created.","title":"Cloudflared (Native)"},{"location":"services/cloudflared/#cloudflared-native","text":"Cloudflared is a daemon that allows to manage Cloudflare Argo Tunnel . We'll use this to expose our web services through Cloudflare without the need to port forward and expose our home network directly.","title":"Cloudflared (Native)"},{"location":"services/cloudflared/#installation","text":"To install Cloudflared : wget -q https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.deb sudo dpkg -i cloudflared-stable-linux-amd64.deb","title":"Installation"},{"location":"services/cloudflared/#authenticating","text":"We now need to authenticate with Cloudflare, for this run: cloudflared tunnel login A link will be displayed on the console. Visit it on any browser, login and select the zone you wish to enable Argo Tunnel for. This will create a cert.pem file inside ~/.cloudflared .","title":"Authenticating"},{"location":"services/cloudflared/#creating-a-tunnel","text":"We can create as many tunnels as we want. Generally one tunnel per DNS zone should suffice. To create a tunnel, run: cloudflared tunnel create <NAME> Note Replace <NAME> with the desired name for your tunnel. Once done, this will create a .json file inside ~/.cloudflared that contains the tunnel credentials.","title":"Creating a Tunnel"},{"location":"services/cloudflared/#pre-configuration","text":"Since we'll create two different tunnels for two different domains, we'll create a folder in ~/.cloudflared with the name of the tunnel lower-cased, where we'll move cert.pem and UUID.json files.","title":"Pre-Configuration"},{"location":"services/cloudflared/#configuration","text":"Inside ~/.cloudflared/<name> we'll create a config.yml file with the configuration of our tunnel. tunnel : TUNNEL_ID credentials-file : /home/USER/.cloudflared/NAME/TUNNEL_ID.json ingress : - hostname : subdomain.domain.com service : http://localhost:port - hostname : subdomain.domain.com service : http://localhost:port - service : http_status:404 Note You can add as many hostname/service pairs as you want.","title":"Configuration"},{"location":"services/cloudflared/#running","text":"You can run the tunnel with: cloudflared tunnel --config ~/.cloudflared/name/config.yml --origincert ~/.cloudflared/name/cert.pem run","title":"Running"},{"location":"services/cloudflared/#auto-starting","text":"To auto-start the tunnel, create a service file: sudo nano /etc/systemd/system/cloudflared_name.service And add the following: [Unit] Description=Cloudflared Tunnel for $NAME After=network.target [Service] Type=simple User=$USER WorkingDirectory=/home/$USER/.cloudflared/$NAME ExecStart=/usr/local/bin/cloudflared tunnel --config ./config.yml --origincert ./cert.pem run Restart=always [Install] WantedBy=multi-user.target Note Replace $USER and $NAME with the correct values for your tunnel. Once saved, start and enable the service. sudo systemctl start cloudflared_name.service sudo systemctl enable cloudflared_name.service","title":"Auto-starting"},{"location":"services/cloudflared/#last-words","text":"Repeat the process from Authenticating for each tunnel created.","title":"Last Words"},{"location":"services/samba/","text":"Samba (Native) \u00b6 Samba lets your Linux based server share files and folders on a Windows File Sharing Workgroup using the same protocol (SMB/CIFS), this is pretty useful when you need to share files between computers on your network. This also helps to allow your files to be accessed through the Internet (although it should only be done through a VPN for security purposes). Installation \u00b6 To install Samba : sudo apt-get install samba Configuring \u00b6 We'll make a folder on our 2TB SATA hard drive directory, this will serve as the share folder which will be accessible through SMB . mkdir /media/sata_2tb/sambashare We now need to add this folder entry to the configuration. Open up Samba 's config file. sudo nano /etc/samba/smb.conf Now we'll add the folder we created alongside other directories to the Samba share (note that you should replace these directories corresponding to your needs). You can add as many entries as you need as long as they're well formatted. [sambashare] comment = Samba shared folder path = /media/sata_2tb/sambashare read only = no browsable = yes writeable = yes Now we restart the Samba service to apply the changes: sudo service smbd restart Before trying to access the share with another computer, we'll need to add a password to the Samba user. Use the next command and replace $USER with your username. sudo smbpasswd -a $USER Now, as a final step, add the firewall rule to allow SMB connections. sudo ufw allow 445 /tcp Issues with Permissions on Windows \u00b6 In case you try to access a shared folder that doesn't have the corresponding permissions to allow the Windows user to manage said folder, you can add the following directives to each shared folder block in the config file: create umask = 0777 directory umask = 0777 Shared Folders that Contain Symlinks \u00b6 If one of your shared folders has symlinks in them and you need to share them too, add the following directives to the shared folder block in the config file: follow symlinks = yes wide links = yes Browsing a Shared Folder as a Specified User \u00b6 If you want your shared folder to be accessed as a certain user, add the following directive to the shared folder block in the config file: force user = $USER Note Replace $USER with the UNIX username required.","title":"Samba (Native)"},{"location":"services/samba/#samba-native","text":"Samba lets your Linux based server share files and folders on a Windows File Sharing Workgroup using the same protocol (SMB/CIFS), this is pretty useful when you need to share files between computers on your network. This also helps to allow your files to be accessed through the Internet (although it should only be done through a VPN for security purposes).","title":"Samba (Native)"},{"location":"services/samba/#installation","text":"To install Samba : sudo apt-get install samba","title":"Installation"},{"location":"services/samba/#configuring","text":"We'll make a folder on our 2TB SATA hard drive directory, this will serve as the share folder which will be accessible through SMB . mkdir /media/sata_2tb/sambashare We now need to add this folder entry to the configuration. Open up Samba 's config file. sudo nano /etc/samba/smb.conf Now we'll add the folder we created alongside other directories to the Samba share (note that you should replace these directories corresponding to your needs). You can add as many entries as you need as long as they're well formatted. [sambashare] comment = Samba shared folder path = /media/sata_2tb/sambashare read only = no browsable = yes writeable = yes Now we restart the Samba service to apply the changes: sudo service smbd restart Before trying to access the share with another computer, we'll need to add a password to the Samba user. Use the next command and replace $USER with your username. sudo smbpasswd -a $USER Now, as a final step, add the firewall rule to allow SMB connections. sudo ufw allow 445 /tcp","title":"Configuring"},{"location":"services/samba/#issues-with-permissions-on-windows","text":"In case you try to access a shared folder that doesn't have the corresponding permissions to allow the Windows user to manage said folder, you can add the following directives to each shared folder block in the config file: create umask = 0777 directory umask = 0777","title":"Issues with Permissions on Windows"},{"location":"services/samba/#shared-folders-that-contain-symlinks","text":"If one of your shared folders has symlinks in them and you need to share them too, add the following directives to the shared folder block in the config file: follow symlinks = yes wide links = yes","title":"Shared Folders that Contain Symlinks"},{"location":"services/samba/#browsing-a-shared-folder-as-a-specified-user","text":"If you want your shared folder to be accessed as a certain user, add the following directive to the shared folder block in the config file: force user = $USER Note Replace $USER with the UNIX username required.","title":"Browsing a Shared Folder as a Specified User"},{"location":"services/automation/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to automation related services. mkdir ~/automation For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/automation/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to automation related services. mkdir ~/automation For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/automation/n8n/","text":"n8n \u00b6 n8n is a self-hosted node based automation to run run jobs based on triggers similarly to IFTTT. There is an official image for n8n on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/automation/n8n Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : n8n : image : n8nio/n8n:latest restart : unless-stopped volumes : - ./data:/home/node/.n8n ports : - 5678:5678 environment : - TZ=America/Guayaquil - N8N_BASIC_AUTH_ACTIVE=true - N8N_BASIC_AUTH_USER=CHANGE_THIS - N8N_BASIC_AUTH_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 5678 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"n8n"},{"location":"services/automation/n8n/#n8n","text":"n8n is a self-hosted node based automation to run run jobs based on triggers similarly to IFTTT. There is an official image for n8n on Docker Hub which we'll use.","title":"n8n"},{"location":"services/automation/n8n/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/automation/n8n","title":"Pre-Installation"},{"location":"services/automation/n8n/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : n8n : image : n8nio/n8n:latest restart : unless-stopped volumes : - ./data:/home/node/.n8n ports : - 5678:5678 environment : - TZ=America/Guayaquil - N8N_BASIC_AUTH_ACTIVE=true - N8N_BASIC_AUTH_USER=CHANGE_THIS - N8N_BASIC_AUTH_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/automation/n8n/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 5678 /tcp","title":"Post-Installation"},{"location":"services/automation/n8n/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/data/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to data servers. mkdir ~/data For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/data/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to data servers. mkdir ~/data For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/data/gitea/","text":"Gitea \u00b6 Gitea is a self-hosted git server, useful for having a private VCS solution. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/gitea Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : gitea : image : gitea/gitea:latest restart : unless-stopped volumes : - ./data:/data ports : - 3000:3000 depends_on : - db environment : - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=gitea - MYSQL_USER=gitea - MYSQL_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3000 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Gitea"},{"location":"services/data/gitea/#gitea","text":"Gitea is a self-hosted git server, useful for having a private VCS solution. This service has an official image on Docker Hub which we'll use.","title":"Gitea"},{"location":"services/data/gitea/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/gitea","title":"Pre-Installation"},{"location":"services/data/gitea/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : gitea : image : gitea/gitea:latest restart : unless-stopped volumes : - ./data:/data ports : - 3000:3000 depends_on : - db environment : - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=gitea - MYSQL_USER=gitea - MYSQL_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/data/gitea/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3000 /tcp","title":"Post-Installation"},{"location":"services/data/gitea/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/docker/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to docker related services. mkdir ~/docker For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/docker/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to docker related services. mkdir ~/docker For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/docker/fleet/","text":"Fleet \u00b6 Fleet is a web UI that displays maintained Docker images from our own repositories, it serves a central place to display all your docker images. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/fleet Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : fleet : image : ghcr.io/linuxserver/fleet:latest restart : unless-stopped volumes : - ./config:/config ports : - 8080:8080 depends_on : - db environment : - PUID=1000 - PGID=1000 - fleet_admin_authentication_type=DATABASE - fleet_database_url=jdbc:mariadb://db/fleet - fleet_database_username=fleet - fleet_database_password=CHANGE_THIS - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=fleet - MYSQL_USER=fleet - MYSQL_PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8080 /tcp The default user and password are: admin : admin , you should create a new user and remove this initial admin user. Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Fleet"},{"location":"services/docker/fleet/#fleet","text":"Fleet is a web UI that displays maintained Docker images from our own repositories, it serves a central place to display all your docker images. This service has an official image on Docker Hub which we'll use.","title":"Fleet"},{"location":"services/docker/fleet/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/fleet","title":"Pre-Installation"},{"location":"services/docker/fleet/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : fleet : image : ghcr.io/linuxserver/fleet:latest restart : unless-stopped volumes : - ./config:/config ports : - 8080:8080 depends_on : - db environment : - PUID=1000 - PGID=1000 - fleet_admin_authentication_type=DATABASE - fleet_database_url=jdbc:mariadb://db/fleet - fleet_database_username=fleet - fleet_database_password=CHANGE_THIS - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=fleet - MYSQL_USER=fleet - MYSQL_PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/docker/fleet/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8080 /tcp The default user and password are: admin : admin , you should create a new user and remove this initial admin user.","title":"Post-Installation"},{"location":"services/docker/fleet/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/docker/portainer/","text":"Portainer \u00b6 Portainer is a web UI for Docker which allows us to have an insight on all the containers running on our server. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/portainer Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : portainer : image : portainer/portainer-ce:latest restart : unless-stopped volumes : - ./data:/data - /var/run/docker.sock:/var/run/docker.sock ports : - 8000:8000 - 9000:9000 environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8000 /tcp sudo ufw allow 9000 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Portainer"},{"location":"services/docker/portainer/#portainer","text":"Portainer is a web UI for Docker which allows us to have an insight on all the containers running on our server. This service has an official image on Docker Hub which we'll use.","title":"Portainer"},{"location":"services/docker/portainer/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/portainer","title":"Pre-Installation"},{"location":"services/docker/portainer/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : portainer : image : portainer/portainer-ce:latest restart : unless-stopped volumes : - ./data:/data - /var/run/docker.sock:/var/run/docker.sock ports : - 8000:8000 - 9000:9000 environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/docker/portainer/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8000 /tcp sudo ufw allow 9000 /tcp","title":"Post-Installation"},{"location":"services/docker/portainer/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to media servers. mkdir ~/media For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/media/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to media servers. mkdir ~/media For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/media/embystat/","text":"EmbyStat \u00b6 Warning This service requires Jellyfin , you must set that up before continuing with this one. EmbyStat is an analytics service for Jellyfin/Emby. There is no official docker image for EmbyStat , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/embystat Docker Compose \u00b6 EmbyStat will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : embystat : image : ghcr.io/linuxserver/embystat:latest restart : unless-stopped networks : - jellyfin volumes : - ./config:/config ports : - 6555:6555 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 6555 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"EmbyStat"},{"location":"services/media/embystat/#embystat","text":"Warning This service requires Jellyfin , you must set that up before continuing with this one. EmbyStat is an analytics service for Jellyfin/Emby. There is no official docker image for EmbyStat , however we'll use one from LinuxServer on Docker Hub .","title":"EmbyStat"},{"location":"services/media/embystat/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/embystat","title":"Pre-Installation"},{"location":"services/media/embystat/#docker-compose","text":"EmbyStat will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : embystat : image : ghcr.io/linuxserver/embystat:latest restart : unless-stopped networks : - jellyfin volumes : - ./config:/config ports : - 6555:6555 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/embystat/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 6555 /tcp","title":"Post-Installation"},{"location":"services/media/embystat/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/jackett/","text":"Jackett \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Jackett is a torrent indexer that standardizes the shape of the data from multiple indexers to make it possible to use originally unsupported indexers on services like Sonarr . There is no official docker image for Jackett , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/jackett Docker Compose \u00b6 Jackett will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jackett : image : ghcr.io/linuxserver/jackett:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 9117:9117 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - AUTO_UPDATE=true networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 9117 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Jackett"},{"location":"services/media/jackett/#jackett","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Jackett is a torrent indexer that standardizes the shape of the data from multiple indexers to make it possible to use originally unsupported indexers on services like Sonarr . There is no official docker image for Jackett , however we'll use one from LinuxServer on Docker Hub .","title":"Jackett"},{"location":"services/media/jackett/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/jackett","title":"Pre-Installation"},{"location":"services/media/jackett/#docker-compose","text":"Jackett will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jackett : image : ghcr.io/linuxserver/jackett:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 9117:9117 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - AUTO_UPDATE=true networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/jackett/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 9117 /tcp","title":"Post-Installation"},{"location":"services/media/jackett/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/jdownloader/","text":"JDownloader \u00b6 JDownloader is a download client that makes downloading from direct links a breeze. There is no official image for JDownloader , however we'll use one available on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the download client's data will be saved. mkdir ~/media/jdownloader Docker Compose \u00b6 JDownloader will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jdownloader : image : jlesage/jdownloader-2:latest restart : unless-stopped volumes : - ./config:/config - /media/sata_2tb/Downloads:/output ports : - 3129:3129 - 5800:5800 environment : - TZ=America/Guayaquil - USER_ID=1000 - GROUP_ID=1000 Note In the case of the USER_ID and GROUP_ID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3129 /tcp sudo ufw allow 5800 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"JDownloader"},{"location":"services/media/jdownloader/#jdownloader","text":"JDownloader is a download client that makes downloading from direct links a breeze. There is no official image for JDownloader , however we'll use one available on Docker Hub .","title":"JDownloader"},{"location":"services/media/jdownloader/#pre-installation","text":"We'll create a folder in the main user's home where all the download client's data will be saved. mkdir ~/media/jdownloader","title":"Pre-Installation"},{"location":"services/media/jdownloader/#docker-compose","text":"JDownloader will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jdownloader : image : jlesage/jdownloader-2:latest restart : unless-stopped volumes : - ./config:/config - /media/sata_2tb/Downloads:/output ports : - 3129:3129 - 5800:5800 environment : - TZ=America/Guayaquil - USER_ID=1000 - GROUP_ID=1000 Note In the case of the USER_ID and GROUP_ID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/jdownloader/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3129 /tcp sudo ufw allow 5800 /tcp","title":"Post-Installation"},{"location":"services/media/jdownloader/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/jellyfin/","text":"Jellyfin \u00b6 Jellyfin is an open source of the famous media server Emby . This media server has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/jellyfin We'll also need to create a custom network to allow other containers to communicate with this one. docker network create jellyfin Docker Compose \u00b6 Jellyfin will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jellyfin : image : jellyfin/jellyfin:latest user : 1000:1000 restart : unless-stopped networks : - jellyfin volumes : - ./config:/config - ./cache:/cache - /media/sata_2tb/Jellyfin:/media ports : - 8096:8096 environment : - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the user directive, 1000:1000 corresponds to the user's UID:GID . You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8086 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Jellyfin"},{"location":"services/media/jellyfin/#jellyfin","text":"Jellyfin is an open source of the famous media server Emby . This media server has an official image available on Docker Hub which we'll use.","title":"Jellyfin"},{"location":"services/media/jellyfin/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/jellyfin We'll also need to create a custom network to allow other containers to communicate with this one. docker network create jellyfin","title":"Pre-Installation"},{"location":"services/media/jellyfin/#docker-compose","text":"Jellyfin will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jellyfin : image : jellyfin/jellyfin:latest user : 1000:1000 restart : unless-stopped networks : - jellyfin volumes : - ./config:/config - ./cache:/cache - /media/sata_2tb/Jellyfin:/media ports : - 8096:8096 environment : - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the user directive, 1000:1000 corresponds to the user's UID:GID . You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/jellyfin/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8086 /tcp","title":"Post-Installation"},{"location":"services/media/jellyfin/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/ombi/","text":"Ombi \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Ombi is a media request tracker, useful for when you share a Plex server or similar with family and friends. There is no official docker image for Ombi , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/ombi Docker Compose \u00b6 Ombi will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : ombi : image : ghcr.io/linuxserver/ombi:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 3579:3579 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3579 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Ombi"},{"location":"services/media/ombi/#ombi","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Ombi is a media request tracker, useful for when you share a Plex server or similar with family and friends. There is no official docker image for Ombi , however we'll use one from LinuxServer on Docker Hub .","title":"Ombi"},{"location":"services/media/ombi/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/ombi","title":"Pre-Installation"},{"location":"services/media/ombi/#docker-compose","text":"Ombi will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : ombi : image : ghcr.io/linuxserver/ombi:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 3579:3579 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/ombi/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3579 /tcp","title":"Post-Installation"},{"location":"services/media/ombi/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/plex/","text":"Plex \u00b6 Plex is one of the most popular media server options out there. This media server has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/plex Docker Compose \u00b6 Plex will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : plex : image : plexinc/pms-docker:latest restart : unless-stopped network_mode : host volumes : - ./config:/config - ./transcode:/transcode - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb environment : - TZ=America/Guayaquil - PLEX_UID=1000 - PLEX_GID=1000 Note In the case of the PLEX_UID and PLEX_GID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 32400 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Plex"},{"location":"services/media/plex/#plex","text":"Plex is one of the most popular media server options out there. This media server has an official image available on Docker Hub which we'll use.","title":"Plex"},{"location":"services/media/plex/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/plex","title":"Pre-Installation"},{"location":"services/media/plex/#docker-compose","text":"Plex will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : plex : image : plexinc/pms-docker:latest restart : unless-stopped network_mode : host volumes : - ./config:/config - ./transcode:/transcode - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb environment : - TZ=America/Guayaquil - PLEX_UID=1000 - PLEX_GID=1000 Note In the case of the PLEX_UID and PLEX_GID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/plex/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 32400 /tcp","title":"Post-Installation"},{"location":"services/media/plex/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/radarr/","text":"Radarr \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Radarr is an RSS downloader focused on movies. There is no official docker image for Radarr , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/radarr Docker Compose \u00b6 Radarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : radarr : image : ghcr.io/linuxserver/radarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/sata_2tb/Downloads:/downloads ports : - 7878:7878 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 7878 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Radarr"},{"location":"services/media/radarr/#radarr","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Radarr is an RSS downloader focused on movies. There is no official docker image for Radarr , however we'll use one from LinuxServer on Docker Hub .","title":"Radarr"},{"location":"services/media/radarr/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/radarr","title":"Pre-Installation"},{"location":"services/media/radarr/#docker-compose","text":"Radarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : radarr : image : ghcr.io/linuxserver/radarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/sata_2tb/Downloads:/downloads ports : - 7878:7878 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/radarr/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 7878 /tcp","title":"Post-Installation"},{"location":"services/media/radarr/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/sonarr/","text":"Sonarr \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Sonarr is an RSS downloader focused on TV Shows. There is no official docker image for Sonarr , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/sonarr Docker Compose \u00b6 Sonarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : sonarr : image : ghcr.io/linuxserver/sonarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/sata_2tb/Downloads:/downloads ports : - 8989:8989 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8989 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Sonarr"},{"location":"services/media/sonarr/#sonarr","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Sonarr is an RSS downloader focused on TV Shows. There is no official docker image for Sonarr , however we'll use one from LinuxServer on Docker Hub .","title":"Sonarr"},{"location":"services/media/sonarr/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/sonarr","title":"Pre-Installation"},{"location":"services/media/sonarr/#docker-compose","text":"Sonarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : sonarr : image : ghcr.io/linuxserver/sonarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/sata_2tb/Downloads:/downloads ports : - 8989:8989 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/sonarr/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8989 /tcp","title":"Post-Installation"},{"location":"services/media/sonarr/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/synclounge/","text":"Synclounge \u00b6 Synclounge is a tool that lets your Plex users watch something simultaneously. There is no official docker image for Synclounge , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/synclounge Docker Compose \u00b6 Synclounge will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : synclounge : image : ghcr.io/linuxserver/synclounge:latest restart : unless-stopped ports : - 8088:8088 environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8088 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Synclounge"},{"location":"services/media/synclounge/#synclounge","text":"Synclounge is a tool that lets your Plex users watch something simultaneously. There is no official docker image for Synclounge , however we'll use one from LinuxServer on Docker Hub .","title":"Synclounge"},{"location":"services/media/synclounge/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/synclounge","title":"Pre-Installation"},{"location":"services/media/synclounge/#docker-compose","text":"Synclounge will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : synclounge : image : ghcr.io/linuxserver/synclounge:latest restart : unless-stopped ports : - 8088:8088 environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/media/synclounge/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8088 /tcp","title":"Post-Installation"},{"location":"services/media/synclounge/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/tautulli/","text":"Tautulli \u00b6 Tautulli is a monitoring tool for Plex . This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/tautulli Docker Compose \u00b6 Tautulli will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : tautulli : image : tautulli/tautulli:latest restart : unless-stopped volumes : - ./config:/config ports : - 8181:8181 environment : - TZ=America/Guayaquil - PUID=1000 - PGID=1000 Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8181 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Tautulli"},{"location":"services/media/tautulli/#tautulli","text":"Tautulli is a monitoring tool for Plex . This service has an official image available on Docker Hub which we'll use.","title":"Tautulli"},{"location":"services/media/tautulli/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/tautulli","title":"Pre-Installation"},{"location":"services/media/tautulli/#docker-compose","text":"Tautulli will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : tautulli : image : tautulli/tautulli:latest restart : unless-stopped volumes : - ./config:/config ports : - 8181:8181 environment : - TZ=America/Guayaquil - PUID=1000 - PGID=1000 Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/tautulli/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8181 /tcp","title":"Post-Installation"},{"location":"services/media/tautulli/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/transmission/","text":"Transmission \u00b6 Tranmission is a BitTorrent client. There is no official docker image for Transmission , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/transmission We'll also need to create a custom network to allow other containers to communicate with this one. docker network create downloader Any container that wants to communicate with this one should join the downloader network. Docker Compose \u00b6 Transmission will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : transmission : image : ghcr.io/linuxserver/transmission:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - ./watch:/watch - /media/sata_2tb/Downloads:/downloads ports : - 9091:9091 - 51413:51413 - 51413:51413/udp environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - TRANSMISSION_WEB_HOME=/flood-for-transmission/ - USER=<USER_HERE> - PASS=<PASS_HERE> networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note The password should be set inside the docker-compose.yml file and not manually updated in config/settings.json which will mess up with the s6 supervisor. Use a password you don't care too much about since it would basically be saved in plain text. Note You may change the contents of config/settings.json as long as the container is stopped. Post-Installation \u00b6 We'll need to allow the service's web UI port on our firewall. sudo ufw allow 9091 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Transmission"},{"location":"services/media/transmission/#transmission","text":"Tranmission is a BitTorrent client. There is no official docker image for Transmission , however we'll use one from LinuxServer on Docker Hub .","title":"Transmission"},{"location":"services/media/transmission/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/transmission We'll also need to create a custom network to allow other containers to communicate with this one. docker network create downloader Any container that wants to communicate with this one should join the downloader network.","title":"Pre-Installation"},{"location":"services/media/transmission/#docker-compose","text":"Transmission will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : transmission : image : ghcr.io/linuxserver/transmission:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - ./watch:/watch - /media/sata_2tb/Downloads:/downloads ports : - 9091:9091 - 51413:51413 - 51413:51413/udp environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - TRANSMISSION_WEB_HOME=/flood-for-transmission/ - USER=<USER_HERE> - PASS=<PASS_HERE> networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note The password should be set inside the docker-compose.yml file and not manually updated in config/settings.json which will mess up with the s6 supervisor. Use a password you don't care too much about since it would basically be saved in plain text. Note You may change the contents of config/settings.json as long as the container is stopped.","title":"Docker Compose"},{"location":"services/media/transmission/#post-installation","text":"We'll need to allow the service's web UI port on our firewall. sudo ufw allow 9091 /tcp","title":"Post-Installation"},{"location":"services/media/transmission/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/monitoring/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to system monitoring related services. mkdir ~/monitoring For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/monitoring/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to system monitoring related services. mkdir ~/monitoring For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/monitoring/librespeed/","text":"LibreSpeed \u00b6 LibreSpeed is a self-hosted speed test, useful to check our connection from outside into our server. There is no official docker image for LibreSpeed , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/librespeed Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : librespeed : image : ghcr.io/linuxserver/librespeed:latest restart : unless-stopped volumes : - ./config:/config ports : - 8050:80 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8050 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"LibreSpeed"},{"location":"services/monitoring/librespeed/#librespeed","text":"LibreSpeed is a self-hosted speed test, useful to check our connection from outside into our server. There is no official docker image for LibreSpeed , however we'll use one from LinuxServer on Docker Hub .","title":"LibreSpeed"},{"location":"services/monitoring/librespeed/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/librespeed","title":"Pre-Installation"},{"location":"services/monitoring/librespeed/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : librespeed : image : ghcr.io/linuxserver/librespeed:latest restart : unless-stopped volumes : - ./config:/config ports : - 8050:80 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/monitoring/librespeed/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8050 /tcp","title":"Post-Installation"},{"location":"services/monitoring/librespeed/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/monitoring/scrutiny/","text":"Scrutiny \u00b6 Scrutiny is a S.M.A.R.T monitoring tool that uses smartd . There is no official docker image for Scrutiny , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/scrutiny Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : scrutiny : image : ghcr.io/linuxserver/scrutiny:latest restart : unless-stopped cap_add : - SYS_RAWIO volumes : - ./config:/config - /run/udev:/run/udev:ro ports : - 8020:8080 devices : - /dev/sda:/dev/sda - /dev/sdb:/dev/sdb - /dev/sdc:/dev/sdc - /dev/sdd:/dev/sdd environment : - PUID=1000 - PGID=1000 - SCRUTINY_WEB=true - SCRUTINY_COLLECTOR=true - TZ=America/Guayaquil Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Under devices make sure you're passing your hard drives. You can check blkid to see which device blocks to pass. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8020 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure. Updating Results \u00b6 To manually update the results, run the following from inside the container's data folder: docker-compose run --rm scrutiny scrutiny-collector-metrics run","title":"Scrutiny"},{"location":"services/monitoring/scrutiny/#scrutiny","text":"Scrutiny is a S.M.A.R.T monitoring tool that uses smartd . There is no official docker image for Scrutiny , however we'll use one from LinuxServer on Docker Hub .","title":"Scrutiny"},{"location":"services/monitoring/scrutiny/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/scrutiny","title":"Pre-Installation"},{"location":"services/monitoring/scrutiny/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : scrutiny : image : ghcr.io/linuxserver/scrutiny:latest restart : unless-stopped cap_add : - SYS_RAWIO volumes : - ./config:/config - /run/udev:/run/udev:ro ports : - 8020:8080 devices : - /dev/sda:/dev/sda - /dev/sdb:/dev/sdb - /dev/sdc:/dev/sdc - /dev/sdd:/dev/sdd environment : - PUID=1000 - PGID=1000 - SCRUTINY_WEB=true - SCRUTINY_COLLECTOR=true - TZ=America/Guayaquil Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Under devices make sure you're passing your hard drives. You can check blkid to see which device blocks to pass.","title":"Docker Compose"},{"location":"services/monitoring/scrutiny/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8020 /tcp","title":"Post-Installation"},{"location":"services/monitoring/scrutiny/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/monitoring/scrutiny/#updating-results","text":"To manually update the results, run the following from inside the container's data folder: docker-compose run --rm scrutiny scrutiny-collector-metrics run","title":"Updating Results"},{"location":"services/other/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to other services. mkdir ~/other For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/other/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to other services. mkdir ~/other For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/other/rtmp-simulcast/","text":"RTMP Simulcast \u00b6 If you like to stream your video games to multiple platforms simultaneously, then RTMP Simulcast is for you. There are services out there that let you do this for free, but they have some cons: Depending on the service you use, your stream titles or descriptions could be used for advertising purposes, which basically means you lose complete control of what your stream description displays to your viewers. Since these services are used by multiple people at the same time, streaming platforms will most likely detect a huge pool of users streaming from the same IP which means that you'll be targeted by a low exposure algorithm that will, ironically, make your stream harder to find. You can bypass these problems by streaming simultaneously to your desired platforms yourself, but keep in mind, there are some difficulties as well: Doing this (ideally) requires you to have a second computer (performance doesn't matter too much, you could even use a Raspberry PI for this), you could technically achieve the same result with a virtual machine inside the streaming computer but it would represent a huge performance drop. Since you would be streaming to multiple platforms yourself, you would need a much higher upload bandwidth (around the stream bitrate multiplied by the number of platforms you're streaming to). For instance, my stream gets rendered at a bitrate of 6000 kbps , if I wanted to stream to 3 different platforms at the same time, I would need around 20000 kbps . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/rtmp-simulcast Configuration \u00b6 To configure this service, we'll first create a folder called config inside ~/other/rtmp-simulcast and create a file named rtmp.conf where the configuration for the simulcast will be located. mkdir ~/other/rtmp-simulcast/config nano ~/other/rtmp-simulcast/config/rtmp.conf And its content should be as follows: # RTMP Stream Simulcast rtmp { server { listen 1935; application live { live on; record off; push rtmp://ingest.server.com/application/stream_key } application local { live on; record off; } } } Note Replace rtmp://ingest.sever.com/application/stream_key with the actual ingest server of the platform you want to stream to. For example: rtmp://a.rtmp.youtube.com/live2/{my_stream_key} . You can push multiple ingest servers. Dockerfile \u00b6 Since the service does not have an official Docker image, we'll create a Dockerfile . The content of the Dockerfile file is as follows: FROM ubuntu:20.04 RUN apt-get update && apt-get install -y nginx libnginx-mod-rtmp WORKDIR /etc/nginx VOLUME /etc/nginx/rtmp-config RUN printf \"\\n\\nrtmp {\\n include /etc/nginx/rtmp-config/*.conf;\\n}\\n\" >> nginx.conf EXPOSE 1935 EXPOSE 80 CMD [ \"nginx\" , \"-g\" , \"daemon off;\" ] Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : rtmp : build : . restart : unless-stopped volumes : - ./config:/etc/nginx/rtmp-config ports : - 1935:1935 environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 1935 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure. Streaming Settings \u00b6 In your streaming software, change your streaming server to the following: rtmp://server_local_ip/live And you can place whatever you want as the stream key. For testing purposes, you can also stream to rtmp://server_local_ip/local and watch it to see how it performs. Watching Your Stream Locally \u00b6 If you wish to see how your server perceives your stream, you can use a RTMP player (VLC will do the trick), and open the stream at the url rtmp://server_local_ip/local/{stream_key} . Replace {stream_key} with the actual streaming key that you're currently using.","title":"RTMP Simulcast"},{"location":"services/other/rtmp-simulcast/#rtmp-simulcast","text":"If you like to stream your video games to multiple platforms simultaneously, then RTMP Simulcast is for you. There are services out there that let you do this for free, but they have some cons: Depending on the service you use, your stream titles or descriptions could be used for advertising purposes, which basically means you lose complete control of what your stream description displays to your viewers. Since these services are used by multiple people at the same time, streaming platforms will most likely detect a huge pool of users streaming from the same IP which means that you'll be targeted by a low exposure algorithm that will, ironically, make your stream harder to find. You can bypass these problems by streaming simultaneously to your desired platforms yourself, but keep in mind, there are some difficulties as well: Doing this (ideally) requires you to have a second computer (performance doesn't matter too much, you could even use a Raspberry PI for this), you could technically achieve the same result with a virtual machine inside the streaming computer but it would represent a huge performance drop. Since you would be streaming to multiple platforms yourself, you would need a much higher upload bandwidth (around the stream bitrate multiplied by the number of platforms you're streaming to). For instance, my stream gets rendered at a bitrate of 6000 kbps , if I wanted to stream to 3 different platforms at the same time, I would need around 20000 kbps .","title":"RTMP Simulcast"},{"location":"services/other/rtmp-simulcast/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/rtmp-simulcast","title":"Pre-Installation"},{"location":"services/other/rtmp-simulcast/#configuration","text":"To configure this service, we'll first create a folder called config inside ~/other/rtmp-simulcast and create a file named rtmp.conf where the configuration for the simulcast will be located. mkdir ~/other/rtmp-simulcast/config nano ~/other/rtmp-simulcast/config/rtmp.conf And its content should be as follows: # RTMP Stream Simulcast rtmp { server { listen 1935; application live { live on; record off; push rtmp://ingest.server.com/application/stream_key } application local { live on; record off; } } } Note Replace rtmp://ingest.sever.com/application/stream_key with the actual ingest server of the platform you want to stream to. For example: rtmp://a.rtmp.youtube.com/live2/{my_stream_key} . You can push multiple ingest servers.","title":"Configuration"},{"location":"services/other/rtmp-simulcast/#dockerfile","text":"Since the service does not have an official Docker image, we'll create a Dockerfile . The content of the Dockerfile file is as follows: FROM ubuntu:20.04 RUN apt-get update && apt-get install -y nginx libnginx-mod-rtmp WORKDIR /etc/nginx VOLUME /etc/nginx/rtmp-config RUN printf \"\\n\\nrtmp {\\n include /etc/nginx/rtmp-config/*.conf;\\n}\\n\" >> nginx.conf EXPOSE 1935 EXPOSE 80 CMD [ \"nginx\" , \"-g\" , \"daemon off;\" ]","title":"Dockerfile"},{"location":"services/other/rtmp-simulcast/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : rtmp : build : . restart : unless-stopped volumes : - ./config:/etc/nginx/rtmp-config ports : - 1935:1935 environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build","title":"Docker Compose"},{"location":"services/other/rtmp-simulcast/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 1935 /tcp","title":"Post-Installation"},{"location":"services/other/rtmp-simulcast/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/other/rtmp-simulcast/#streaming-settings","text":"In your streaming software, change your streaming server to the following: rtmp://server_local_ip/live And you can place whatever you want as the stream key. For testing purposes, you can also stream to rtmp://server_local_ip/local and watch it to see how it performs.","title":"Streaming Settings"},{"location":"services/other/rtmp-simulcast/#watching-your-stream-locally","text":"If you wish to see how your server perceives your stream, you can use a RTMP player (VLC will do the trick), and open the stream at the url rtmp://server_local_ip/local/{stream_key} . Replace {stream_key} with the actual streaming key that you're currently using.","title":"Watching Your Stream Locally"},{"location":"services/other/webframes/","text":"Webframes \u00b6 Webframes is a little webapp that frames other pages. This will be useful to have a central place where you can access all the aforementioned web services. This service has an image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/webframes Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : webframes : image : moonstarx/webframes:latest restart : unless-stopped ports : - 80:4000 volumes : - ./data:/opt/app/backend/data environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 80 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Webframes"},{"location":"services/other/webframes/#webframes","text":"Webframes is a little webapp that frames other pages. This will be useful to have a central place where you can access all the aforementioned web services. This service has an image on Docker Hub which we'll use.","title":"Webframes"},{"location":"services/other/webframes/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/webframes","title":"Pre-Installation"},{"location":"services/other/webframes/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : webframes : image : moonstarx/webframes:latest restart : unless-stopped ports : - 80:4000 volumes : - ./data:/opt/app/backend/data environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/other/webframes/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 80 /tcp","title":"Post-Installation"},{"location":"services/other/webframes/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"setting-up/docker/","text":"Docker \u00b6 A good portion of our services will be run through Docker . We'll need to first install this. Installation \u00b6 First we'll need to install some dependencies: sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release We'll then need to add the Docker repository: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Finally, we'll update the repositories and install Docker : sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io Permissions \u00b6 We'll add the required permissions for our user into the docker group. sudo groupadd docker sudo gpasswd -a $USER docker Finally, reboot the server for the changes to apply. Docker Compose \u00b6 We'll be using Docker Compose to run our containers, to install it run the following: sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"Docker"},{"location":"setting-up/docker/#docker","text":"A good portion of our services will be run through Docker . We'll need to first install this.","title":"Docker"},{"location":"setting-up/docker/#installation","text":"First we'll need to install some dependencies: sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release We'll then need to add the Docker repository: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Finally, we'll update the repositories and install Docker : sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io","title":"Installation"},{"location":"setting-up/docker/#permissions","text":"We'll add the required permissions for our user into the docker group. sudo groupadd docker sudo gpasswd -a $USER docker Finally, reboot the server for the changes to apply.","title":"Permissions"},{"location":"setting-up/docker/#docker-compose","text":"We'll be using Docker Compose to run our containers, to install it run the following: sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"Docker Compose"},{"location":"setting-up/mounting-drives/","text":"Mounting Drives \u00b6 In this server there will be a 2TB SATA drive, and 2 USB 3.0 drives of 1TB and 4TB respectively. We need these drives to mount on system startup, for this, we'll need to set up the fstab . Getting Drives' UUIDs \u00b6 In order to get the UUIDs of the drives in question, it is necessary to plug them in and reboot the server. Once this is done, execute the following: lsblk -o NAME,FSTYPE,UUID This will give an output like the following: loop0 squashfs loop1 squashfs loop2 squashfs sda \u2514\u2500sda1 ext4 dfeba4f0-e470-49ca-bc6d-87d6d7cb2926 sdb \u251c\u2500sdb1 vfat A12E-F096 \u2514\u2500sdb2 ext4 c1aafa14-c857-4d3e-8ae1-00c8cd462810 sdc ext4 418987da-2351-11e9-aec8-b8975ad7798b sdd \u2514\u2500sdd1 ext4 fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 In this case, /dev/sda1 is the 1TB USB hard drive with ext4 format, /dev/sdc is the 2TB SATA drive with ext4 format and lastly, /dev/sdd1 is the 4TB USB hard drive with ext4 format. We'll need the UUIDs later, so copy them somewhere. Preparing the Folders \u00b6 We'll mount the hard drives in /media , for this we'll create the required folders like so: sudo mkdir /media/sata_2tb /media/usb_1tb /media/usb_4tb You may also change the permissions on these folders if it causes any problem. sudo chmod -R 777 /media/sata_2tb /media/usb_1tb /media/usb_4tb Modifying fstab \u00b6 Danger Proceed at your own risk, messing up this file will most probably break your computer. You can still fix it by entering safe mode and logging in as root to rollback. We'll modify the /etc/fstab file. sudo nano /etc/fstab And we'll add a new line for each hard drive with the following structure: UUID=$UUID $DIR $FORMAT defaults 0 0 In our case, we'll add the following lines: UUID=dfeba4f0-e470-49ca-bc6d-87d6d7cb2926 /media/usb_1tb ext4 defaults 0 0 UUID=418987da-2351-11e9-aec8-b8975ad7798b /media/sata_2tb ext4 defaults 0 0 UUID=fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 /media/usb_4tb ext4 defaults 0 0 Finally, reboot the server. The hard drives should now be automatically mounted.","title":"Mounting Drives"},{"location":"setting-up/mounting-drives/#mounting-drives","text":"In this server there will be a 2TB SATA drive, and 2 USB 3.0 drives of 1TB and 4TB respectively. We need these drives to mount on system startup, for this, we'll need to set up the fstab .","title":"Mounting Drives"},{"location":"setting-up/mounting-drives/#getting-drives-uuids","text":"In order to get the UUIDs of the drives in question, it is necessary to plug them in and reboot the server. Once this is done, execute the following: lsblk -o NAME,FSTYPE,UUID This will give an output like the following: loop0 squashfs loop1 squashfs loop2 squashfs sda \u2514\u2500sda1 ext4 dfeba4f0-e470-49ca-bc6d-87d6d7cb2926 sdb \u251c\u2500sdb1 vfat A12E-F096 \u2514\u2500sdb2 ext4 c1aafa14-c857-4d3e-8ae1-00c8cd462810 sdc ext4 418987da-2351-11e9-aec8-b8975ad7798b sdd \u2514\u2500sdd1 ext4 fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 In this case, /dev/sda1 is the 1TB USB hard drive with ext4 format, /dev/sdc is the 2TB SATA drive with ext4 format and lastly, /dev/sdd1 is the 4TB USB hard drive with ext4 format. We'll need the UUIDs later, so copy them somewhere.","title":"Getting Drives' UUIDs"},{"location":"setting-up/mounting-drives/#preparing-the-folders","text":"We'll mount the hard drives in /media , for this we'll create the required folders like so: sudo mkdir /media/sata_2tb /media/usb_1tb /media/usb_4tb You may also change the permissions on these folders if it causes any problem. sudo chmod -R 777 /media/sata_2tb /media/usb_1tb /media/usb_4tb","title":"Preparing the Folders"},{"location":"setting-up/mounting-drives/#modifying-fstab","text":"Danger Proceed at your own risk, messing up this file will most probably break your computer. You can still fix it by entering safe mode and logging in as root to rollback. We'll modify the /etc/fstab file. sudo nano /etc/fstab And we'll add a new line for each hard drive with the following structure: UUID=$UUID $DIR $FORMAT defaults 0 0 In our case, we'll add the following lines: UUID=dfeba4f0-e470-49ca-bc6d-87d6d7cb2926 /media/usb_1tb ext4 defaults 0 0 UUID=418987da-2351-11e9-aec8-b8975ad7798b /media/sata_2tb ext4 defaults 0 0 UUID=fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 /media/usb_4tb ext4 defaults 0 0 Finally, reboot the server. The hard drives should now be automatically mounted.","title":"Modifying fstab"},{"location":"setting-up/networking/","text":"Networking \u00b6 Here's a table that contains the required default ports that need to be forwarded on the router (and allowed by the firewall) so the services are accessible from outside the private network. Ports can change if desired, port forwarding rules should be set up accordingly. Port Forwarding Table \u00b6 Service Port Range Protocol SSH 22 TCP Samba (SMB/CIFS) 445 TCP Portainer 8000, 9000 TCP Fleet 8080 TCP Jellyfin 8086 TCP EmbyStat 6555 TCP Plex 32400 TCP Tautulli 8181 TCP Synclounge 8088 TCP Ombi 3579 TCP Transmission 9091 TCP Sonarr 8989 TCP Radarr 7878 TCP Jackett 9117 TCP JDownloader 3129, 5800 TCP Gitea 3000 TCP LibreSpeed 8050 TCP Scrutiny 8020 TCP n8n 5678 TCP RTMP Simulcast 1935 TCP Webframes 80 TCP If you don't know what internal IP the server is running on, you can always type on the terminal: ifconfig UFW \u00b6 UFW is a friendly frontend for iptables that makes it a lot easier to add connection rules to your firewall. One of the many wonders of UFW is the fact that rules are automatically saved when set, which is not true for iptables . Installation \u00b6 We'll need to install UFW and set it up. sudo apt-get install ufw sudo ufw default allow outgoing sudo ufw default deny incoming sudo ufw enable The commands should be pretty self-explanatory but, just in case, these default the firewall to allow any connections going from the server to the Internet and deny any incoming connections from the Internet to the server. Usage \u00b6 A very good command to check UFW 's status (if it's enabled or disabled) and see all the custom rules added and active is: sudo ufw status You can add a new rule by using: sudo ufw allow <PORT_RANGE>/<PROTOCOL> SSH \u00b6 Installation \u00b6 Since the server will run in headless mode, it would be very useful to be able to access it remotely from within (and even outside) the network. We'll use OpenSSH , it is generally installed with the OS but in case that it isn't, you can install it by running: sudo apt-get install openssh-client openssh-server Setting-up \u00b6 We now need to allow SSH connections through the firewall so we can access the server. sudo ufw allow ssh Google Authentication (2FA) \u00b6 Two Factor Authentication has become a must-have in terms of account security, almost all services out there have the option to add this security measure to ensure account security. Luckily, we can implement our own Two Factor Authentication to access the server through SSH . Installation \u00b6 To enable 2FA , we'll need to install the following package: sudo apt-get install libpam-google-authenticator Setting-up \u00b6 To set it up, simply run: google-authenticator When running this, you'll receive a secret key which is used to add your account manually to your phone's 2FA application. Alternatively, you also get a nicely printed QR code on the terminal window (which you may need to resize to see fully) that you can scan with your phone. You will also get some scratch codes that you should always keep somewhere safe, just in case you lose access to your phone or something happens, you can still login to your server. To continue, answer y to all the questions to set up 2FA with the default settings. We now need to enable 2FA on SSH , to do this, edit the following file: sudo nano /etc/ssh/sshd_config Look for the following lines and edit them accordingly: UsePAM yes ChallengeResponseAuthentication yes Save and close the editor and restart the SSH service. sudo systemctl restart ssh We now need to edit the PAM rule file: sudo nano /etc/pam.d/sshd At the end of the file, add the following line: auth required pam_google_authenticator.so Save and close the file. Testing \u00b6 In order to test that 2FA works properly, open up a new SSH session without closing the previous one and try logging in, you'll be prompted for your user password and for the 2FA code which is available on your phone. Info When using 2FA for SSH , all the users in the server will need to set-it up, otherwise they won't be able to access their accounts. In case you get locked out from one of these users, you can always login to a sudoer account (usually the admin one which is added when installing the OS) and force-login with: sudo -iu <user> .","title":"Networking"},{"location":"setting-up/networking/#networking","text":"Here's a table that contains the required default ports that need to be forwarded on the router (and allowed by the firewall) so the services are accessible from outside the private network. Ports can change if desired, port forwarding rules should be set up accordingly.","title":"Networking"},{"location":"setting-up/networking/#port-forwarding-table","text":"Service Port Range Protocol SSH 22 TCP Samba (SMB/CIFS) 445 TCP Portainer 8000, 9000 TCP Fleet 8080 TCP Jellyfin 8086 TCP EmbyStat 6555 TCP Plex 32400 TCP Tautulli 8181 TCP Synclounge 8088 TCP Ombi 3579 TCP Transmission 9091 TCP Sonarr 8989 TCP Radarr 7878 TCP Jackett 9117 TCP JDownloader 3129, 5800 TCP Gitea 3000 TCP LibreSpeed 8050 TCP Scrutiny 8020 TCP n8n 5678 TCP RTMP Simulcast 1935 TCP Webframes 80 TCP If you don't know what internal IP the server is running on, you can always type on the terminal: ifconfig","title":"Port Forwarding Table"},{"location":"setting-up/networking/#ufw","text":"UFW is a friendly frontend for iptables that makes it a lot easier to add connection rules to your firewall. One of the many wonders of UFW is the fact that rules are automatically saved when set, which is not true for iptables .","title":"UFW"},{"location":"setting-up/networking/#installation","text":"We'll need to install UFW and set it up. sudo apt-get install ufw sudo ufw default allow outgoing sudo ufw default deny incoming sudo ufw enable The commands should be pretty self-explanatory but, just in case, these default the firewall to allow any connections going from the server to the Internet and deny any incoming connections from the Internet to the server.","title":"Installation"},{"location":"setting-up/networking/#usage","text":"A very good command to check UFW 's status (if it's enabled or disabled) and see all the custom rules added and active is: sudo ufw status You can add a new rule by using: sudo ufw allow <PORT_RANGE>/<PROTOCOL>","title":"Usage"},{"location":"setting-up/networking/#ssh","text":"","title":"SSH"},{"location":"setting-up/networking/#installation_1","text":"Since the server will run in headless mode, it would be very useful to be able to access it remotely from within (and even outside) the network. We'll use OpenSSH , it is generally installed with the OS but in case that it isn't, you can install it by running: sudo apt-get install openssh-client openssh-server","title":"Installation"},{"location":"setting-up/networking/#setting-up","text":"We now need to allow SSH connections through the firewall so we can access the server. sudo ufw allow ssh","title":"Setting-up"},{"location":"setting-up/networking/#google-authentication-2fa","text":"Two Factor Authentication has become a must-have in terms of account security, almost all services out there have the option to add this security measure to ensure account security. Luckily, we can implement our own Two Factor Authentication to access the server through SSH .","title":"Google Authentication (2FA)"},{"location":"setting-up/networking/#installation_2","text":"To enable 2FA , we'll need to install the following package: sudo apt-get install libpam-google-authenticator","title":"Installation"},{"location":"setting-up/networking/#setting-up_1","text":"To set it up, simply run: google-authenticator When running this, you'll receive a secret key which is used to add your account manually to your phone's 2FA application. Alternatively, you also get a nicely printed QR code on the terminal window (which you may need to resize to see fully) that you can scan with your phone. You will also get some scratch codes that you should always keep somewhere safe, just in case you lose access to your phone or something happens, you can still login to your server. To continue, answer y to all the questions to set up 2FA with the default settings. We now need to enable 2FA on SSH , to do this, edit the following file: sudo nano /etc/ssh/sshd_config Look for the following lines and edit them accordingly: UsePAM yes ChallengeResponseAuthentication yes Save and close the editor and restart the SSH service. sudo systemctl restart ssh We now need to edit the PAM rule file: sudo nano /etc/pam.d/sshd At the end of the file, add the following line: auth required pam_google_authenticator.so Save and close the file.","title":"Setting-up"},{"location":"setting-up/networking/#testing","text":"In order to test that 2FA works properly, open up a new SSH session without closing the previous one and try logging in, you'll be prompted for your user password and for the 2FA code which is available on your phone. Info When using 2FA for SSH , all the users in the server will need to set-it up, otherwise they won't be able to access their accounts. In case you get locked out from one of these users, you can always login to a sudoer account (usually the admin one which is added when installing the OS) and force-login with: sudo -iu <user> .","title":"Testing"},{"location":"setting-up/os-installation/","text":"OS Installation \u00b6 The server will be running Ubuntu Server 20.04 LTS 64-bit in headless mode, meaning that no DE will be used. The installation is quick and assisted by its own install wizard. When asked what snapshot (initial server configuration) should be installed, simply choose none or default . As a general rule of thumb, after installing the OS it is recommended to update the sources ad packages: sudo apt-get update && sudo apt-get upgrade Configuring Date and Time \u00b6 By default, the OS will be installed with GMT+0 as the timezone. We'll change this to conform with our real timezone which is GMT-5 . sudo timedatectl set-timezone America/Guayaquil","title":"OS Installation"},{"location":"setting-up/os-installation/#os-installation","text":"The server will be running Ubuntu Server 20.04 LTS 64-bit in headless mode, meaning that no DE will be used. The installation is quick and assisted by its own install wizard. When asked what snapshot (initial server configuration) should be installed, simply choose none or default . As a general rule of thumb, after installing the OS it is recommended to update the sources ad packages: sudo apt-get update && sudo apt-get upgrade","title":"OS Installation"},{"location":"setting-up/os-installation/#configuring-date-and-time","text":"By default, the OS will be installed with GMT+0 as the timezone. We'll change this to conform with our real timezone which is GMT-5 . sudo timedatectl set-timezone America/Guayaquil","title":"Configuring Date and Time"},{"location":"setting-up/packages/","text":"Packages \u00b6 We'll install a handful of packages once we're done with the OS installation. Screen \u00b6 We'll also require screen which is a wonderful tool capable of improving multitasking on a single shell window with the ability to background processes. It also lets you recover shell windows when there's a connection loss. Installation \u00b6 Installing screen is as simple as running the following command: sudo apt-get install screen Usage \u00b6 At first it may seem a little complicated and maybe even intimidating to use this tool but once you get used to it you'll realize how useful it really is. First start up screen by typing: screen -S <socket name> Here's a table with the keys and actions you can use with screen : Keys Action Ctrl-a c Creates a new window. Ctrl-a n Switches between windows. Ctrl-a d Detaches from screen. Ctrl-a n Switches between screens. To reattach to a screen : screen -r <screen pid> or, screen -rd <screen socket name> The Rest \u00b6 Install the rest of the packages with the following: sudo apt-get install net-tools neofetch nload","title":"Packages"},{"location":"setting-up/packages/#packages","text":"We'll install a handful of packages once we're done with the OS installation.","title":"Packages"},{"location":"setting-up/packages/#screen","text":"We'll also require screen which is a wonderful tool capable of improving multitasking on a single shell window with the ability to background processes. It also lets you recover shell windows when there's a connection loss.","title":"Screen"},{"location":"setting-up/packages/#installation","text":"Installing screen is as simple as running the following command: sudo apt-get install screen","title":"Installation"},{"location":"setting-up/packages/#usage","text":"At first it may seem a little complicated and maybe even intimidating to use this tool but once you get used to it you'll realize how useful it really is. First start up screen by typing: screen -S <socket name> Here's a table with the keys and actions you can use with screen : Keys Action Ctrl-a c Creates a new window. Ctrl-a n Switches between windows. Ctrl-a d Detaches from screen. Ctrl-a n Switches between screens. To reattach to a screen : screen -r <screen pid> or, screen -rd <screen socket name>","title":"Usage"},{"location":"setting-up/packages/#the-rest","text":"Install the rest of the packages with the following: sudo apt-get install net-tools neofetch nload","title":"The Rest"}]}