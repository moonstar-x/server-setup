{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 This is a simple guide that focuses on the installation and configuration process of my little home server that runs multiple services for various purposes. The server now uses Docker for most of its services. This is an improved version of the previous server guide , some of the services from the previous version are present here, some are gone for good. Server Specs \u00b6 The server computer is a self-built desktop with the following specs: CPU : Intel Core i3-4170 (4 Threads) @3.70GHz RAM : 2x8GB DDR3 @1600MHz (16GB - Dual Channel) Motherboard : Biostar H81MHV3 Storage : 256GB Crucial BX500 SATA SSD 2TB WD Green 5400RPM SATA HDD 4TB WD Elements USB 3.0 HDD 4TB Toshiba USB 3.0 HDD 8TB Seagate USB 3.0 HDD","title":"Home"},{"location":"#introduction","text":"This is a simple guide that focuses on the installation and configuration process of my little home server that runs multiple services for various purposes. The server now uses Docker for most of its services. This is an improved version of the previous server guide , some of the services from the previous version are present here, some are gone for good.","title":"Introduction"},{"location":"#server-specs","text":"The server computer is a self-built desktop with the following specs: CPU : Intel Core i3-4170 (4 Threads) @3.70GHz RAM : 2x8GB DDR3 @1600MHz (16GB - Dual Channel) Motherboard : Biostar H81MHV3 Storage : 256GB Crucial BX500 SATA SSD 2TB WD Green 5400RPM SATA HDD 4TB WD Elements USB 3.0 HDD 4TB Toshiba USB 3.0 HDD 8TB Seagate USB 3.0 HDD","title":"Server Specs"},{"location":"deprecated/automation/","text":"Information \u00b6 The following section contains all the automation related deprecated services. To see the current automation services, head over to the Automation Section .","title":"Information"},{"location":"deprecated/automation/#information","text":"The following section contains all the automation related deprecated services. To see the current automation services, head over to the Automation Section .","title":"Information"},{"location":"deprecated/automation/n8n/","text":"n8n \u00b6 Deprecation Warning This service was deprecated on the server in favor of my own automation service . There is nothing wrong with this service, I just wanted a solution that would give me a bit more control and that would be easier to maintain. n8n is a self-hosted node based automation to run run jobs based on triggers similarly to IFTTT. There is an official image for n8n on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/automation/n8n Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : n8n : image : n8nio/n8n:latest restart : unless-stopped volumes : - ./data:/home/node/.n8n - ./local-files:/home/node/local-files ports : - 5678:5678 environment : - TZ=America/Guayaquil - N8N_BASIC_AUTH_ACTIVE=true - N8N_BASIC_AUTH_USER=CHANGE_THIS - N8N_BASIC_AUTH_PASSWORD=CHANGE_THIS - WEBHOOK_URL=https://example.com mongo : image : mongo:latest restart : unless-stopped ports : - 56787:27017 volumes : - ./mongo-data:/data/db environment : - MONGO_INITDB_ROOT_USERNAME=CHANGE_THIS - MONGO_INITDB_ROOT_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value. The local-files volume for n8n will serve as a way to load binary files from the filesystem in our workflows. We also need a database for workflows that require data persistence, in this case we've chosen mongo but any database that is supported by n8n can work just fine. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 5678 /tcp sudo ufw allow 56787 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"n8n"},{"location":"deprecated/automation/n8n/#n8n","text":"Deprecation Warning This service was deprecated on the server in favor of my own automation service . There is nothing wrong with this service, I just wanted a solution that would give me a bit more control and that would be easier to maintain. n8n is a self-hosted node based automation to run run jobs based on triggers similarly to IFTTT. There is an official image for n8n on Docker Hub which we'll use.","title":"n8n"},{"location":"deprecated/automation/n8n/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/automation/n8n","title":"Pre-Installation"},{"location":"deprecated/automation/n8n/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : n8n : image : n8nio/n8n:latest restart : unless-stopped volumes : - ./data:/home/node/.n8n - ./local-files:/home/node/local-files ports : - 5678:5678 environment : - TZ=America/Guayaquil - N8N_BASIC_AUTH_ACTIVE=true - N8N_BASIC_AUTH_USER=CHANGE_THIS - N8N_BASIC_AUTH_PASSWORD=CHANGE_THIS - WEBHOOK_URL=https://example.com mongo : image : mongo:latest restart : unless-stopped ports : - 56787:27017 volumes : - ./mongo-data:/data/db environment : - MONGO_INITDB_ROOT_USERNAME=CHANGE_THIS - MONGO_INITDB_ROOT_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value. The local-files volume for n8n will serve as a way to load binary files from the filesystem in our workflows. We also need a database for workflows that require data persistence, in this case we've chosen mongo but any database that is supported by n8n can work just fine.","title":"Docker Compose"},{"location":"deprecated/automation/n8n/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 5678 /tcp sudo ufw allow 56787 /tcp","title":"Post-Installation"},{"location":"deprecated/automation/n8n/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"deprecated/data/","text":"Information \u00b6 The following section contains all the data related deprecated services. To see the current data services, head over to the Data Section .","title":"Information"},{"location":"deprecated/data/#information","text":"The following section contains all the data related deprecated services. To see the current data services, head over to the Data Section .","title":"Information"},{"location":"deprecated/data/drone/","text":"Drone \u00b6 Deprecation Warning This service has been deprecated in favor of Jenkins . Warning This service requires Gitea , you must set that up before continuing with this one. Drone is a self-hosted CI/CD pipeline service that can be used with Gitea . This service has an official image on Docker Hub which we'll use. Pre-Requisites \u00b6 Gitea OAuth2 Token \u00b6 First, we'll need to log into our Gitea instance and then head over to the Settings page and click on the Applications tab. In here, create a new OAuth2 application. You can choose whatever name you want but the Redirect URI should be: https://ci.example.com/login Note Replace ci.example.com with the actual domain where your Drone instance will be hosted in. Once you've done this, you'll need to keep the Client ID and Client Secret generated, which will be necessary for the Docker Compose file. Shared Secret \u00b6 You will also need a shared secret which will be necessary to link your runners to the main Drone service. You can generate a random secret by running the following command anywhere: openssl rand -hex 16 Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/drone Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : drone : image : drone/drone:latest restart : unless-stopped ports : - 3080:80 volumes : - ./data:/data environment : - TZ=America/Guayaquil - DRONE_GITEA_SERVER=https://ci.example.com - DRONE_GITEA_CLIENT_ID=OAUTH_CLIENT_ID - DRONE_GITEA_CLIENT_SECRET=OAUTH_CLIENT_SECRET - DRONE_RPC_SECRET=SHARED_SECRET - DRONE_SERVER_HOST=ci.example.com - DRONE_SERVER_PROTO=https - DRONE_REGISTRATION_CLOSED=true runner : image : drone/drone-runner-docker:latest restart : unless-stopped depends_on : - drone ports : - 3100:3000 volumes : - /var/run/docker.sock:/var/run/docker.sock environment : - TZ=America/Guayaquil - DRONE_RPC_PROTO=http - DRONE_RPC_HOST=drone - DRONE_RPC_SECRET=SHARED_SECRET - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NAME=local-runner Note Make sure to replace the following values: ci.example.com with the domain where your Drone instance will be hosted. OAUTH_CLIENT_ID with the client ID generated previously. OAUTH_CLIENT_SECRET with the client secret generated previously. SHARED_SECRET with the shared secret generated previously. You may also replace https with http in the drone service in DRONE_GITEA_SERVER and DRONE_SERVER_PROTO to host the service over HTTP. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3080 /tcp sudo ufw allow 3100 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Drone"},{"location":"deprecated/data/drone/#drone","text":"Deprecation Warning This service has been deprecated in favor of Jenkins . Warning This service requires Gitea , you must set that up before continuing with this one. Drone is a self-hosted CI/CD pipeline service that can be used with Gitea . This service has an official image on Docker Hub which we'll use.","title":"Drone"},{"location":"deprecated/data/drone/#pre-requisites","text":"","title":"Pre-Requisites"},{"location":"deprecated/data/drone/#gitea-oauth2-token","text":"First, we'll need to log into our Gitea instance and then head over to the Settings page and click on the Applications tab. In here, create a new OAuth2 application. You can choose whatever name you want but the Redirect URI should be: https://ci.example.com/login Note Replace ci.example.com with the actual domain where your Drone instance will be hosted in. Once you've done this, you'll need to keep the Client ID and Client Secret generated, which will be necessary for the Docker Compose file.","title":"Gitea OAuth2 Token"},{"location":"deprecated/data/drone/#shared-secret","text":"You will also need a shared secret which will be necessary to link your runners to the main Drone service. You can generate a random secret by running the following command anywhere: openssl rand -hex 16","title":"Shared Secret"},{"location":"deprecated/data/drone/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/drone","title":"Pre-Installation"},{"location":"deprecated/data/drone/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : drone : image : drone/drone:latest restart : unless-stopped ports : - 3080:80 volumes : - ./data:/data environment : - TZ=America/Guayaquil - DRONE_GITEA_SERVER=https://ci.example.com - DRONE_GITEA_CLIENT_ID=OAUTH_CLIENT_ID - DRONE_GITEA_CLIENT_SECRET=OAUTH_CLIENT_SECRET - DRONE_RPC_SECRET=SHARED_SECRET - DRONE_SERVER_HOST=ci.example.com - DRONE_SERVER_PROTO=https - DRONE_REGISTRATION_CLOSED=true runner : image : drone/drone-runner-docker:latest restart : unless-stopped depends_on : - drone ports : - 3100:3000 volumes : - /var/run/docker.sock:/var/run/docker.sock environment : - TZ=America/Guayaquil - DRONE_RPC_PROTO=http - DRONE_RPC_HOST=drone - DRONE_RPC_SECRET=SHARED_SECRET - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NAME=local-runner Note Make sure to replace the following values: ci.example.com with the domain where your Drone instance will be hosted. OAUTH_CLIENT_ID with the client ID generated previously. OAUTH_CLIENT_SECRET with the client secret generated previously. SHARED_SECRET with the shared secret generated previously. You may also replace https with http in the drone service in DRONE_GITEA_SERVER and DRONE_SERVER_PROTO to host the service over HTTP.","title":"Docker Compose"},{"location":"deprecated/data/drone/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3080 /tcp sudo ufw allow 3100 /tcp","title":"Post-Installation"},{"location":"deprecated/data/drone/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"deprecated/data/nexus/","text":"Nexus \u00b6 Deprecation Warning This service has been deprecated in favor of Gitea 's Package Registry . Nexus is an artifact repository that supports various types of formats, including Docker images and NPM packages. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/nexus Docker Compose \u00b6 Nexus will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : nexus : image : sonatype/nexus3:latest restart : unless-stopped user : 1000:1000 volumes : - ./data:/nexus-data ports : - 10600:8081 - 10610:10610 - 10620:10620 environment : - TZ=America/Guayaquil Post-Installation \u00b6 To avoid permission issues, create the data folder that will be used as a volume: mkdir data We'll need to allow the service's port on our firewall. sudo ufw allow 10600 /tcp sudo ufw allow 10610 /tcp sudo ufw allow 10620 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure. Configuration \u00b6 Follow the following guidelines to configure the registry dashboard. Creating an Admin Account \u00b6 Inside the stack's folder, run the following command: cat data/admin.password This will print a random string that will be the first administrator's password. Now, visit the registry's dashboard at: http://localhost:10600 And login with the admin username and the password recovered previously. Setting Up Blob Storage \u00b6 It is preferable to have a blob storage for each repository. Since we'll have NPM and Docker registries, we'll create a blob storage for each one of them. Create 2 blob storages with the docker and npm names and remove the default blob storage. Setting Up Repositories \u00b6 Remove the base repositories included. Now, create the following repositories: Docker Registry Type: Docker (hosted) Name: docker HTTP Connector: 10610 Blob Store: docker Deployment Policy: Allow redeploy NPM Registry Type: NPM (hosted) Name: npm HTTP Connector: 10620 Blob Store: npm Deployment Policy: Allow redeploy Create Some Roles \u00b6 We'll create some roles to create limited users to use with the registry. Create the following roles: Docker Role Role ID: custom-docker Role Name: custom-docker Role Description: Allow Docker operations. Privileges: nx-repository-view-docker-*-* NPM Role Role ID: custom-npm Role Name: custom-npm Role Description: Allow NPM operations. Privileges: nx-repository-view-npm-*-* Create Some users \u00b6 It is recommended to create a new administrator user and remove the default one. Now, create an user that you'll use for each of the registries created and give it only access to the corresponding role that was created previously for each of the registries. For example, create a user user-docker that has only access to the custom-docker role. Now you can use this user to login with Docker with the command: docker login Note As a last recommendation, create additional users with limited roles to use with any CI system.","title":"Nexus"},{"location":"deprecated/data/nexus/#nexus","text":"Deprecation Warning This service has been deprecated in favor of Gitea 's Package Registry . Nexus is an artifact repository that supports various types of formats, including Docker images and NPM packages. This service has an official image available on Docker Hub which we'll use.","title":"Nexus"},{"location":"deprecated/data/nexus/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/nexus","title":"Pre-Installation"},{"location":"deprecated/data/nexus/#docker-compose","text":"Nexus will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : nexus : image : sonatype/nexus3:latest restart : unless-stopped user : 1000:1000 volumes : - ./data:/nexus-data ports : - 10600:8081 - 10610:10610 - 10620:10620 environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"deprecated/data/nexus/#post-installation","text":"To avoid permission issues, create the data folder that will be used as a volume: mkdir data We'll need to allow the service's port on our firewall. sudo ufw allow 10600 /tcp sudo ufw allow 10610 /tcp sudo ufw allow 10620 /tcp","title":"Post-Installation"},{"location":"deprecated/data/nexus/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"deprecated/data/nexus/#configuration","text":"Follow the following guidelines to configure the registry dashboard.","title":"Configuration"},{"location":"deprecated/data/nexus/#creating-an-admin-account","text":"Inside the stack's folder, run the following command: cat data/admin.password This will print a random string that will be the first administrator's password. Now, visit the registry's dashboard at: http://localhost:10600 And login with the admin username and the password recovered previously.","title":"Creating an Admin Account"},{"location":"deprecated/data/nexus/#setting-up-blob-storage","text":"It is preferable to have a blob storage for each repository. Since we'll have NPM and Docker registries, we'll create a blob storage for each one of them. Create 2 blob storages with the docker and npm names and remove the default blob storage.","title":"Setting Up Blob Storage"},{"location":"deprecated/data/nexus/#setting-up-repositories","text":"Remove the base repositories included. Now, create the following repositories: Docker Registry Type: Docker (hosted) Name: docker HTTP Connector: 10610 Blob Store: docker Deployment Policy: Allow redeploy NPM Registry Type: NPM (hosted) Name: npm HTTP Connector: 10620 Blob Store: npm Deployment Policy: Allow redeploy","title":"Setting Up Repositories"},{"location":"deprecated/data/nexus/#create-some-roles","text":"We'll create some roles to create limited users to use with the registry. Create the following roles: Docker Role Role ID: custom-docker Role Name: custom-docker Role Description: Allow Docker operations. Privileges: nx-repository-view-docker-*-* NPM Role Role ID: custom-npm Role Name: custom-npm Role Description: Allow NPM operations. Privileges: nx-repository-view-npm-*-*","title":"Create Some Roles"},{"location":"deprecated/data/nexus/#create-some-users","text":"It is recommended to create a new administrator user and remove the default one. Now, create an user that you'll use for each of the registries created and give it only access to the corresponding role that was created previously for each of the registries. For example, create a user user-docker that has only access to the custom-docker role. Now you can use this user to login with Docker with the command: docker login Note As a last recommendation, create additional users with limited roles to use with any CI system.","title":"Create Some users"},{"location":"deprecated/media/","text":"Information \u00b6 The following section contains all the media related deprecated services. To see the current media services, head over to the Media Section .","title":"Information"},{"location":"deprecated/media/#information","text":"The following section contains all the media related deprecated services. To see the current media services, head over to the Media Section .","title":"Information"},{"location":"deprecated/media/miniflux/","text":"Miniflux \u00b6 Deprecation Warning This service was deprecated on the server in favor of FreshRSS for its better web interface and third-party app support. Miniflux is an RSS feed reader. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/miniflux Docker Compose \u00b6 Miniflux will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : miniflux : image : miniflux/miniflux:latest restart : unless-stopped ports : - 5190:8080 environment : - TZ=America/Guayaquil - DATABASE_URL=postgres://miniflux:CHANGE_THIS@db/miniflux?sslmode=disable - RUN_MIGRATIONS=1 - CREATE_ADMIN=1 - ADMIN_USERNAME=CHANGE_THIS - ADMIN_PASSWORD=CHANGE_THIS db : image : postgres:13.7 volumes : - ./data:/var/lib/postgresql/data environment : - POSTGRES_USER=miniflux - POSTGRES_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 5190 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Miniflux"},{"location":"deprecated/media/miniflux/#miniflux","text":"Deprecation Warning This service was deprecated on the server in favor of FreshRSS for its better web interface and third-party app support. Miniflux is an RSS feed reader. This service has an official image available on Docker Hub which we'll use.","title":"Miniflux"},{"location":"deprecated/media/miniflux/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/miniflux","title":"Pre-Installation"},{"location":"deprecated/media/miniflux/#docker-compose","text":"Miniflux will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : miniflux : image : miniflux/miniflux:latest restart : unless-stopped ports : - 5190:8080 environment : - TZ=America/Guayaquil - DATABASE_URL=postgres://miniflux:CHANGE_THIS@db/miniflux?sslmode=disable - RUN_MIGRATIONS=1 - CREATE_ADMIN=1 - ADMIN_USERNAME=CHANGE_THIS - ADMIN_PASSWORD=CHANGE_THIS db : image : postgres:13.7 volumes : - ./data:/var/lib/postgresql/data environment : - POSTGRES_USER=miniflux - POSTGRES_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"deprecated/media/miniflux/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 5190 /tcp","title":"Post-Installation"},{"location":"deprecated/media/miniflux/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/","text":"Initialization \u00b6 All the bots inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the bots, we'll create a folder on the main user's home folder dedicated to Discord bots. mkdir ~/discord For each bot created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"discord-bots/#initialization","text":"All the bots inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the bots, we'll create a folder on the main user's home folder dedicated to Discord bots. mkdir ~/discord For each bot created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"discord-bots/free-games-notifier/","text":"Free Games Notifier \u00b6 discord-free-games-notifier is a bot that notifies a channel whenever there's a free game on Steam or Epic Games. This bot has an image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-free-games-notifier Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-free-games-notifier:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - DISCORD_PREFIX=! - DISCORD_OWNER_ID=<OWNER_ID_HERE> - TZ=America/Guayaquil Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Free Games Notifier"},{"location":"discord-bots/free-games-notifier/#free-games-notifier","text":"discord-free-games-notifier is a bot that notifies a channel whenever there's a free game on Steam or Epic Games. This bot has an image available on Docker Hub which we'll use.","title":"Free Games Notifier"},{"location":"discord-bots/free-games-notifier/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-free-games-notifier","title":"Pre-Installation"},{"location":"discord-bots/free-games-notifier/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-free-games-notifier:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - DISCORD_PREFIX=! - DISCORD_OWNER_ID=<OWNER_ID_HERE> - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"discord-bots/free-games-notifier/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/jda-music-bot/","text":"JDA Music Bot \u00b6 jagrosh's MusicBot is a very powerful music bot written in Java with JDA. This bot does not have an official Docker image so we'll create a Dockerfile for this one. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/jda-music-bot We'll also need to download the latest version of the jar from here which will be downloaded inside an app folder where all the bot's data will be stored. cd ~/discord/jda-music-bot && mkdir app && cd app wget https://github.com/jagrosh/MusicBot/releases/download/0.3.4/JMusicBot-0.3.4.jar mv JMusicBot-0.3.4.jar JMusicBot.jar Now, we should have a JMusicBot.jar file inside of ~/discord/jda-music-bot/app . Configuration \u00b6 This bot requires its configuration to be saved in a text file. We'll create a file called config.txt with: nano ~/discord/jda-music-bot/app/config.txt And its content should be as follows: token=<DISCORD_TOKEN_HERE> owner=<OWNER_ID_HERE> prefix=% game=\"DEFAULT\" status=ONLINE songinstatus=true altprefix=\"NONE\" stayinchannel=true maxtime=0 updatealerts=false Dockerfile \u00b6 Since the bot does not have an official Docker image, we'll create a Dockerfile to run any java jar file through volumes. The content of the Dockerfile file is as follows: FROM openjdk:8 WORKDIR /opt/app VOLUME /opt/app CMD [ \"java\" , \"-Dnogui=true\" , \"-jar\" , \"JMusicBot.jar\" ] Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : build : . restart : unless-stopped network_mode : host volumes : - ./app:/opt/app environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"JDA Music Bot"},{"location":"discord-bots/jda-music-bot/#jda-music-bot","text":"jagrosh's MusicBot is a very powerful music bot written in Java with JDA. This bot does not have an official Docker image so we'll create a Dockerfile for this one.","title":"JDA Music Bot"},{"location":"discord-bots/jda-music-bot/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/jda-music-bot We'll also need to download the latest version of the jar from here which will be downloaded inside an app folder where all the bot's data will be stored. cd ~/discord/jda-music-bot && mkdir app && cd app wget https://github.com/jagrosh/MusicBot/releases/download/0.3.4/JMusicBot-0.3.4.jar mv JMusicBot-0.3.4.jar JMusicBot.jar Now, we should have a JMusicBot.jar file inside of ~/discord/jda-music-bot/app .","title":"Pre-Installation"},{"location":"discord-bots/jda-music-bot/#configuration","text":"This bot requires its configuration to be saved in a text file. We'll create a file called config.txt with: nano ~/discord/jda-music-bot/app/config.txt And its content should be as follows: token=<DISCORD_TOKEN_HERE> owner=<OWNER_ID_HERE> prefix=% game=\"DEFAULT\" status=ONLINE songinstatus=true altprefix=\"NONE\" stayinchannel=true maxtime=0 updatealerts=false","title":"Configuration"},{"location":"discord-bots/jda-music-bot/#dockerfile","text":"Since the bot does not have an official Docker image, we'll create a Dockerfile to run any java jar file through volumes. The content of the Dockerfile file is as follows: FROM openjdk:8 WORKDIR /opt/app VOLUME /opt/app CMD [ \"java\" , \"-Dnogui=true\" , \"-jar\" , \"JMusicBot.jar\" ]","title":"Dockerfile"},{"location":"discord-bots/jda-music-bot/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : build : . restart : unless-stopped network_mode : host volumes : - ./app:/opt/app environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build","title":"Docker Compose"},{"location":"discord-bots/jda-music-bot/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/music-24-7/","text":"Music 24/7 Bot \u00b6 discord-music-24-7 is a music bot with auto-pause capabilities that pauses the music playback when nobody is in the channel. It can play music from YouTube, SoundCloud and local files. This bot has an image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-music-24-7 Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-music-24-7:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - DISCORD_PREFIX=s! - DISCORD_CHANNEL_ID=<CHANNEL_ID_HERE> - DISCORD_OWNER_ID=<OWNER_ID_HERE> - TZ=America/Guayaquil Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Music 24/7 Bot"},{"location":"discord-bots/music-24-7/#music-247-bot","text":"discord-music-24-7 is a music bot with auto-pause capabilities that pauses the music playback when nobody is in the channel. It can play music from YouTube, SoundCloud and local files. This bot has an image available on Docker Hub which we'll use.","title":"Music 24/7 Bot"},{"location":"discord-bots/music-24-7/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-music-24-7","title":"Pre-Installation"},{"location":"discord-bots/music-24-7/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : bot : image : moonstarx/discord-music-24-7:latest restart : unless-stopped network_mode : host volumes : - ./data:/opt/app/data environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - DISCORD_PREFIX=s! - DISCORD_CHANNEL_ID=<CHANNEL_ID_HERE> - DISCORD_OWNER_ID=<OWNER_ID_HERE> - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"discord-bots/music-24-7/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"discord-bots/tts-bot/","text":"Text-to-Speech Bot \u00b6 discord-tts-bot is a bot that uses the Google Translate API to utter the messages you send to the bot in any language. This bot has an image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-tts-bot Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : redis : image : redis:latest restart : unless-stopped ports : - 60000:6379 volumes : - ./data:/data environment : - TZ=America/Guayaquil command : redis-server --save 60 1 --loglevel warning bot : image : moonstarx/discord-tts-bot:latest restart : unless-stopped depends_on : - redis environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - DISCORD_OWNER_ID=<OWNER_ID_HERE> - DISCORD_DEFAULT_DISCONNECT_TIMEOUT=10 - DISCORD_PROVIDER_TYPE=redis - DISCORD_REDIS_URL=redis://redis:6379 - TZ=America/Guayaquil Running \u00b6 Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Text-to-Speech Bot"},{"location":"discord-bots/tts-bot/#text-to-speech-bot","text":"discord-tts-bot is a bot that uses the Google Translate API to utter the messages you send to the bot in any language. This bot has an image available on Docker Hub which we'll use.","title":"Text-to-Speech Bot"},{"location":"discord-bots/tts-bot/#pre-installation","text":"We'll create a folder in the main user's home where all the bot's data will be saved. mkdir ~/discord/discord-tts-bot","title":"Pre-Installation"},{"location":"discord-bots/tts-bot/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : redis : image : redis:latest restart : unless-stopped ports : - 60000:6379 volumes : - ./data:/data environment : - TZ=America/Guayaquil command : redis-server --save 60 1 --loglevel warning bot : image : moonstarx/discord-tts-bot:latest restart : unless-stopped depends_on : - redis environment : - DISCORD_TOKEN=<DISCORD_TOKEN_HERE> - DISCORD_OWNER_ID=<OWNER_ID_HERE> - DISCORD_DEFAULT_DISCONNECT_TIMEOUT=10 - DISCORD_PROVIDER_TYPE=redis - DISCORD_REDIS_URL=redis://redis:6379 - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"discord-bots/tts-bot/#running","text":"Start up the bot with: docker-compose up -d That's it! The bot will auto-start on system startup and restart on failure.","title":"Running"},{"location":"games/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to game servers and related services. mkdir ~/games For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"games/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to game servers and related services. mkdir ~/games For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"games/arma3/","text":"Arma 3 (Native) \u00b6 Arma 3 is an excellent military simulation game. I haven't been able to find any Docker image for this server that is maintained and does not require to disable Steam Guard from your account. For this reason, this server will be installed natively. User Creation \u00b6 For this server, we'll create a separate user where all the server data will be located. sudo adduser --disabled-login arma Note For future reference, you may switch to this user by running sudo -iu arma . Dependencies \u00b6 The Arma 3 server requires some dependencies that we'll install: sudo apt-get install lib32gcc1 lib32stdc++6 Installing SteamCMD \u00b6 SteamCMD is a headless Steam client that is generally used to download dedicated servers. We'll need this in order to install the Arma 3 server. First, let's switch to the arma user: sudo -iu arma We'll also create a folder named steamcmd : mkdir steamcmd && cd steamcmd Then, download and extract SteamCMD: wget https://steamcdn-a.akamaihd.net/client/installer/steamcmd_linux.tar.gz tar zxvf steamcmd_linux.tar.gz && rm steamcmd_linux.tar.gz Once this is done, you may execute steamcmd for the first time so that all its data can be downloaded. ./steamcmd Installing Arma 3 Server \u00b6 In order to install the server, start up steamcmd then run the following commands: login <username> force_install_dir /home/arma/arma3 app_update 233780 Note Replace <username> with your Steam username. Once you run the login command, steamcmd will ask for your password and your Steam Guard code. Mods \u00b6 Setting Up Case Insensitive On Purpose (ciopfs) \u00b6 On a Linux based installation, Arma 3 modding becomes a bit complicated because of the Unix filesystem's case sensitivity, which renders mods with capital letters in their filenames unusable. Luckily, we can fix this with a nice package called ciopfs . As a sudoer account (not arma ), run: sudo apt-get install ciopfs Switch back to the arma user. We'll create the folders for the mods and run ciopfs on them: mkdir arma3mods arma3mods_ciopfs ciopfs arma3mods arma3mods_ciopfs What this does is mount the commands of arma3mods in arma3mods_ciopfs in a case insensitive fashion. This means that new content should be added to the arma3mods_ciopfs folder, this will make the arma3mods folder contain the corresponding data with case insensitivity. The issue with this is that this change will be undone on system restart. For this reason, we'll create a service to run this on system start. As a sudoer account, run: sudo nano /etc/systemd/system/arma3ciopfs.service And paste the following: Description=Arma 3 ciopfs mount. Wants=network.target After=syslog.target network-online.target [Service] Type=simple User=arma ExecStart=/usr/bin/ciopfs /home/arma/arma3mods /home/arma/arma3mods_ciopfs Restart=on-failure RestartSec=10 KillMode=process [Install] WantedBy=multi-user.target Finally, enable the service: sudo systemctl enable arma3ciopfs.service sudo systemctl start arma3ciopfs.service Installing Mods \u00b6 With the arma user, run steamcmd and run the following commands: login <username> force_install_dir /home/arma/arma3mods_ciopfs workshop_download_item 107410 <mod_id> Note You may need to re-run the last command a second time to make sure the mod does get downloaded. Once installed, we'll need to create symlinks from the mod folders to the Arma 3 server directory. For this, run the following command: ln -s ~/arma3mods/steamapps/workshop/content/107410/<mod_id> ~/arma3/@<mod_name> As an example, for the CBA_A3 mod: ln -s ~/arma3mods/steamapps/workshop/content/107410/450814997 ~/arma3/@CBA_A3 Finally, we'll also need to copy the keys for each mod into the keys folder inside the server directory. Mod keys will be in ~/arma3mods/steamapps/workshop/content/107410/<mod_id>/keys (sometimes the last folder will be key rather than keys ). These keys will have a .bikey extension and will need to copied to ~/arma3/keys . Note Every time a mod gets updated, you need to replace the old keys with the new ones. Mods List \u00b6 Here's a small list of the mods that I currently use: Workshop ID Addon Name Symlink Name 463939057 ACE @ACE 450814997 CBA_A3 @CBA_A3 621650475 CUP ACE3 Compatibility Addon - Vehicles @CUP_ACE_compat_vehicles 549676314 CUP ACE3 Compatibility Addon - Weapons @CUP_ACE_compat_weapons 583496184 CUP Terrains - Core @CUP_Core 853743366 CUP Terrains - CWA @CUP_CWA 583544987 CUP Terrains - Maps @CUP_Maps 497661914 CUP Units @CUP_Units 541888371 CUP Vehicles @CUP_Vehicles 497660133 CUP Weapons @CUP_Weapons 333310405 Enhanced Movement @Enhanced_Movement 843425103 RHSAFRF @RHSAFRF 843593391 RHSGREF @RHSGREF 843632231 RHSSAF @RHSSAF 843577117 RHSUSAF @RHSUSAF 498740884 ShackTac User Interface @ShackTac_UI 620019431 TaskForce Arrowhead Radio @task_force_radio 501966277 Zombies and Demons @Zombies_and_Demons Infinite Loading Screen Bug \u00b6 Unfortunately, the Linux Arma 3 server can be a bit buggy, this is the case for servers that run certain mod combinations (in this case CUP and RHS) that will make clients get stuck on an infinite loading screen when joining the server, the server console will not display any error messages and will in fact freeze the process. It seems the only way to fix this issue is to disable BattlEye from the server configs. In the server config, change the following: BattlEye = 0; This will in fact turn off BattlEye on your server which will make it less secure against hackers, sadly it is the only fix for this weird problem. Configuration \u00b6 Server Profile \u00b6 Arma 3 uses profile files to define difficulty settings and vars. We'll need to first create the corresponding folder, run: mkdir -p ~/ \".local/share/Arma 3\" && mkdir -p ~/ \".local/share/Arma 3 - Other Profiles\" cd ~/.local/share/Arma \\ 3 \\ - \\ Other \\ Profiles/ && mkdir server && cd server Then, inside this folder, create a file named server.Arma3Profile with: nano server.Arma3Profile Inside, paste the following: version=1; blood=1; singleVoice=0; gamma=1; brightness=1; maxSamplesPlayed=96; activeKeys[]= { \"BIS_Dynamic Recon Ops - Chernarus Winter.Chernarus_winter_done\", \"BIS_creeping death.altis_done\", \"BIS_co10_Escape_CUP_RU_vs_BAF.Chernarus_done\", \"BIS_co10_Escape_RHS_RU_vs_US.Chernarus_done\", \"BIS_COOP1-6%20A%20Cabin%20in%20the%20Hills.chernarus_done\", \"BIS_co10_Escape_RHS_RU_vs_US.Takistan_done\" }; playedKeys[]={}; difficulty=\"Custom\"; class DifficultyPresets { class CustomDifficulty { displayName=\"Custom\"; optionDescription=\"Custom Difficulty\"; levelAI=\"AILevelMedium\"; class Options { reducedDamage=0; groupIndicators=2; friendlyTags=2; enemyTags=0; detectedMines=0; commands=2; waypoints=2; tacticalPing=1; weaponInfo=1; stanceIndicator=1; staminaBar=0; weaponCrosshair=0; visionAid=0; thirdPersonView=0; cameraShake=1; scoreTable=1; deathMessages=1; vonID=1; mapContent=0; autoReport=0; multipleSaves=1; }; aiLevelPreset=1; }; class CustomAILevel { skillAI=0.5; precisionAI=0.5; }; }; sceneComplexity=400000; shadowZDistance=100; viewDistance=4000; preferredObjectViewDistance=1000; terrainGrid=25; vonRecThreshold=0.029999999; soundEnableEAX=1; soundEnableHW=0; volumeCD=10; volumeFX=10; volumeSpeech=10; volumeVoN=10; volumeMapDucking=1; Server Config \u00b6 Now, we'll go to the folder where we installed Arma 3 and create a config file with whatever name you wish: cd ~/arma3 nano modded.cfg You can paste the following config and change it or use whichever you want: steamPort = 2303; steamQueryPort = 2304; hostname = \"SERVER NAME\"; password = \"\"; passwordAdmin = \"SECRET\"; maxPlayers = 32; persistent = 0; disableVoN = 0; vonCodecQuality = 20; voteMissionPlayers = 1; voteThreshold = 0.66; allowedVoteCmds[] = { {\"admin\", false, false}, {\"kick\", false, true, 0.51}, {\"missions\", false, true}, {\"mission\", false, false}, {\"restart\", false, true}, {\"reassign\", false, false} }; timeStampFormat = \"short\"; logFile = \"server_console.log\"; BattlEye = 1; VerifySignatures = 2; kickDuplicate = 1; allowedFilePatching = 1; allowedLoadFileExtensions[] = {\"hpp\",\"sqs\",\"sqf\",\"fsm\",\"cpp\",\"paa\",\"txt\",\"xml\",\"inc\",\"ext\",\"sqm\",\"ods\",\"fxy\",\"lip\",\"csv\",\"kb\",\"bik\",\"bikb\",\"html\",\"htm\",\"biedi\"}; allowedPreprocessFileExtensions[] = {\"hpp\",\"sqs\",\"sqf\",\"fsm\",\"cpp\",\"paa\",\"txt\",\"xml\",\"inc\",\"ext\",\"sqm\",\"ods\",\"fxy\",\"lip\",\"csv\",\"kb\",\"bik\",\"bikb\",\"html\",\"htm\",\"biedi\"}; allowedHTMLLoadExtensions[] = {\"htm\",\"html\",\"php\",\"xml\",\"txt\"}; onUserConnected = \"\"; onUserDisconnected = \"\"; doubleIdDetected = \"\"; onUnsignedData = \"kick (_this select 0)\"; onHackeddData = \"kick (_this select 0)\"; headlessClients[] = {\"127.0.0.1\"}; localClient[] = {\"127.0.0.1\"}; As a side note, if you need to run servers with multiple configurations, you can always create more config files and use them at the server start. Custom Missions \u00b6 In order to run custom missions on your server, you'll need to add the .pbo files inside the mpmissions folder inside the Arma 3 server folder. You can get the .pbo files directly from Steam Workshop if you download the missions through this Workshop Downloader or from Armaholic . Firewall Rules \u00b6 Again, we'll need to add the following firewall rules: sudo ufw allow 2302:2345/tcp sudo ufw allow 2302:2345/udp Running the Server \u00b6 Now, to run the game, we'll create a small script so we can easily save the addons that we want to run and the configs that we want to load. Inside the Arma 3 server directory, create the script file (the filename with whatever you want): nano start_<name>.sh Inside the editor, paste the following: #!/bin/bash ./arma3server -name = <server_name> -config = <config_file> -mod = @mod1 \\; @mod2 \\; @mod3... Note server_name refers to the server name that you used for the Arma 3 Profile that is located in ~/.local/share/Arma 3 - Other Profiles , the config_file refers to the Arma 3 Config that is inside the Arma 3 directory, replace them with your own settings. An example for this script that runs ACE and CBA_A3. #!/bin/bash ./arma3server -name = server -config = modded.cfg -mod = @CBA_A3 \\; @ACE As per always, the script must be made executable: chmod +x <script_name>.sh Headless Client \u00b6 A headless client is an instance of the game with no interface. The idea of having a headless client on a server is to reduce the load on the server process by taking control of the AI processing. This will (ideally) make the server run better and the AI more responsive since their processing will be done somewhere else, their reaction times will be much quicker. Setting up a headless client is a trivial task. The first thing that should be done is modify the server config ( .cfg file) to allow our headless client. In server.cfg (or whichever it is the name of your .cfg file), add or edit the following lines with the IP address of your headless client: headlessClients[] = {\"127.0.0.1\"}; localClient[] = {\"127.0.0.1\"}; Note In this case, our headless client will be running in the same machine as the server, which means that 127.0.0.1 will be used. You can add as many of these as you want. Once the server config allows the headless client, we'll create a run script to start the headless client. #!/bin/bash ./arma3server -client -connect = SERVER_IP -password = SERVER_PASSWORD -mod = @MOD1 \\; @MOD2... Note You can omit the password directive if the server you're connecting to has no password. You can also omit the mod directive if the server has no mods. Finally, make the script executable: chmod +x start_hc.sh Now you're ready. Start the server and then the headless client, which will connect directly and automatically offload the AI processing (if the mission implements headless clients properly). Start Server and Headless Client Script \u00b6 If you wish to run them both directly, you can create the following script: #!/bin/bash echo \"Launching server...\" screen -dmS arma3-server /bin/bash -c \"./start_antistasi.sh\" echo \"Launching Headless Client...\" screen -dmS arma3-hc /bin/bash -c \"./hc_antistasi.sh\" Note Replace \"./start_antistasi.sh\" with the name of the server start script and \"./hc_antistasi.sh\" with the name of the headless client start script. This will start both processes in two different screen windows. You can switch to them by using: screen -rd arma3-server screen -rd arma3-hc","title":"Arma 3 (Native)"},{"location":"games/arma3/#arma-3-native","text":"Arma 3 is an excellent military simulation game. I haven't been able to find any Docker image for this server that is maintained and does not require to disable Steam Guard from your account. For this reason, this server will be installed natively.","title":"Arma 3 (Native)"},{"location":"games/arma3/#user-creation","text":"For this server, we'll create a separate user where all the server data will be located. sudo adduser --disabled-login arma Note For future reference, you may switch to this user by running sudo -iu arma .","title":"User Creation"},{"location":"games/arma3/#dependencies","text":"The Arma 3 server requires some dependencies that we'll install: sudo apt-get install lib32gcc1 lib32stdc++6","title":"Dependencies"},{"location":"games/arma3/#installing-steamcmd","text":"SteamCMD is a headless Steam client that is generally used to download dedicated servers. We'll need this in order to install the Arma 3 server. First, let's switch to the arma user: sudo -iu arma We'll also create a folder named steamcmd : mkdir steamcmd && cd steamcmd Then, download and extract SteamCMD: wget https://steamcdn-a.akamaihd.net/client/installer/steamcmd_linux.tar.gz tar zxvf steamcmd_linux.tar.gz && rm steamcmd_linux.tar.gz Once this is done, you may execute steamcmd for the first time so that all its data can be downloaded. ./steamcmd","title":"Installing SteamCMD"},{"location":"games/arma3/#installing-arma-3-server","text":"In order to install the server, start up steamcmd then run the following commands: login <username> force_install_dir /home/arma/arma3 app_update 233780 Note Replace <username> with your Steam username. Once you run the login command, steamcmd will ask for your password and your Steam Guard code.","title":"Installing Arma 3 Server"},{"location":"games/arma3/#mods","text":"","title":"Mods"},{"location":"games/arma3/#setting-up-case-insensitive-on-purpose-ciopfs","text":"On a Linux based installation, Arma 3 modding becomes a bit complicated because of the Unix filesystem's case sensitivity, which renders mods with capital letters in their filenames unusable. Luckily, we can fix this with a nice package called ciopfs . As a sudoer account (not arma ), run: sudo apt-get install ciopfs Switch back to the arma user. We'll create the folders for the mods and run ciopfs on them: mkdir arma3mods arma3mods_ciopfs ciopfs arma3mods arma3mods_ciopfs What this does is mount the commands of arma3mods in arma3mods_ciopfs in a case insensitive fashion. This means that new content should be added to the arma3mods_ciopfs folder, this will make the arma3mods folder contain the corresponding data with case insensitivity. The issue with this is that this change will be undone on system restart. For this reason, we'll create a service to run this on system start. As a sudoer account, run: sudo nano /etc/systemd/system/arma3ciopfs.service And paste the following: Description=Arma 3 ciopfs mount. Wants=network.target After=syslog.target network-online.target [Service] Type=simple User=arma ExecStart=/usr/bin/ciopfs /home/arma/arma3mods /home/arma/arma3mods_ciopfs Restart=on-failure RestartSec=10 KillMode=process [Install] WantedBy=multi-user.target Finally, enable the service: sudo systemctl enable arma3ciopfs.service sudo systemctl start arma3ciopfs.service","title":"Setting Up Case Insensitive On Purpose (ciopfs)"},{"location":"games/arma3/#installing-mods","text":"With the arma user, run steamcmd and run the following commands: login <username> force_install_dir /home/arma/arma3mods_ciopfs workshop_download_item 107410 <mod_id> Note You may need to re-run the last command a second time to make sure the mod does get downloaded. Once installed, we'll need to create symlinks from the mod folders to the Arma 3 server directory. For this, run the following command: ln -s ~/arma3mods/steamapps/workshop/content/107410/<mod_id> ~/arma3/@<mod_name> As an example, for the CBA_A3 mod: ln -s ~/arma3mods/steamapps/workshop/content/107410/450814997 ~/arma3/@CBA_A3 Finally, we'll also need to copy the keys for each mod into the keys folder inside the server directory. Mod keys will be in ~/arma3mods/steamapps/workshop/content/107410/<mod_id>/keys (sometimes the last folder will be key rather than keys ). These keys will have a .bikey extension and will need to copied to ~/arma3/keys . Note Every time a mod gets updated, you need to replace the old keys with the new ones.","title":"Installing Mods"},{"location":"games/arma3/#mods-list","text":"Here's a small list of the mods that I currently use: Workshop ID Addon Name Symlink Name 463939057 ACE @ACE 450814997 CBA_A3 @CBA_A3 621650475 CUP ACE3 Compatibility Addon - Vehicles @CUP_ACE_compat_vehicles 549676314 CUP ACE3 Compatibility Addon - Weapons @CUP_ACE_compat_weapons 583496184 CUP Terrains - Core @CUP_Core 853743366 CUP Terrains - CWA @CUP_CWA 583544987 CUP Terrains - Maps @CUP_Maps 497661914 CUP Units @CUP_Units 541888371 CUP Vehicles @CUP_Vehicles 497660133 CUP Weapons @CUP_Weapons 333310405 Enhanced Movement @Enhanced_Movement 843425103 RHSAFRF @RHSAFRF 843593391 RHSGREF @RHSGREF 843632231 RHSSAF @RHSSAF 843577117 RHSUSAF @RHSUSAF 498740884 ShackTac User Interface @ShackTac_UI 620019431 TaskForce Arrowhead Radio @task_force_radio 501966277 Zombies and Demons @Zombies_and_Demons","title":"Mods List"},{"location":"games/arma3/#infinite-loading-screen-bug","text":"Unfortunately, the Linux Arma 3 server can be a bit buggy, this is the case for servers that run certain mod combinations (in this case CUP and RHS) that will make clients get stuck on an infinite loading screen when joining the server, the server console will not display any error messages and will in fact freeze the process. It seems the only way to fix this issue is to disable BattlEye from the server configs. In the server config, change the following: BattlEye = 0; This will in fact turn off BattlEye on your server which will make it less secure against hackers, sadly it is the only fix for this weird problem.","title":"Infinite Loading Screen Bug"},{"location":"games/arma3/#configuration","text":"","title":"Configuration"},{"location":"games/arma3/#server-profile","text":"Arma 3 uses profile files to define difficulty settings and vars. We'll need to first create the corresponding folder, run: mkdir -p ~/ \".local/share/Arma 3\" && mkdir -p ~/ \".local/share/Arma 3 - Other Profiles\" cd ~/.local/share/Arma \\ 3 \\ - \\ Other \\ Profiles/ && mkdir server && cd server Then, inside this folder, create a file named server.Arma3Profile with: nano server.Arma3Profile Inside, paste the following: version=1; blood=1; singleVoice=0; gamma=1; brightness=1; maxSamplesPlayed=96; activeKeys[]= { \"BIS_Dynamic Recon Ops - Chernarus Winter.Chernarus_winter_done\", \"BIS_creeping death.altis_done\", \"BIS_co10_Escape_CUP_RU_vs_BAF.Chernarus_done\", \"BIS_co10_Escape_RHS_RU_vs_US.Chernarus_done\", \"BIS_COOP1-6%20A%20Cabin%20in%20the%20Hills.chernarus_done\", \"BIS_co10_Escape_RHS_RU_vs_US.Takistan_done\" }; playedKeys[]={}; difficulty=\"Custom\"; class DifficultyPresets { class CustomDifficulty { displayName=\"Custom\"; optionDescription=\"Custom Difficulty\"; levelAI=\"AILevelMedium\"; class Options { reducedDamage=0; groupIndicators=2; friendlyTags=2; enemyTags=0; detectedMines=0; commands=2; waypoints=2; tacticalPing=1; weaponInfo=1; stanceIndicator=1; staminaBar=0; weaponCrosshair=0; visionAid=0; thirdPersonView=0; cameraShake=1; scoreTable=1; deathMessages=1; vonID=1; mapContent=0; autoReport=0; multipleSaves=1; }; aiLevelPreset=1; }; class CustomAILevel { skillAI=0.5; precisionAI=0.5; }; }; sceneComplexity=400000; shadowZDistance=100; viewDistance=4000; preferredObjectViewDistance=1000; terrainGrid=25; vonRecThreshold=0.029999999; soundEnableEAX=1; soundEnableHW=0; volumeCD=10; volumeFX=10; volumeSpeech=10; volumeVoN=10; volumeMapDucking=1;","title":"Server Profile"},{"location":"games/arma3/#server-config","text":"Now, we'll go to the folder where we installed Arma 3 and create a config file with whatever name you wish: cd ~/arma3 nano modded.cfg You can paste the following config and change it or use whichever you want: steamPort = 2303; steamQueryPort = 2304; hostname = \"SERVER NAME\"; password = \"\"; passwordAdmin = \"SECRET\"; maxPlayers = 32; persistent = 0; disableVoN = 0; vonCodecQuality = 20; voteMissionPlayers = 1; voteThreshold = 0.66; allowedVoteCmds[] = { {\"admin\", false, false}, {\"kick\", false, true, 0.51}, {\"missions\", false, true}, {\"mission\", false, false}, {\"restart\", false, true}, {\"reassign\", false, false} }; timeStampFormat = \"short\"; logFile = \"server_console.log\"; BattlEye = 1; VerifySignatures = 2; kickDuplicate = 1; allowedFilePatching = 1; allowedLoadFileExtensions[] = {\"hpp\",\"sqs\",\"sqf\",\"fsm\",\"cpp\",\"paa\",\"txt\",\"xml\",\"inc\",\"ext\",\"sqm\",\"ods\",\"fxy\",\"lip\",\"csv\",\"kb\",\"bik\",\"bikb\",\"html\",\"htm\",\"biedi\"}; allowedPreprocessFileExtensions[] = {\"hpp\",\"sqs\",\"sqf\",\"fsm\",\"cpp\",\"paa\",\"txt\",\"xml\",\"inc\",\"ext\",\"sqm\",\"ods\",\"fxy\",\"lip\",\"csv\",\"kb\",\"bik\",\"bikb\",\"html\",\"htm\",\"biedi\"}; allowedHTMLLoadExtensions[] = {\"htm\",\"html\",\"php\",\"xml\",\"txt\"}; onUserConnected = \"\"; onUserDisconnected = \"\"; doubleIdDetected = \"\"; onUnsignedData = \"kick (_this select 0)\"; onHackeddData = \"kick (_this select 0)\"; headlessClients[] = {\"127.0.0.1\"}; localClient[] = {\"127.0.0.1\"}; As a side note, if you need to run servers with multiple configurations, you can always create more config files and use them at the server start.","title":"Server Config"},{"location":"games/arma3/#custom-missions","text":"In order to run custom missions on your server, you'll need to add the .pbo files inside the mpmissions folder inside the Arma 3 server folder. You can get the .pbo files directly from Steam Workshop if you download the missions through this Workshop Downloader or from Armaholic .","title":"Custom Missions"},{"location":"games/arma3/#firewall-rules","text":"Again, we'll need to add the following firewall rules: sudo ufw allow 2302:2345/tcp sudo ufw allow 2302:2345/udp","title":"Firewall Rules"},{"location":"games/arma3/#running-the-server","text":"Now, to run the game, we'll create a small script so we can easily save the addons that we want to run and the configs that we want to load. Inside the Arma 3 server directory, create the script file (the filename with whatever you want): nano start_<name>.sh Inside the editor, paste the following: #!/bin/bash ./arma3server -name = <server_name> -config = <config_file> -mod = @mod1 \\; @mod2 \\; @mod3... Note server_name refers to the server name that you used for the Arma 3 Profile that is located in ~/.local/share/Arma 3 - Other Profiles , the config_file refers to the Arma 3 Config that is inside the Arma 3 directory, replace them with your own settings. An example for this script that runs ACE and CBA_A3. #!/bin/bash ./arma3server -name = server -config = modded.cfg -mod = @CBA_A3 \\; @ACE As per always, the script must be made executable: chmod +x <script_name>.sh","title":"Running the Server"},{"location":"games/arma3/#headless-client","text":"A headless client is an instance of the game with no interface. The idea of having a headless client on a server is to reduce the load on the server process by taking control of the AI processing. This will (ideally) make the server run better and the AI more responsive since their processing will be done somewhere else, their reaction times will be much quicker. Setting up a headless client is a trivial task. The first thing that should be done is modify the server config ( .cfg file) to allow our headless client. In server.cfg (or whichever it is the name of your .cfg file), add or edit the following lines with the IP address of your headless client: headlessClients[] = {\"127.0.0.1\"}; localClient[] = {\"127.0.0.1\"}; Note In this case, our headless client will be running in the same machine as the server, which means that 127.0.0.1 will be used. You can add as many of these as you want. Once the server config allows the headless client, we'll create a run script to start the headless client. #!/bin/bash ./arma3server -client -connect = SERVER_IP -password = SERVER_PASSWORD -mod = @MOD1 \\; @MOD2... Note You can omit the password directive if the server you're connecting to has no password. You can also omit the mod directive if the server has no mods. Finally, make the script executable: chmod +x start_hc.sh Now you're ready. Start the server and then the headless client, which will connect directly and automatically offload the AI processing (if the mission implements headless clients properly).","title":"Headless Client"},{"location":"games/arma3/#start-server-and-headless-client-script","text":"If you wish to run them both directly, you can create the following script: #!/bin/bash echo \"Launching server...\" screen -dmS arma3-server /bin/bash -c \"./start_antistasi.sh\" echo \"Launching Headless Client...\" screen -dmS arma3-hc /bin/bash -c \"./hc_antistasi.sh\" Note Replace \"./start_antistasi.sh\" with the name of the server start script and \"./hc_antistasi.sh\" with the name of the headless client start script. This will start both processes in two different screen windows. You can switch to them by using: screen -rd arma3-server screen -rd arma3-hc","title":"Start Server and Headless Client Script"},{"location":"games/assettocorsa/","text":"Assetto Corsa \u00b6 Assetto Corsa is a realistic racing simulator. This game server has a community made server manager available on Docker Hub , however, I have made a small fork of this to update the source for SteamCMD since I've been having quite a lot of trouble getting it to work. This fork is available from GitHub Packages , which is the image we'll use for this. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the game server's data will be saved. mkdir ~/games/assettocorsa Docker Compose \u00b6 The game server will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : assettocorsa : image : ghcr.io/moonstar-x/assetto-server-manager:master restart : unless-stopped user : 1000:1000 ports : - 8772:8772 - 9600:9600 - 9600:9600/udp - 8081:8081 volumes : - ./server:/home/assetto/server-manager/assetto - ./data:/home/assetto/server-manager Warning Make sure to create the data and server folder before starting the container, otherwise you'll have some problems with the server data being saved. Configuration \u00b6 Create a config file inside data/config.yml : nano data/config.yml And paste the following: steam : username : STEAM_USER password : STEAM_PASS install_path : assetto executable_path : acServer force_update : false http : hostname : 0.0.0.0:8772 session_key : RANDOMLY_GENERATE_THIS server_manager_base_URL : session_store_type : cookie session_store_path : '' tls : enabled : false cert_path : '' key_path : '' monitoring : enabled : true store : type : boltdb path : server_manager.db shared_data_path : scheduled_event_check_loop : 0s accounts : admin_password_override : live_map : refresh_interval_ms : 500 server : audit_logging : true performance_mode : false dont_open_browser : false scan_content_folder_for_chanes : true use_car_name_cache : true persist_mid_session_results : false plugins : championships : recaptcha : site_key : secret_key : lua : enabled : false Note Make sure to replace STEAM_USER and STEAM_PASS with your steam account's information. I recommend you create a separate Steam account with Steam Guard disabled . You don't need an Assetto Corsa license to download the dedicated server. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8772 /tcp sudo ufw allow 9600 /udp sudo ufw allow 9600 /tcp sudo ufw allow 8081 /tcp Starting for the First Time \u00b6 Start up the game server with: docker-compose up -d Joining the Server \u00b6 If you have set the server to be LAN only, you may join your server by going to the following URL: https://acstuff.ru/s/q:race/online/join?ip=<IP>&httpPort=8081 Make sure the clients have AC Content Manager to be able to access through that URL.","title":"Assetto Corsa"},{"location":"games/assettocorsa/#assetto-corsa","text":"Assetto Corsa is a realistic racing simulator. This game server has a community made server manager available on Docker Hub , however, I have made a small fork of this to update the source for SteamCMD since I've been having quite a lot of trouble getting it to work. This fork is available from GitHub Packages , which is the image we'll use for this.","title":"Assetto Corsa"},{"location":"games/assettocorsa/#pre-installation","text":"We'll create a folder in the main user's home where all the game server's data will be saved. mkdir ~/games/assettocorsa","title":"Pre-Installation"},{"location":"games/assettocorsa/#docker-compose","text":"The game server will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : assettocorsa : image : ghcr.io/moonstar-x/assetto-server-manager:master restart : unless-stopped user : 1000:1000 ports : - 8772:8772 - 9600:9600 - 9600:9600/udp - 8081:8081 volumes : - ./server:/home/assetto/server-manager/assetto - ./data:/home/assetto/server-manager Warning Make sure to create the data and server folder before starting the container, otherwise you'll have some problems with the server data being saved.","title":"Docker Compose"},{"location":"games/assettocorsa/#configuration","text":"Create a config file inside data/config.yml : nano data/config.yml And paste the following: steam : username : STEAM_USER password : STEAM_PASS install_path : assetto executable_path : acServer force_update : false http : hostname : 0.0.0.0:8772 session_key : RANDOMLY_GENERATE_THIS server_manager_base_URL : session_store_type : cookie session_store_path : '' tls : enabled : false cert_path : '' key_path : '' monitoring : enabled : true store : type : boltdb path : server_manager.db shared_data_path : scheduled_event_check_loop : 0s accounts : admin_password_override : live_map : refresh_interval_ms : 500 server : audit_logging : true performance_mode : false dont_open_browser : false scan_content_folder_for_chanes : true use_car_name_cache : true persist_mid_session_results : false plugins : championships : recaptcha : site_key : secret_key : lua : enabled : false Note Make sure to replace STEAM_USER and STEAM_PASS with your steam account's information. I recommend you create a separate Steam account with Steam Guard disabled . You don't need an Assetto Corsa license to download the dedicated server.","title":"Configuration"},{"location":"games/assettocorsa/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8772 /tcp sudo ufw allow 9600 /udp sudo ufw allow 9600 /tcp sudo ufw allow 8081 /tcp","title":"Post-Installation"},{"location":"games/assettocorsa/#starting-for-the-first-time","text":"Start up the game server with: docker-compose up -d","title":"Starting for the First Time"},{"location":"games/assettocorsa/#joining-the-server","text":"If you have set the server to be LAN only, you may join your server by going to the following URL: https://acstuff.ru/s/q:race/online/join?ip=<IP>&httpPort=8081 Make sure the clients have AC Content Manager to be able to access through that URL.","title":"Joining the Server"},{"location":"games/minecraft-paper/","text":"Minecraft (Paper) \u00b6 Minecraft (Paper) is a plugin based server for Minecraft . This game server has an un-official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the game server's data will be saved. mkdir ~/games/minecraft-paper Docker Compose \u00b6 The game server will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : minecraft : image : itzg/minecraft-server:latest ports : - 25565:25565 volumes : - ./data:/data environment : - TZ=America/Guayaquil - EULA=TRUE - MEMORY=2G - VERSION=LATEST - TYPE=PAPER Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 25565 /tcp Configuration \u00b6 Inside the data folder there will be all the server's information, this includes the server.properties file which includes all the configuration for the server. You may modify this. Adding Plugins \u00b6 You may add plugins for PaperMC inside data/plugins , just make sure to restart the container when adding or removing plugins. Running Commands \u00b6 You can run commands inside the console through RCON by running: docker-compose exec minecraft rcon-cli <command> For more information, check: docker-compose exec minecraft rcon-cli --help Starting for the First Time \u00b6 Start up the game server with: docker-compose up -d Starting/Stopping the Server \u00b6 Since the server is not supposed to be restarted on server boot, you should manually start the server with: docker-compose start And stop it with: docker-compose stop","title":"Minecraft (Paper)"},{"location":"games/minecraft-paper/#minecraft-paper","text":"Minecraft (Paper) is a plugin based server for Minecraft . This game server has an un-official image available on Docker Hub which we'll use.","title":"Minecraft (Paper)"},{"location":"games/minecraft-paper/#pre-installation","text":"We'll create a folder in the main user's home where all the game server's data will be saved. mkdir ~/games/minecraft-paper","title":"Pre-Installation"},{"location":"games/minecraft-paper/#docker-compose","text":"The game server will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : minecraft : image : itzg/minecraft-server:latest ports : - 25565:25565 volumes : - ./data:/data environment : - TZ=America/Guayaquil - EULA=TRUE - MEMORY=2G - VERSION=LATEST - TYPE=PAPER","title":"Docker Compose"},{"location":"games/minecraft-paper/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 25565 /tcp","title":"Post-Installation"},{"location":"games/minecraft-paper/#configuration","text":"Inside the data folder there will be all the server's information, this includes the server.properties file which includes all the configuration for the server. You may modify this.","title":"Configuration"},{"location":"games/minecraft-paper/#adding-plugins","text":"You may add plugins for PaperMC inside data/plugins , just make sure to restart the container when adding or removing plugins.","title":"Adding Plugins"},{"location":"games/minecraft-paper/#running-commands","text":"You can run commands inside the console through RCON by running: docker-compose exec minecraft rcon-cli <command> For more information, check: docker-compose exec minecraft rcon-cli --help","title":"Running Commands"},{"location":"games/minecraft-paper/#starting-for-the-first-time","text":"Start up the game server with: docker-compose up -d","title":"Starting for the First Time"},{"location":"games/minecraft-paper/#startingstopping-the-server","text":"Since the server is not supposed to be restarted on server boot, you should manually start the server with: docker-compose start And stop it with: docker-compose stop","title":"Starting/Stopping the Server"},{"location":"games/teamspeak/","text":"TeamSpeak 3 \u00b6 TeamSpeak 3 is a gaming focused voice server. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/games/teamspeak Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : teamspeak : image : teamspeak:latest restart : unless-stopped depends_on : - db ports : - 9987:9987/udp - 10011:10011 - 30033:30033 volumes : - ./data:/var/ts3server environment : - TZ=America/Guayaquil - TS3SERVER_DB_PLUGIN=ts3db_mariadb - TS3SERVER_DB_SQLCREATEPATH=create_mariadb - TS3SERVER_DB_HOST=db - TS3SERVER_DB_USER=root - TS3SERVER_DB_NAME=teamspeak - TS3SERVER_DB_PASSWORD=CHANGE_THIS - TS3SERVER_DB_WAITUNTILREADY=30 - TS3SERVER_LICENSE=accept db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=teamspeak Note Make sure to change CHANGE_THIS to a custom value. Getting Server Auth Tokens \u00b6 After the container has been created, check its logs and save the serveradmin login details. This is very important in case you get locked out of your server or if you need to change some settings through ServerQuery. Use: docker logs teamspeak_teamspeak_1 --follow You should also find here the privilege key to set up your user as the server administrator. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 10011 /tcp sudo ufw allow 30033 /tcp sudo ufw allow 9987 /udp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"TeamSpeak 3"},{"location":"games/teamspeak/#teamspeak-3","text":"TeamSpeak 3 is a gaming focused voice server. This service has an official image available on Docker Hub which we'll use.","title":"TeamSpeak 3"},{"location":"games/teamspeak/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/games/teamspeak","title":"Pre-Installation"},{"location":"games/teamspeak/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : teamspeak : image : teamspeak:latest restart : unless-stopped depends_on : - db ports : - 9987:9987/udp - 10011:10011 - 30033:30033 volumes : - ./data:/var/ts3server environment : - TZ=America/Guayaquil - TS3SERVER_DB_PLUGIN=ts3db_mariadb - TS3SERVER_DB_SQLCREATEPATH=create_mariadb - TS3SERVER_DB_HOST=db - TS3SERVER_DB_USER=root - TS3SERVER_DB_NAME=teamspeak - TS3SERVER_DB_PASSWORD=CHANGE_THIS - TS3SERVER_DB_WAITUNTILREADY=30 - TS3SERVER_LICENSE=accept db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=teamspeak Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"games/teamspeak/#getting-server-auth-tokens","text":"After the container has been created, check its logs and save the serveradmin login details. This is very important in case you get locked out of your server or if you need to change some settings through ServerQuery. Use: docker logs teamspeak_teamspeak_1 --follow You should also find here the privilege key to set up your user as the server administrator.","title":"Getting Server Auth Tokens"},{"location":"games/teamspeak/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 10011 /tcp sudo ufw allow 30033 /tcp sudo ufw allow 9987 /udp","title":"Post-Installation"},{"location":"games/teamspeak/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"games/valheim/","text":"Valheim \u00b6 Valheim is an exploration game set in a Viking mythology world. This game server has an un-official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the game server's data will be saved. mkdir ~/games/valheim Docker Compose \u00b6 The game server will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : valheim : image : lloesche/valheim-server:latest cap_add : - SYS_NICE ports : - 2456:2456/udp - 2457:2457/udp volumes : - ./config:/config - ./data:/opt/valheim environment : - TZ=America/Guayaquil - SERVER_NAME=CHANGE_THIS - WORLD_NAME=world - SERVER_PASS=CHANGE_THIS - SERVER_PUBLIC=false - PUID=1000 - PGID=1000 Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 2456 /udp sudo ufw allow 2457 /udp Starting for the First Time \u00b6 Start up the game server with: docker-compose up -d Starting/Stopping the Server \u00b6 Since the server is not supposed to be restarted on server boot, you should manually start the server with: docker-compose start And stop it with: docker-compose stop","title":"Valheim"},{"location":"games/valheim/#valheim","text":"Valheim is an exploration game set in a Viking mythology world. This game server has an un-official image available on Docker Hub which we'll use.","title":"Valheim"},{"location":"games/valheim/#pre-installation","text":"We'll create a folder in the main user's home where all the game server's data will be saved. mkdir ~/games/valheim","title":"Pre-Installation"},{"location":"games/valheim/#docker-compose","text":"The game server will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : valheim : image : lloesche/valheim-server:latest cap_add : - SYS_NICE ports : - 2456:2456/udp - 2457:2457/udp volumes : - ./config:/config - ./data:/opt/valheim environment : - TZ=America/Guayaquil - SERVER_NAME=CHANGE_THIS - WORLD_NAME=world - SERVER_PASS=CHANGE_THIS - SERVER_PUBLIC=false - PUID=1000 - PGID=1000 Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"games/valheim/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 2456 /udp sudo ufw allow 2457 /udp","title":"Post-Installation"},{"location":"games/valheim/#starting-for-the-first-time","text":"Start up the game server with: docker-compose up -d","title":"Starting for the First Time"},{"location":"games/valheim/#startingstopping-the-server","text":"Since the server is not supposed to be restarted on server boot, you should manually start the server with: docker-compose start And stop it with: docker-compose stop","title":"Starting/Stopping the Server"},{"location":"games/zerotier/","text":"ZeroTier-One \u00b6 ZeroTier-One is a virtual LAN service, similar to Hamachi, that allows you to have your services exposed through a VPN. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/games/zerotier Creating a Network \u00b6 To create a network, simply visit My ZeroTier , login to your account (or create one if needed) and simply click on the Create Network button. This will give you a Network ID (which you should keep since we'll need this). This Network ID is what you need to share with your friends so that they can connect to your network. If you leave the network settings to be private, you may need to manually authorize new members into the network. Docker Compose \u00b6 The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : zerotier : image : zerotier/zerotier:latest restart : unless-stopped cap_add : - NET_ADMIN network_mode : host devices : - /dev/net/tun:/dev/net/tun command : NETWORK_ID volumes : - ./config/authtoken.secret:/var/lib/zerotier-one/authtoken.secret - ./config/identity.public:/var/lib/zerotier-one/identity.public - ./config/identity.secret:/var/lib/zerotier-one/identity.secret environment : - TZ=America/Guayaquil dns : image : zerotier/zeronsd:latest restart : unless-stopped depends_on : - zerotier network_mode : host command : start NETWORK_ID -d DOMAIN volumes : - ./config/authtoken.secret:/var/lib/zerotier-one/authtoken.secret:ro environment : - TZ=America/Guayaquil - ZEROTIER_CENTRAL_TOKEN=CENTRAL_TOKEN Note Replace NETWORK_ID with your Network ID . Replace CENTRAL_TOKEN with a ZeroTier token, you may acquire one from here . Replace DOMAIN with the domain you wish to use. Note that the domain only represents the base domain, everyone in your network will be assigned a subdomain based on their assigned names on the network. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 53 /tcp sudo ufw allow 53 /udp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"ZeroTier-One"},{"location":"games/zerotier/#zerotier-one","text":"ZeroTier-One is a virtual LAN service, similar to Hamachi, that allows you to have your services exposed through a VPN. This service has an official image available on Docker Hub which we'll use.","title":"ZeroTier-One"},{"location":"games/zerotier/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/games/zerotier","title":"Pre-Installation"},{"location":"games/zerotier/#creating-a-network","text":"To create a network, simply visit My ZeroTier , login to your account (or create one if needed) and simply click on the Create Network button. This will give you a Network ID (which you should keep since we'll need this). This Network ID is what you need to share with your friends so that they can connect to your network. If you leave the network settings to be private, you may need to manually authorize new members into the network.","title":"Creating a Network"},{"location":"games/zerotier/#docker-compose","text":"The bot will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : zerotier : image : zerotier/zerotier:latest restart : unless-stopped cap_add : - NET_ADMIN network_mode : host devices : - /dev/net/tun:/dev/net/tun command : NETWORK_ID volumes : - ./config/authtoken.secret:/var/lib/zerotier-one/authtoken.secret - ./config/identity.public:/var/lib/zerotier-one/identity.public - ./config/identity.secret:/var/lib/zerotier-one/identity.secret environment : - TZ=America/Guayaquil dns : image : zerotier/zeronsd:latest restart : unless-stopped depends_on : - zerotier network_mode : host command : start NETWORK_ID -d DOMAIN volumes : - ./config/authtoken.secret:/var/lib/zerotier-one/authtoken.secret:ro environment : - TZ=America/Guayaquil - ZEROTIER_CENTRAL_TOKEN=CENTRAL_TOKEN Note Replace NETWORK_ID with your Network ID . Replace CENTRAL_TOKEN with a ZeroTier token, you may acquire one from here . Replace DOMAIN with the domain you wish to use. Note that the domain only represents the base domain, everyone in your network will be assigned a subdomain based on their assigned names on the network.","title":"Docker Compose"},{"location":"games/zerotier/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 53 /tcp sudo ufw allow 53 /udp","title":"Post-Installation"},{"location":"games/zerotier/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"server-monitoring/introduction/","text":"Introduction \u00b6 Since I had a Raspberry Pi 3B+ laying around collecting dust, I decided to use it as an always-on monitoring service using Prometheus and Grafana . The idea would be that the server would report data about its current usage and Grafana would display a pretty dashboard containing all the relevant data to give a better insight on the server's current usage. This section of the guide is meant to be followed in the order that is displayed in the content sidebar. It is separated by the machine that has to run the corresponding service.","title":"Introduction"},{"location":"server-monitoring/introduction/#introduction","text":"Since I had a Raspberry Pi 3B+ laying around collecting dust, I decided to use it as an always-on monitoring service using Prometheus and Grafana . The idea would be that the server would report data about its current usage and Grafana would display a pretty dashboard containing all the relevant data to give a better insight on the server's current usage. This section of the guide is meant to be followed in the order that is displayed in the content sidebar. It is separated by the machine that has to run the corresponding service.","title":"Introduction"},{"location":"server-monitoring/in-monitor/","text":"Initialization \u00b6 The following section contains the guides that should be applied on the monitor device. In this case, a Raspberry Pi 3B+ will be used since it is a low profile and low consumption device, which fits perfectly for this always-on monitoring system. If you're using a Raspberry Pi 3B+, I recommend you follow the Configuration page, otherwise you may be able to skip it. Keep in mind that the Grafana service will run through Docker, so you should install it there too if you don't already have it.","title":"Initialization"},{"location":"server-monitoring/in-monitor/#initialization","text":"The following section contains the guides that should be applied on the monitor device. In this case, a Raspberry Pi 3B+ will be used since it is a low profile and low consumption device, which fits perfectly for this always-on monitoring system. If you're using a Raspberry Pi 3B+, I recommend you follow the Configuration page, otherwise you may be able to skip it. Keep in mind that the Grafana service will run through Docker, so you should install it there too if you don't already have it.","title":"Initialization"},{"location":"server-monitoring/in-monitor/configuration/","text":"Configuration \u00b6 Info This page depends on the monitoring device that will be used. In this case, a Raspberry Pi 3B+ will be used. If you do not have one you might need to skip this guide and go straight to the Grafana page. OS Installation \u00b6 Flash your SD Card with the OS of your choice, in this case, we'll be using Raspberry Pi OS Lite . Head over to the Operating Systems page for more information. You can choose Raspberry Pi OS Desktop , however the Lite version will contain much less clutter that will be unnecessary. Configuring \u00b6 Before continuing we must change some system information using the raspi-config utility. Note You will need to reboot your device after completing all these changes in order for them to have effect. Change the Hostname \u00b6 The hostname is the name of the machine, by default it is set to pi which might not be descriptive enough. In order to change it, open the configurator utility: sudo raspi-config And choose the following options: System Options > Hostname And insert the hostname you wish to use. Disable Screen Blanking \u00b6 Since this will be an always-on monitoring dashboard, we must disable the screen from turning off. Inside the raspi-config utility, select the options: Display Options > Screen Blanking And disable it. Change the Timezone \u00b6 Your Raspberry Pi might have the incorrect timezone set, it is very important to have the correct time in your device to avoid problems with connectivity. Inside the raspi-config utility, select the options: Localisation Options > Timezone And pick the your own timezone. Connect to Wi-Fi \u00b6 In the case that using Ethernet is not possible, Wi-Fi will be necessary. Since we do not have a GUI yet, we need to connect to the Internet through the raspi-config . Inside the utility, select the options: System Options > Wireless LAN Insert your Wi-Fi's SSID and password to connect. Enable SSH \u00b6 Remote control will be necessary to avoid having to use the machine directly. For this, SSH should be enabled. In the same raspi-config utility, select the options: Interface Options > SSH > Enable SSH should now be enabled. Installing Software \u00b6 Before installing anything, let's update the repositories and installed packages: sudo apt-get update && sudo apt-get upgrade And installed the required programs: sudo apt-get install xterm firefox-esr git Installing a WM \u00b6 In order to access the Grafana site, a GUI is indeed necessary. We'll install a simple WM to avoid overwhelming the Raspberry Pi with heavy usage that might hinder our experience. For this, we'll use Awesome WM . First, install X and Awesome : sudo apt-get install xinit awesome And start it, xinit && awesome We'll instal a theme to the WM so it doesn't look too bare-bones. We'll use awesome-copycats for this. Install this with: git clone --recurse-submodules --remote-submodules --depth 1 -j 2 https://github.com/lcpz/awesome-copycats.git mkdir -p ~/.config/awesome mv -bv awesome-copycats/ { *,. [ ^. ] * } ~/.config/awesome ; rm -rf awesome-copycats cd ~/.config/awesome cp rc.lua.template rc.lua Finally, restart awesome by right-clicking anywhere on the desktop and selecting the Restart option. In order for the Raspberry Pi to automatically open Awesome on system boot, edit the following file: sudo nano /etc/profile And add the following lines: if [[ ! $DISPLAY && $XDG_VTNR -eq 1 ]]; then exec startx fi Installing Docker \u00b6 Finally, we'll need Docker to host the Grafana service. To install it, run: curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker $USER And finally, reboot your machine with: sudo reboot You should now be able to execute Docker without issues. Make sure your user has the required permissions with: docker info","title":"Configuration"},{"location":"server-monitoring/in-monitor/configuration/#configuration","text":"Info This page depends on the monitoring device that will be used. In this case, a Raspberry Pi 3B+ will be used. If you do not have one you might need to skip this guide and go straight to the Grafana page.","title":"Configuration"},{"location":"server-monitoring/in-monitor/configuration/#os-installation","text":"Flash your SD Card with the OS of your choice, in this case, we'll be using Raspberry Pi OS Lite . Head over to the Operating Systems page for more information. You can choose Raspberry Pi OS Desktop , however the Lite version will contain much less clutter that will be unnecessary.","title":"OS Installation"},{"location":"server-monitoring/in-monitor/configuration/#configuring","text":"Before continuing we must change some system information using the raspi-config utility. Note You will need to reboot your device after completing all these changes in order for them to have effect.","title":"Configuring"},{"location":"server-monitoring/in-monitor/configuration/#change-the-hostname","text":"The hostname is the name of the machine, by default it is set to pi which might not be descriptive enough. In order to change it, open the configurator utility: sudo raspi-config And choose the following options: System Options > Hostname And insert the hostname you wish to use.","title":"Change the Hostname"},{"location":"server-monitoring/in-monitor/configuration/#disable-screen-blanking","text":"Since this will be an always-on monitoring dashboard, we must disable the screen from turning off. Inside the raspi-config utility, select the options: Display Options > Screen Blanking And disable it.","title":"Disable Screen Blanking"},{"location":"server-monitoring/in-monitor/configuration/#change-the-timezone","text":"Your Raspberry Pi might have the incorrect timezone set, it is very important to have the correct time in your device to avoid problems with connectivity. Inside the raspi-config utility, select the options: Localisation Options > Timezone And pick the your own timezone.","title":"Change the Timezone"},{"location":"server-monitoring/in-monitor/configuration/#connect-to-wi-fi","text":"In the case that using Ethernet is not possible, Wi-Fi will be necessary. Since we do not have a GUI yet, we need to connect to the Internet through the raspi-config . Inside the utility, select the options: System Options > Wireless LAN Insert your Wi-Fi's SSID and password to connect.","title":"Connect to Wi-Fi"},{"location":"server-monitoring/in-monitor/configuration/#enable-ssh","text":"Remote control will be necessary to avoid having to use the machine directly. For this, SSH should be enabled. In the same raspi-config utility, select the options: Interface Options > SSH > Enable SSH should now be enabled.","title":"Enable SSH"},{"location":"server-monitoring/in-monitor/configuration/#installing-software","text":"Before installing anything, let's update the repositories and installed packages: sudo apt-get update && sudo apt-get upgrade And installed the required programs: sudo apt-get install xterm firefox-esr git","title":"Installing Software"},{"location":"server-monitoring/in-monitor/configuration/#installing-a-wm","text":"In order to access the Grafana site, a GUI is indeed necessary. We'll install a simple WM to avoid overwhelming the Raspberry Pi with heavy usage that might hinder our experience. For this, we'll use Awesome WM . First, install X and Awesome : sudo apt-get install xinit awesome And start it, xinit && awesome We'll instal a theme to the WM so it doesn't look too bare-bones. We'll use awesome-copycats for this. Install this with: git clone --recurse-submodules --remote-submodules --depth 1 -j 2 https://github.com/lcpz/awesome-copycats.git mkdir -p ~/.config/awesome mv -bv awesome-copycats/ { *,. [ ^. ] * } ~/.config/awesome ; rm -rf awesome-copycats cd ~/.config/awesome cp rc.lua.template rc.lua Finally, restart awesome by right-clicking anywhere on the desktop and selecting the Restart option. In order for the Raspberry Pi to automatically open Awesome on system boot, edit the following file: sudo nano /etc/profile And add the following lines: if [[ ! $DISPLAY && $XDG_VTNR -eq 1 ]]; then exec startx fi","title":"Installing a WM"},{"location":"server-monitoring/in-monitor/configuration/#installing-docker","text":"Finally, we'll need Docker to host the Grafana service. To install it, run: curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker $USER And finally, reboot your machine with: sudo reboot You should now be able to execute Docker without issues. Make sure your user has the required permissions with: docker info","title":"Installing Docker"},{"location":"server-monitoring/in-monitor/grafana/","text":"Grafana \u00b6 Prometheus is a dashboard that can consume from Prometheus and other data sources to display all the information that you need. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/grafana Inside this folder, create a data folder: mkdir data Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : grafana : image : grafana/grafana:latest restart : unless-stopped user : 1000:1000 ports : - 3000:3000 volumes : - ./data:/var/lib/grafana environment : - TZ=America/Guayaquil Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure. Add Prometheus to Grafana \u00b6 Visit the Grafana's site by accessing: http://localhost:3000 And create your Admin account. Make your way to the following page: Configuration > Data Sources > Add a data source > Prometheus And add the local IP of your server. Add a Dashboard \u00b6 Make your way to the following page. Create > Import And paste the following JSON in it: { \"annotations\" : { \"list\" : [ { \"builtIn\" : 1 , \"datasource\" : { \"type\" : \"grafana\" , \"uid\" : \"-- Grafana --\" }, \"enable\" : true , \"hide\" : true , \"iconColor\" : \"rgba(0, 211, 255, 1)\" , \"name\" : \"Annotations & Alerts\" , \"target\" : { \"limit\" : 100 , \"matchAny\" : false , \"tags\" : [], \"type\" : \"dashboard\" }, \"type\" : \"dashboard\" } ] }, \"description\" : \"moonstar's Server Dashboard\" , \"editable\" : true , \"fiscalYearStartMonth\" : 0 , \"graphTooltip\" : 0 , \"id\" : 4 , \"iteration\" : 1653438285360 , \"links\" : [], \"liveNow\" : false , \"panels\" : [ { \"collapsed\" : false , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 0 }, \"id\" : 8 , \"panels\" : [], \"title\" : \"Quick Info\" , \"type\" : \"row\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 75 }, { \"color\" : \"semi-dark-red\" , \"value\" : 95 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 0 , \"y\" : 1 }, \"id\" : 2 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"(((count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu))) - avg(sum by (mode)(irate(node_cpu_seconds_total{mode='idle',instance=\\\"$node\\\",job=\\\"$job\\\"}[5m])))) * 100) / count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu))\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Usage\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU temperature\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"blue\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 45 }, { \"color\" : \"semi-dark-red\" , \"value\" : 65 } ] }, \"unit\" : \"celsius\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 3 , \"y\" : 1 }, \"id\" : 5 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"mean\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(node_hwmon_temp_celsius{instance=\\\"$node\\\",job=\\\"$job\\\"})\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Temp\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Sys Load (5m avg)\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 75 }, { \"color\" : \"semi-dark-red\" , \"value\" : 95 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 6 , \"y\" : 1 }, \"id\" : 6 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(node_load5{instance=\\\"$node\\\",job=\\\"$job\\\"}) / count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu)) * 100\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Sys Load\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"RAM Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 70 }, { \"color\" : \"semi-dark-red\" , \"value\" : 90 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 9 , \"y\" : 1 }, \"id\" : 3 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"100 - ((node_memory_MemAvailable_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"} * 100) / node_memory_MemTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"})\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"RAM Usage\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Swap Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 15 }, { \"color\" : \"semi-dark-red\" , \"value\" : 30 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 12 , \"y\" : 1 }, \"id\" : 4 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"((node_memory_SwapTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"} - node_memory_SwapFree_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"}) / (node_memory_SwapTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"} )) * 100\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Swap Usage\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Cores\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"short\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 15 , \"y\" : 1 }, \"id\" : 10 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu))\" , \"refId\" : \"A\" } ], \"title\" : \"CPU Cores\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"RAM Total\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 18 , \"y\" : 1 }, \"id\" : 11 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_memory_MemTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"RAM Total\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Swap Total\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 21 , \"y\" : 1 }, \"id\" : 12 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_memory_SwapTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"Swap Total\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Uptime\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"dtdhms\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 15 , \"y\" : 3 }, \"id\" : 13 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_time_seconds{instance=\\\"$node\\\",job=\\\"$job\\\"} - node_boot_time_seconds{instance=\\\"$node\\\",job=\\\"$job\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"Uptime\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"/ Total Size\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 18 , \"y\" : 3 }, \"id\" : 14 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_filesystem_size_bytes{instance=\\\"$node\\\",job=\\\"$job\\\",mountpoint=\\\"/\\\",fstype!=\\\"rootfs\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"/ Total Size\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"/ Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 65 }, { \"color\" : \"semi-dark-red\" , \"value\" : 90 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 21 , \"y\" : 3 }, \"id\" : 15 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"100 - ((node_filesystem_avail_bytes{instance=\\\"$node\\\",job=\\\"$job\\\",mountpoint=\\\"/\\\",fstype!=\\\"rootfs\\\"} * 100) / node_filesystem_size_bytes{instance=\\\"$node\\\",job=\\\"$job\\\",mountpoint=\\\"/\\\",fstype!=\\\"rootfs\\\"})\" , \"refId\" : \"A\" } ], \"title\" : \"/ Usage\" , \"type\" : \"stat\" }, { \"collapsed\" : false , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 5 }, \"id\" : 26 , \"panels\" : [], \"title\" : \"Network Stats\" , \"type\" : \"row\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Bytes Received/Transferred [$dev]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 8 , \"x\" : 0 , \"y\" : 6 }, \"id\" : 28 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"node_network_receive_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}\" , \"legendFormat\" : \"Bytes Received\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"node_network_transmit_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}\" , \"hide\" : false , \"legendFormat\" : \"Bytes Transferred\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Bytes Received/Transferred\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Transfer Speed [$network_interface]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"Bps\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 8 , \"x\" : 8 , \"y\" : 6 }, \"id\" : 29 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"rate(node_network_receive_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}[5m])\" , \"instant\" : false , \"legendFormat\" : \"Receive Speed\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"rate(node_network_transmit_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}[5m])\" , \"hide\" : false , \"legendFormat\" : \"Transmit Speed\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Transfer Speed\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"TCP Connections [$network_interface]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"short\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 8 , \"x\" : 16 , \"y\" : 6 }, \"id\" : 30 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"node_netstat_Tcp_CurrEstab\" , \"instant\" : false , \"legendFormat\" : \"Number of Connections\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"TCP Connections\" , \"type\" : \"timeseries\" }, { \"collapsed\" : false , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 14 }, \"id\" : 32 , \"panels\" : [], \"title\" : \"CPU Stats\" , \"type\" : \"row\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Core Frequency\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"rothz\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 11 , \"w\" : 8 , \"x\" : 0 , \"y\" : 15 }, \"id\" : 34 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"node_cpu_scaling_frequency_hertz\" , \"legendFormat\" : \"Core {{cpu}}\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Core Frequency\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Usage by Mode\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 11 , \"w\" : 8 , \"x\" : 8 , \"y\" : 15 }, \"id\" : 35 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" , \"sortBy\" : \"Max\" , \"sortDesc\" : true }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"system\\\"}[5m]) * 100) \" , \"instant\" : false , \"legendFormat\" : \"system\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"user\\\"}[5m]) * 100) \" , \"hide\" : false , \"legendFormat\" : \"user\" , \"range\" : true , \"refId\" : \"B\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"iowait\\\"}[5m]) * 100) \" , \"hide\" : false , \"legendFormat\" : \"iowait\" , \"range\" : true , \"refId\" : \"C\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"steal\\\"}[5m]) * 100) \" , \"hide\" : false , \"legendFormat\" : \"steal\" , \"range\" : true , \"refId\" : \"D\" } ], \"title\" : \"CPU Usage by Mode\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 11 , \"w\" : 8 , \"x\" : 16 , \"y\" : 15 }, \"id\" : 36 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" , \"sortBy\" : \"Max\" , \"sortDesc\" : true }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"system\\\"}[5m]) * 100) + avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"user\\\"}[5m]) * 100) + avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"iowait\\\"}[5m]) * 100) + avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"steal\\\"}[5m]) * 100) \" , \"instant\" : false , \"legendFormat\" : \"CPU Usage\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Usage\" , \"type\" : \"timeseries\" }, { \"collapsed\" : true , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 26 }, \"id\" : 17 , \"panels\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Bytes Read/Written [$drive_name ]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : true , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 9 , \"x\" : 0 , \"y\" : 27 }, \"id\" : 19 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"rate(node_disk_read_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[5m])\" , \"instant\" : false , \"legendFormat\" : \"Bytes Read\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"rate(node_disk_written_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[5m])\" , \"hide\" : false , \"legendFormat\" : \"Bytes Written\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Bytes Read/Written\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Disk IOps Completed [$drive_name ]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : true , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" } ] }, \"unit\" : \"iops\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 9 , \"x\" : 9 , \"y\" : 27 }, \"id\" : 24 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"irate(node_disk_reads_completed_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[1m])\" , \"instant\" : false , \"legendFormat\" : \"Reads Completed\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"irate(node_disk_writes_completed_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[1m])\" , \"hide\" : false , \"legendFormat\" : \"Writes Completed\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Disk IOps Completed\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Total Size\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 18 , \"y\" : 27 }, \"id\" : 20 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"})\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Total Size\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Used Space\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"yellow\" } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 21 , \"y\" : 27 }, \"id\" : 22 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"}) - sum(node_filesystem_avail_bytes{device=~\\\".+$drive_name.?\\\"})\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Used Space\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Free Space\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"semi-dark-red\" }, { \"color\" : \"#EAB839\" , \"value\" : 20 }, { \"color\" : \"green\" , \"value\" : 50 } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 18 , \"y\" : 31 }, \"id\" : 21 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"sum(node_filesystem_avail_bytes{device=~\\\".+$drive_name.?\\\"})\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Free Space\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Disk Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" }, { \"color\" : \"#EAB839\" , \"value\" : 75 }, { \"color\" : \"semi-dark-red\" , \"value\" : 90 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 21 , \"y\" : 31 }, \"id\" : 23 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"((sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"}) - sum(node_filesystem_avail_bytes{device=~\\\".+$drive_name.?\\\"})) / sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"})) * 100\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Disk Usage\" , \"type\" : \"gauge\" } ], \"repeat\" : \"drive_name\" , \"title\" : \"Drive Stats for /dev/$drive_name\" , \"type\" : \"row\" } ], \"refresh\" : \"10s\" , \"schemaVersion\" : 36 , \"style\" : \"dark\" , \"tags\" : [ \"linux\" , \"node-exporter\" ], \"templating\" : { \"list\" : [ { \"current\" : { \"selected\" : false , \"text\" : \"node\" , \"value\" : \"node\" }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_uname_info, job)\" , \"hide\" : 0 , \"includeAll\" : false , \"label\" : \"Job\" , \"multi\" : false , \"name\" : \"job\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_uname_info, job)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 1 , \"type\" : \"query\" }, { \"current\" : { \"selected\" : false , \"text\" : \"host.docker.internal:9100\" , \"value\" : \"host.docker.internal:9100\" }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_uname_info{job=\\\"$job\\\"}, instance)\" , \"hide\" : 0 , \"includeAll\" : false , \"label\" : \"Host\" , \"multi\" : false , \"name\" : \"node\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_uname_info{job=\\\"$job\\\"}, instance)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 1 , \"type\" : \"query\" }, { \"current\" : { \"selected\" : false , \"text\" : \"enp2s0\" , \"value\" : \"enp2s0\" }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_network_info{operstate=\\\"up\\\"}, device)\" , \"hide\" : 0 , \"includeAll\" : false , \"label\" : \"NIC\" , \"multi\" : false , \"name\" : \"network_interface\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_network_info{operstate=\\\"up\\\"}, device)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 0 , \"type\" : \"query\" }, { \"current\" : { \"selected\" : true , \"text\" : [ \"All\" ], \"value\" : [ \"$__all\" ] }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_disk_info, device)\" , \"description\" : \"Drive /dev/sdX\" , \"hide\" : 0 , \"includeAll\" : true , \"label\" : \"Drive\" , \"multi\" : true , \"name\" : \"drive_name\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_disk_info, device)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 1 , \"type\" : \"query\" } ] }, \"time\" : { \"from\" : \"now-5m\" , \"to\" : \"now\" }, \"timepicker\" : { \"refresh_intervals\" : [ \"10s\" , \"1m\" , \"5m\" , \"15m\" , \"30m\" ] }, \"timezone\" : \"browser\" , \"title\" : \"Server Dashboard\" , \"uid\" : \"iUjT2qZgz\" , \"version\" : 9 , \"weekStart\" : \"\" } This dashboard will look similar to this: Final Touches \u00b6 Before saying we're done we would like to autostart this dashboard on system startup. For this we'll need to install the Auto fullscreen Firefox addon so that every time we open the browser it opens on fullscreen mode. We'll also make the following URL the home page of the browser: http://localhost:3000/d/iUjT2qZgz/server-dashboard?orgid=1&refresh=10s&kiosk Note Make sure to replace this URL with the one for your actual dashboard. Finally, to autostart firefox, create the following file: nano ~/.xinitrc And add the following text inside: awesome & firefox","title":"Grafana"},{"location":"server-monitoring/in-monitor/grafana/#grafana","text":"Prometheus is a dashboard that can consume from Prometheus and other data sources to display all the information that you need. This service has an official image on Docker Hub which we'll use.","title":"Grafana"},{"location":"server-monitoring/in-monitor/grafana/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/grafana Inside this folder, create a data folder: mkdir data","title":"Pre-Installation"},{"location":"server-monitoring/in-monitor/grafana/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : grafana : image : grafana/grafana:latest restart : unless-stopped user : 1000:1000 ports : - 3000:3000 volumes : - ./data:/var/lib/grafana environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"server-monitoring/in-monitor/grafana/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"server-monitoring/in-monitor/grafana/#add-prometheus-to-grafana","text":"Visit the Grafana's site by accessing: http://localhost:3000 And create your Admin account. Make your way to the following page: Configuration > Data Sources > Add a data source > Prometheus And add the local IP of your server.","title":"Add Prometheus to Grafana"},{"location":"server-monitoring/in-monitor/grafana/#add-a-dashboard","text":"Make your way to the following page. Create > Import And paste the following JSON in it: { \"annotations\" : { \"list\" : [ { \"builtIn\" : 1 , \"datasource\" : { \"type\" : \"grafana\" , \"uid\" : \"-- Grafana --\" }, \"enable\" : true , \"hide\" : true , \"iconColor\" : \"rgba(0, 211, 255, 1)\" , \"name\" : \"Annotations & Alerts\" , \"target\" : { \"limit\" : 100 , \"matchAny\" : false , \"tags\" : [], \"type\" : \"dashboard\" }, \"type\" : \"dashboard\" } ] }, \"description\" : \"moonstar's Server Dashboard\" , \"editable\" : true , \"fiscalYearStartMonth\" : 0 , \"graphTooltip\" : 0 , \"id\" : 4 , \"iteration\" : 1653438285360 , \"links\" : [], \"liveNow\" : false , \"panels\" : [ { \"collapsed\" : false , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 0 }, \"id\" : 8 , \"panels\" : [], \"title\" : \"Quick Info\" , \"type\" : \"row\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 75 }, { \"color\" : \"semi-dark-red\" , \"value\" : 95 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 0 , \"y\" : 1 }, \"id\" : 2 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"(((count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu))) - avg(sum by (mode)(irate(node_cpu_seconds_total{mode='idle',instance=\\\"$node\\\",job=\\\"$job\\\"}[5m])))) * 100) / count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu))\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Usage\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU temperature\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"blue\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 45 }, { \"color\" : \"semi-dark-red\" , \"value\" : 65 } ] }, \"unit\" : \"celsius\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 3 , \"y\" : 1 }, \"id\" : 5 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"mean\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(node_hwmon_temp_celsius{instance=\\\"$node\\\",job=\\\"$job\\\"})\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Temp\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Sys Load (5m avg)\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 75 }, { \"color\" : \"semi-dark-red\" , \"value\" : 95 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 6 , \"y\" : 1 }, \"id\" : 6 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(node_load5{instance=\\\"$node\\\",job=\\\"$job\\\"}) / count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu)) * 100\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Sys Load\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"RAM Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 70 }, { \"color\" : \"semi-dark-red\" , \"value\" : 90 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 9 , \"y\" : 1 }, \"id\" : 3 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"100 - ((node_memory_MemAvailable_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"} * 100) / node_memory_MemTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"})\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"RAM Usage\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Swap Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 15 }, { \"color\" : \"semi-dark-red\" , \"value\" : 30 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 12 , \"y\" : 1 }, \"id\" : 4 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"((node_memory_SwapTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"} - node_memory_SwapFree_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"}) / (node_memory_SwapTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"} )) * 100\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Swap Usage\" , \"type\" : \"gauge\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Cores\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"short\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 15 , \"y\" : 1 }, \"id\" : 10 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"count(count(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\"}) by (cpu))\" , \"refId\" : \"A\" } ], \"title\" : \"CPU Cores\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"RAM Total\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 18 , \"y\" : 1 }, \"id\" : 11 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_memory_MemTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"RAM Total\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Swap Total\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 21 , \"y\" : 1 }, \"id\" : 12 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_memory_SwapTotal_bytes{instance=\\\"$node\\\",job=\\\"$job\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"Swap Total\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Uptime\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"dtdhms\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 15 , \"y\" : 3 }, \"id\" : 13 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_time_seconds{instance=\\\"$node\\\",job=\\\"$job\\\"} - node_boot_time_seconds{instance=\\\"$node\\\",job=\\\"$job\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"Uptime\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"/ Total Size\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 18 , \"y\" : 3 }, \"id\" : 14 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"node_filesystem_size_bytes{instance=\\\"$node\\\",job=\\\"$job\\\",mountpoint=\\\"/\\\",fstype!=\\\"rootfs\\\"}\" , \"refId\" : \"A\" } ], \"title\" : \"/ Total Size\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"/ Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null }, { \"color\" : \"#EAB839\" , \"value\" : 65 }, { \"color\" : \"semi-dark-red\" , \"value\" : 90 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 2 , \"w\" : 3 , \"x\" : 21 , \"y\" : 3 }, \"id\" : 15 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"expr\" : \"100 - ((node_filesystem_avail_bytes{instance=\\\"$node\\\",job=\\\"$job\\\",mountpoint=\\\"/\\\",fstype!=\\\"rootfs\\\"} * 100) / node_filesystem_size_bytes{instance=\\\"$node\\\",job=\\\"$job\\\",mountpoint=\\\"/\\\",fstype!=\\\"rootfs\\\"})\" , \"refId\" : \"A\" } ], \"title\" : \"/ Usage\" , \"type\" : \"stat\" }, { \"collapsed\" : false , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 5 }, \"id\" : 26 , \"panels\" : [], \"title\" : \"Network Stats\" , \"type\" : \"row\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Bytes Received/Transferred [$dev]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 8 , \"x\" : 0 , \"y\" : 6 }, \"id\" : 28 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"node_network_receive_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}\" , \"legendFormat\" : \"Bytes Received\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"node_network_transmit_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}\" , \"hide\" : false , \"legendFormat\" : \"Bytes Transferred\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Bytes Received/Transferred\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Transfer Speed [$network_interface]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"Bps\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 8 , \"x\" : 8 , \"y\" : 6 }, \"id\" : 29 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"rate(node_network_receive_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}[5m])\" , \"instant\" : false , \"legendFormat\" : \"Receive Speed\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"rate(node_network_transmit_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$network_interface\\\"}[5m])\" , \"hide\" : false , \"legendFormat\" : \"Transmit Speed\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Transfer Speed\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"TCP Connections [$network_interface]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"short\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 8 , \"x\" : 16 , \"y\" : 6 }, \"id\" : 30 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"node_netstat_Tcp_CurrEstab\" , \"instant\" : false , \"legendFormat\" : \"Number of Connections\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"TCP Connections\" , \"type\" : \"timeseries\" }, { \"collapsed\" : false , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 14 }, \"id\" : 32 , \"panels\" : [], \"title\" : \"CPU Stats\" , \"type\" : \"row\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Core Frequency\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"rothz\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 11 , \"w\" : 8 , \"x\" : 0 , \"y\" : 15 }, \"id\" : 34 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"node_cpu_scaling_frequency_hertz\" , \"legendFormat\" : \"Core {{cpu}}\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Core Frequency\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Usage by Mode\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 11 , \"w\" : 8 , \"x\" : 8 , \"y\" : 15 }, \"id\" : 35 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" , \"sortBy\" : \"Max\" , \"sortDesc\" : true }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"system\\\"}[5m]) * 100) \" , \"instant\" : false , \"legendFormat\" : \"system\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"user\\\"}[5m]) * 100) \" , \"hide\" : false , \"legendFormat\" : \"user\" , \"range\" : true , \"refId\" : \"B\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"iowait\\\"}[5m]) * 100) \" , \"hide\" : false , \"legendFormat\" : \"iowait\" , \"range\" : true , \"refId\" : \"C\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"steal\\\"}[5m]) * 100) \" , \"hide\" : false , \"legendFormat\" : \"steal\" , \"range\" : true , \"refId\" : \"D\" } ], \"title\" : \"CPU Usage by Mode\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"CPU Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : false , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" , \"value\" : null } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 11 , \"w\" : 8 , \"x\" : 16 , \"y\" : 15 }, \"id\" : 36 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" , \"sortBy\" : \"Max\" , \"sortDesc\" : true }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"system\\\"}[5m]) * 100) + avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"user\\\"}[5m]) * 100) + avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"iowait\\\"}[5m]) * 100) + avg(rate(node_cpu_seconds_total{instance=\\\"$node\\\",job=\\\"$job\\\",mode=\\\"steal\\\"}[5m]) * 100) \" , \"instant\" : false , \"legendFormat\" : \"CPU Usage\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"CPU Usage\" , \"type\" : \"timeseries\" }, { \"collapsed\" : true , \"gridPos\" : { \"h\" : 1 , \"w\" : 24 , \"x\" : 0 , \"y\" : 26 }, \"id\" : 17 , \"panels\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Bytes Read/Written [$drive_name ]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : true , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 9 , \"x\" : 0 , \"y\" : 27 }, \"id\" : 19 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"rate(node_disk_read_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[5m])\" , \"instant\" : false , \"legendFormat\" : \"Bytes Read\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"rate(node_disk_written_bytes_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[5m])\" , \"hide\" : false , \"legendFormat\" : \"Bytes Written\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Bytes Read/Written\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"Disk IOps Completed [$drive_name ]\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"palette-classic\" }, \"custom\" : { \"axisLabel\" : \"\" , \"axisPlacement\" : \"auto\" , \"barAlignment\" : 0 , \"drawStyle\" : \"line\" , \"fillOpacity\" : 10 , \"gradientMode\" : \"none\" , \"hideFrom\" : { \"legend\" : false , \"tooltip\" : false , \"viz\" : false }, \"lineInterpolation\" : \"smooth\" , \"lineStyle\" : { \"fill\" : \"solid\" }, \"lineWidth\" : 1 , \"pointSize\" : 5 , \"scaleDistribution\" : { \"type\" : \"linear\" }, \"showPoints\" : \"never\" , \"spanNulls\" : true , \"stacking\" : { \"group\" : \"A\" , \"mode\" : \"none\" }, \"thresholdsStyle\" : { \"mode\" : \"off\" } }, \"decimals\" : 0 , \"mappings\" : [], \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" } ] }, \"unit\" : \"iops\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 8 , \"w\" : 9 , \"x\" : 9 , \"y\" : 27 }, \"id\" : 24 , \"options\" : { \"legend\" : { \"calcs\" : [ \"min\" , \"max\" , \"mean\" , \"lastNotNull\" ], \"displayMode\" : \"table\" , \"placement\" : \"bottom\" }, \"tooltip\" : { \"mode\" : \"multi\" , \"sort\" : \"none\" } }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"exemplar\" : false , \"expr\" : \"irate(node_disk_reads_completed_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[1m])\" , \"instant\" : false , \"legendFormat\" : \"Reads Completed\" , \"range\" : true , \"refId\" : \"A\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"irate(node_disk_writes_completed_total{instance=\\\"$node\\\",job=\\\"$job\\\",device=\\\"$drive_name\\\"}[1m])\" , \"hide\" : false , \"legendFormat\" : \"Writes Completed\" , \"range\" : true , \"refId\" : \"B\" } ], \"title\" : \"Disk IOps Completed\" , \"type\" : \"timeseries\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Total Size\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 18 , \"y\" : 27 }, \"id\" : 20 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"})\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Total Size\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Used Space\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"yellow\" } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 21 , \"y\" : 27 }, \"id\" : 22 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"}) - sum(node_filesystem_avail_bytes{device=~\\\".+$drive_name.?\\\"})\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Used Space\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Free Space\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"semi-dark-red\" }, { \"color\" : \"#EAB839\" , \"value\" : 20 }, { \"color\" : \"green\" , \"value\" : 50 } ] }, \"unit\" : \"decbytes\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 18 , \"y\" : 31 }, \"id\" : 21 , \"options\" : { \"colorMode\" : \"value\" , \"graphMode\" : \"none\" , \"justifyMode\" : \"auto\" , \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"textMode\" : \"auto\" }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"sum(node_filesystem_avail_bytes{device=~\\\".+$drive_name.?\\\"})\" , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Free Space\" , \"type\" : \"stat\" }, { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"description\" : \"$drive_name Disk Usage\" , \"fieldConfig\" : { \"defaults\" : { \"color\" : { \"mode\" : \"thresholds\" }, \"decimals\" : 0 , \"mappings\" : [], \"max\" : 100 , \"min\" : 0 , \"noValue\" : \"N/A\" , \"thresholds\" : { \"mode\" : \"absolute\" , \"steps\" : [ { \"color\" : \"green\" }, { \"color\" : \"#EAB839\" , \"value\" : 75 }, { \"color\" : \"semi-dark-red\" , \"value\" : 90 } ] }, \"unit\" : \"percent\" }, \"overrides\" : [] }, \"gridPos\" : { \"h\" : 4 , \"w\" : 3 , \"x\" : 21 , \"y\" : 31 }, \"id\" : 23 , \"options\" : { \"orientation\" : \"horizontal\" , \"reduceOptions\" : { \"calcs\" : [ \"lastNotNull\" ], \"fields\" : \"\" , \"values\" : false }, \"showThresholdLabels\" : false , \"showThresholdMarkers\" : true , \"text\" : {} }, \"pluginVersion\" : \"8.5.3\" , \"targets\" : [ { \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"editorMode\" : \"code\" , \"expr\" : \"((sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"}) - sum(node_filesystem_avail_bytes{device=~\\\".+$drive_name.?\\\"})) / sum(node_filesystem_size_bytes{device=~\\\".+$drive_name.?\\\"})) * 100\" , \"hide\" : false , \"range\" : true , \"refId\" : \"A\" } ], \"title\" : \"Disk Usage\" , \"type\" : \"gauge\" } ], \"repeat\" : \"drive_name\" , \"title\" : \"Drive Stats for /dev/$drive_name\" , \"type\" : \"row\" } ], \"refresh\" : \"10s\" , \"schemaVersion\" : 36 , \"style\" : \"dark\" , \"tags\" : [ \"linux\" , \"node-exporter\" ], \"templating\" : { \"list\" : [ { \"current\" : { \"selected\" : false , \"text\" : \"node\" , \"value\" : \"node\" }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_uname_info, job)\" , \"hide\" : 0 , \"includeAll\" : false , \"label\" : \"Job\" , \"multi\" : false , \"name\" : \"job\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_uname_info, job)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 1 , \"type\" : \"query\" }, { \"current\" : { \"selected\" : false , \"text\" : \"host.docker.internal:9100\" , \"value\" : \"host.docker.internal:9100\" }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_uname_info{job=\\\"$job\\\"}, instance)\" , \"hide\" : 0 , \"includeAll\" : false , \"label\" : \"Host\" , \"multi\" : false , \"name\" : \"node\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_uname_info{job=\\\"$job\\\"}, instance)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 1 , \"type\" : \"query\" }, { \"current\" : { \"selected\" : false , \"text\" : \"enp2s0\" , \"value\" : \"enp2s0\" }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_network_info{operstate=\\\"up\\\"}, device)\" , \"hide\" : 0 , \"includeAll\" : false , \"label\" : \"NIC\" , \"multi\" : false , \"name\" : \"network_interface\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_network_info{operstate=\\\"up\\\"}, device)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 0 , \"type\" : \"query\" }, { \"current\" : { \"selected\" : true , \"text\" : [ \"All\" ], \"value\" : [ \"$__all\" ] }, \"datasource\" : { \"type\" : \"prometheus\" , \"uid\" : \"UCHnO3Wgz\" }, \"definition\" : \"label_values(node_disk_info, device)\" , \"description\" : \"Drive /dev/sdX\" , \"hide\" : 0 , \"includeAll\" : true , \"label\" : \"Drive\" , \"multi\" : true , \"name\" : \"drive_name\" , \"options\" : [], \"query\" : { \"query\" : \"label_values(node_disk_info, device)\" , \"refId\" : \"StandardVariableQuery\" }, \"refresh\" : 1 , \"regex\" : \"\" , \"skipUrlSync\" : false , \"sort\" : 1 , \"type\" : \"query\" } ] }, \"time\" : { \"from\" : \"now-5m\" , \"to\" : \"now\" }, \"timepicker\" : { \"refresh_intervals\" : [ \"10s\" , \"1m\" , \"5m\" , \"15m\" , \"30m\" ] }, \"timezone\" : \"browser\" , \"title\" : \"Server Dashboard\" , \"uid\" : \"iUjT2qZgz\" , \"version\" : 9 , \"weekStart\" : \"\" } This dashboard will look similar to this:","title":"Add a Dashboard"},{"location":"server-monitoring/in-monitor/grafana/#final-touches","text":"Before saying we're done we would like to autostart this dashboard on system startup. For this we'll need to install the Auto fullscreen Firefox addon so that every time we open the browser it opens on fullscreen mode. We'll also make the following URL the home page of the browser: http://localhost:3000/d/iUjT2qZgz/server-dashboard?orgid=1&refresh=10s&kiosk Note Make sure to replace this URL with the one for your actual dashboard. Finally, to autostart firefox, create the following file: nano ~/.xinitrc And add the following text inside: awesome & firefox","title":"Final Touches"},{"location":"server-monitoring/in-monitor/portainer-agent/","text":"Portainer (Agent) \u00b6 Portainer is a web UI for Docker which allows us to have an insight on all the containers running on our server. An agent is a service that can expose a particular Docker server through Portainer hosted on another machine. In this case we'll use this to manage the monitor's Docker service. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/portainer-agent Now, head over to the Portainer web dashboard and access: Settings > Environments > Add environment > Docker Standalone > Edge Client Set a name for it and make sure that the Portainer URL is accessible by the agent, then click Create . You will get a preview of a docker command with two environment variables: EDGE_ID and EDGE_KEY . Save these values because we'll need them later. Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : agent : image : portainer/agent:latest restart : unless-stopped volumes : - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes - /:/host - ./data:/data environment : - TZ=America/Guayaquil - EDGE=1 - EDGE_ID=CHANGE_ME - EDGE_KEY=CHANGE_ME - EDGE_INSECURE_POLL=1 Note Replace CHANGE_ME with the appropriate variables taken before. Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Portainer (Agent)"},{"location":"server-monitoring/in-monitor/portainer-agent/#portainer-agent","text":"Portainer is a web UI for Docker which allows us to have an insight on all the containers running on our server. An agent is a service that can expose a particular Docker server through Portainer hosted on another machine. In this case we'll use this to manage the monitor's Docker service. This service has an official image on Docker Hub which we'll use.","title":"Portainer (Agent)"},{"location":"server-monitoring/in-monitor/portainer-agent/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/portainer-agent Now, head over to the Portainer web dashboard and access: Settings > Environments > Add environment > Docker Standalone > Edge Client Set a name for it and make sure that the Portainer URL is accessible by the agent, then click Create . You will get a preview of a docker command with two environment variables: EDGE_ID and EDGE_KEY . Save these values because we'll need them later.","title":"Pre-Installation"},{"location":"server-monitoring/in-monitor/portainer-agent/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : agent : image : portainer/agent:latest restart : unless-stopped volumes : - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes - /:/host - ./data:/data environment : - TZ=America/Guayaquil - EDGE=1 - EDGE_ID=CHANGE_ME - EDGE_KEY=CHANGE_ME - EDGE_INSECURE_POLL=1 Note Replace CHANGE_ME with the appropriate variables taken before.","title":"Docker Compose"},{"location":"server-monitoring/in-monitor/portainer-agent/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"server-monitoring/in-server/","text":"Initialization \u00b6 The following guides should be followed inside the main server machine. This also assumes that the Monitoring section has been followed, since the Prometheus service will be saved in the monitoring folder.","title":"Initialization"},{"location":"server-monitoring/in-server/#initialization","text":"The following guides should be followed inside the main server machine. This also assumes that the Monitoring section has been followed, since the Prometheus service will be saved in the monitoring folder.","title":"Initialization"},{"location":"server-monitoring/in-server/prometheus/","text":"Prometheus \u00b6 Prometheus is a time series database for monitoring systems, this will serve as the backend of the monitoring service. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/prometheus Inside this folder, create a data folder: mkdir data And also, create a prometheus.yml file: nano prometheus.yml Which should have the following: global : scrape_interval : 15s scrape_configs : - job_name : \"prometheus\" scrape_interval : 15s static_configs : - targets : [ \"localhost:9090\" ] - job_name : \"node\" static_configs : - targets : [ \"host.docker.internal:9100\" ] Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : exporter : image : prom/node-exporter:latest restart : unless-stopped user : '1000:1000' network_mode : host volumes : - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command : - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' prometheus : image : prom/prometheus:latest restart : unless-stopped user : '1000:1000' extra_hosts : - 'host.docker.internal:host-gateway' ports : - 9090:9090 volumes : - ./prometheus.yml:/etc/prometheus/prometheus.yml - ./data:/prometheus command : - '--config.file=/etc/prometheus/prometheus.yml' - '--storage.tsdb.path=/prometheus' - '--web.console.libraries=/etc/prometheus/console_libraries' - '--web.console.templates=/etc/prometheus/consoles' - '--web.enable-lifecycle' Note The exporter service needs to have network_mode: host in order to have access to the main network interface to actually have valid network usage data. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 9090 /tcp sudo ufw allow 9100 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Prometheus"},{"location":"server-monitoring/in-server/prometheus/#prometheus","text":"Prometheus is a time series database for monitoring systems, this will serve as the backend of the monitoring service. This service has an official image on Docker Hub which we'll use.","title":"Prometheus"},{"location":"server-monitoring/in-server/prometheus/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/prometheus Inside this folder, create a data folder: mkdir data And also, create a prometheus.yml file: nano prometheus.yml Which should have the following: global : scrape_interval : 15s scrape_configs : - job_name : \"prometheus\" scrape_interval : 15s static_configs : - targets : [ \"localhost:9090\" ] - job_name : \"node\" static_configs : - targets : [ \"host.docker.internal:9100\" ]","title":"Pre-Installation"},{"location":"server-monitoring/in-server/prometheus/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : exporter : image : prom/node-exporter:latest restart : unless-stopped user : '1000:1000' network_mode : host volumes : - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command : - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' prometheus : image : prom/prometheus:latest restart : unless-stopped user : '1000:1000' extra_hosts : - 'host.docker.internal:host-gateway' ports : - 9090:9090 volumes : - ./prometheus.yml:/etc/prometheus/prometheus.yml - ./data:/prometheus command : - '--config.file=/etc/prometheus/prometheus.yml' - '--storage.tsdb.path=/prometheus' - '--web.console.libraries=/etc/prometheus/console_libraries' - '--web.console.templates=/etc/prometheus/consoles' - '--web.enable-lifecycle' Note The exporter service needs to have network_mode: host in order to have access to the main network interface to actually have valid network usage data.","title":"Docker Compose"},{"location":"server-monitoring/in-server/prometheus/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 9090 /tcp sudo ufw allow 9100 /tcp","title":"Post-Installation"},{"location":"server-monitoring/in-server/prometheus/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/cloudflared/","text":"Cloudflared (Native) \u00b6 Cloudflared is a daemon that allows to manage Cloudflare Argo Tunnel . We'll use this to expose our web services through Cloudflare without the need to port forward and expose our home network directly. Installation \u00b6 To install Cloudflared : wget -q https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.deb sudo dpkg -i cloudflared-stable-linux-amd64.deb Authenticating \u00b6 We now need to authenticate with Cloudflare, for this run: cloudflared tunnel login A link will be displayed on the console. Visit it on any browser, login and select the zone you wish to enable Argo Tunnel for. This will create a cert.pem file inside ~/.cloudflared . Creating a Tunnel \u00b6 We can create as many tunnels as we want. Generally one tunnel per DNS zone should suffice. To create a tunnel, run: cloudflared tunnel create <NAME> Note Replace <NAME> with the desired name for your tunnel. Once done, this will create a .json file inside ~/.cloudflared that contains the tunnel credentials. Pre-Configuration \u00b6 Since we'll create two different tunnels for two different domains, we'll create a folder in ~/.cloudflared with the name of the tunnel lower-cased, where we'll move cert.pem and UUID.json files. Configuration \u00b6 Inside ~/.cloudflared/<name> we'll create a config.yml file with the configuration of our tunnel. tunnel : TUNNEL_ID credentials-file : /home/USER/.cloudflared/NAME/TUNNEL_ID.json ingress : - hostname : subdomain.domain.com service : http://localhost:port - hostname : subdomain.domain.com service : http://localhost:port - service : http_status:404 Note You can add as many hostname/service pairs as you want. Running \u00b6 You can run the tunnel with: cloudflared tunnel --config ~/.cloudflared/name/config.yml --origincert ~/.cloudflared/name/cert.pem run Auto-starting \u00b6 To auto-start the tunnel, create a service file: sudo nano /etc/systemd/system/cloudflared_name.service And add the following: [Unit] Description=Cloudflared Tunnel for $NAME After=network.target [Service] Type=simple User=$USER WorkingDirectory=/home/$USER/.cloudflared/$NAME ExecStart=/usr/local/bin/cloudflared tunnel --config ./config.yml --origincert ./cert.pem run Restart=always [Install] WantedBy=multi-user.target Note Replace $USER and $NAME with the correct values for your tunnel. Once saved, start and enable the service. sudo systemctl start cloudflared_name.service sudo systemctl enable cloudflared_name.service Last Words \u00b6 Repeat the process from Authenticating for each tunnel created.","title":"Cloudflared (Native)"},{"location":"services/cloudflared/#cloudflared-native","text":"Cloudflared is a daemon that allows to manage Cloudflare Argo Tunnel . We'll use this to expose our web services through Cloudflare without the need to port forward and expose our home network directly.","title":"Cloudflared (Native)"},{"location":"services/cloudflared/#installation","text":"To install Cloudflared : wget -q https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.deb sudo dpkg -i cloudflared-stable-linux-amd64.deb","title":"Installation"},{"location":"services/cloudflared/#authenticating","text":"We now need to authenticate with Cloudflare, for this run: cloudflared tunnel login A link will be displayed on the console. Visit it on any browser, login and select the zone you wish to enable Argo Tunnel for. This will create a cert.pem file inside ~/.cloudflared .","title":"Authenticating"},{"location":"services/cloudflared/#creating-a-tunnel","text":"We can create as many tunnels as we want. Generally one tunnel per DNS zone should suffice. To create a tunnel, run: cloudflared tunnel create <NAME> Note Replace <NAME> with the desired name for your tunnel. Once done, this will create a .json file inside ~/.cloudflared that contains the tunnel credentials.","title":"Creating a Tunnel"},{"location":"services/cloudflared/#pre-configuration","text":"Since we'll create two different tunnels for two different domains, we'll create a folder in ~/.cloudflared with the name of the tunnel lower-cased, where we'll move cert.pem and UUID.json files.","title":"Pre-Configuration"},{"location":"services/cloudflared/#configuration","text":"Inside ~/.cloudflared/<name> we'll create a config.yml file with the configuration of our tunnel. tunnel : TUNNEL_ID credentials-file : /home/USER/.cloudflared/NAME/TUNNEL_ID.json ingress : - hostname : subdomain.domain.com service : http://localhost:port - hostname : subdomain.domain.com service : http://localhost:port - service : http_status:404 Note You can add as many hostname/service pairs as you want.","title":"Configuration"},{"location":"services/cloudflared/#running","text":"You can run the tunnel with: cloudflared tunnel --config ~/.cloudflared/name/config.yml --origincert ~/.cloudflared/name/cert.pem run","title":"Running"},{"location":"services/cloudflared/#auto-starting","text":"To auto-start the tunnel, create a service file: sudo nano /etc/systemd/system/cloudflared_name.service And add the following: [Unit] Description=Cloudflared Tunnel for $NAME After=network.target [Service] Type=simple User=$USER WorkingDirectory=/home/$USER/.cloudflared/$NAME ExecStart=/usr/local/bin/cloudflared tunnel --config ./config.yml --origincert ./cert.pem run Restart=always [Install] WantedBy=multi-user.target Note Replace $USER and $NAME with the correct values for your tunnel. Once saved, start and enable the service. sudo systemctl start cloudflared_name.service sudo systemctl enable cloudflared_name.service","title":"Auto-starting"},{"location":"services/cloudflared/#last-words","text":"Repeat the process from Authenticating for each tunnel created.","title":"Last Words"},{"location":"services/samba/","text":"Samba (Native) \u00b6 Samba lets your Linux based server share files and folders on a Windows File Sharing Workgroup using the same protocol (SMB/CIFS), this is pretty useful when you need to share files between computers on your network. This also helps to allow your files to be accessed through the Internet (although it should only be done through a VPN for security purposes). Installation \u00b6 To install Samba : sudo apt-get install samba Configuring \u00b6 We'll make a folder on our 2TB SATA hard drive directory, this will serve as the share folder which will be accessible through SMB . mkdir /media/sata_2tb/sambashare We now need to add this folder entry to the configuration. Open up Samba 's config file. sudo nano /etc/samba/smb.conf Now we'll add the folder we created alongside other directories to the Samba share (note that you should replace these directories corresponding to your needs). You can add as many entries as you need as long as they're well formatted. [sambashare] comment = Samba shared folder path = /media/sata_2tb/sambashare read only = no browsable = yes writeable = yes Now we restart the Samba service to apply the changes: sudo service smbd restart Before trying to access the share with another computer, we'll need to add a password to the Samba user. Use the next command and replace $USER with your username. sudo smbpasswd -a $USER Now, as a final step, add the firewall rule to allow SMB connections. sudo ufw allow 445 /tcp Issues with Permissions on Windows \u00b6 In case you try to access a shared folder that doesn't have the corresponding permissions to allow the Windows user to manage said folder, you can add the following directives to each shared folder block in the config file: create umask = 0777 directory umask = 0777 Shared Folders that Contain Symlinks \u00b6 If one of your shared folders has symlinks in them and you need to share them too, add the following directives to the shared folder block in the config file: follow symlinks = yes wide links = yes Browsing a Shared Folder as a Specified User \u00b6 If you want your shared folder to be accessed as a certain user, add the following directive to the shared folder block in the config file: force user = $USER Note Replace $USER with the UNIX username required.","title":"Samba (Native)"},{"location":"services/samba/#samba-native","text":"Samba lets your Linux based server share files and folders on a Windows File Sharing Workgroup using the same protocol (SMB/CIFS), this is pretty useful when you need to share files between computers on your network. This also helps to allow your files to be accessed through the Internet (although it should only be done through a VPN for security purposes).","title":"Samba (Native)"},{"location":"services/samba/#installation","text":"To install Samba : sudo apt-get install samba","title":"Installation"},{"location":"services/samba/#configuring","text":"We'll make a folder on our 2TB SATA hard drive directory, this will serve as the share folder which will be accessible through SMB . mkdir /media/sata_2tb/sambashare We now need to add this folder entry to the configuration. Open up Samba 's config file. sudo nano /etc/samba/smb.conf Now we'll add the folder we created alongside other directories to the Samba share (note that you should replace these directories corresponding to your needs). You can add as many entries as you need as long as they're well formatted. [sambashare] comment = Samba shared folder path = /media/sata_2tb/sambashare read only = no browsable = yes writeable = yes Now we restart the Samba service to apply the changes: sudo service smbd restart Before trying to access the share with another computer, we'll need to add a password to the Samba user. Use the next command and replace $USER with your username. sudo smbpasswd -a $USER Now, as a final step, add the firewall rule to allow SMB connections. sudo ufw allow 445 /tcp","title":"Configuring"},{"location":"services/samba/#issues-with-permissions-on-windows","text":"In case you try to access a shared folder that doesn't have the corresponding permissions to allow the Windows user to manage said folder, you can add the following directives to each shared folder block in the config file: create umask = 0777 directory umask = 0777","title":"Issues with Permissions on Windows"},{"location":"services/samba/#shared-folders-that-contain-symlinks","text":"If one of your shared folders has symlinks in them and you need to share them too, add the following directives to the shared folder block in the config file: follow symlinks = yes wide links = yes","title":"Shared Folders that Contain Symlinks"},{"location":"services/samba/#browsing-a-shared-folder-as-a-specified-user","text":"If you want your shared folder to be accessed as a certain user, add the following directive to the shared folder block in the config file: force user = $USER Note Replace $USER with the UNIX username required.","title":"Browsing a Shared Folder as a Specified User"},{"location":"services/analytics/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to analytics servers. mkdir ~/analytics For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/analytics/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to analytics servers. mkdir ~/analytics For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/analytics/plausible/","text":"Plausible \u00b6 Plausible is a Web analytics dashboard. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the analytics server's data will be saved. mkdir ~/analytics/plausible Next, create a folder for the Clickhouse configs inside this new folder: mkdir clickhouse And create the following files: nano clickhouse/clickhouse-config.xml <clickhouse> <logger> <level> warning </level> <console> true </console> </logger> <!-- Stop all the unnecessary logging --> <query_thread_log remove= \"remove\" /> <query_log remove= \"remove\" /> <text_log remove= \"remove\" /> <trace_log remove= \"remove\" /> <metric_log remove= \"remove\" /> <asynchronous_metric_log remove= \"remove\" /> <session_log remove= \"remove\" /> <part_log remove= \"remove\" /> </clickhouse> nano clickhouse/clickhouse-user-config.xml <clickhouse> <profiles> <default> <log_queries> 0 </log_queries> <log_query_threads> 0 </log_query_threads> </default> </profiles> </clickhouse> And now change the permissions for this folder: chmod -R 777 clickhouse Docker Compose \u00b6 Plausible will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : plausible : image : plausible/analytics:v1 restart : unless-stopped command : sh -c \"sleep 10 && /entrypoint.sh db createdb && /entrypoint.sh db migrate && /entrypoint.sh run\" depends_on : - db - events_db ports : - 10500:80 environment : - TZ=America/Guayaquil - BASE_URL=CHANGE_THIS_URL - PORT=80 - SECRET_KEY_BASE=CHANGE_THIS_SECRET_KEY - DISABLE_REGISTRATION=true - DATABASE_URL=postgres://plausible:CHANGE_THIS_DB_PASS@db/plausible?sslmode=disable - CLICKHOUSE_DATABASE_URL=http://events_db:8123/plausible_events_db db : image : postgres:14-alpine restart : unless-stopped volumes : - ./db-data:/var/lib/postgresql/data environment : - POSTGRES_USER=plausible - POSTGRES_PASSWORD=CHANGE_THIS_DB_PASS events_db : image : clickhouse/clickhouse-server:22-alpine restart : unless-stopped volumes : - ./events-data:/var/lib/clickhouse - ./clickhouse/clickhouse-config.xml:/etc/clickhouse-server/config.d/logging.xml:ro - ./clickhouse/clickhouse-user-config.xml:/etc/clickhouse-server/users.d/logging.xml:ro ulimits : nofile : soft : 262144 hard : 262144 environment : - CLICKHOUSE_DB=plausible_events_db Note Make sure to change CHANGE_THIS_URL with the URL of where this service will be hosted with protocol. For instance, https://analytics.example.com . Make sure to change CHANGE_THIS_DB_PASS with anything you want. Make sure to change CHANGE_THIS_SECRET_KEY with a random key. You may use the openssl rand -hex 64 command to generate one. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 10500 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Plausible"},{"location":"services/analytics/plausible/#plausible","text":"Plausible is a Web analytics dashboard. This service has an official image available on Docker Hub which we'll use.","title":"Plausible"},{"location":"services/analytics/plausible/#pre-installation","text":"We'll create a folder in the main user's home where all the analytics server's data will be saved. mkdir ~/analytics/plausible Next, create a folder for the Clickhouse configs inside this new folder: mkdir clickhouse And create the following files: nano clickhouse/clickhouse-config.xml <clickhouse> <logger> <level> warning </level> <console> true </console> </logger> <!-- Stop all the unnecessary logging --> <query_thread_log remove= \"remove\" /> <query_log remove= \"remove\" /> <text_log remove= \"remove\" /> <trace_log remove= \"remove\" /> <metric_log remove= \"remove\" /> <asynchronous_metric_log remove= \"remove\" /> <session_log remove= \"remove\" /> <part_log remove= \"remove\" /> </clickhouse> nano clickhouse/clickhouse-user-config.xml <clickhouse> <profiles> <default> <log_queries> 0 </log_queries> <log_query_threads> 0 </log_query_threads> </default> </profiles> </clickhouse> And now change the permissions for this folder: chmod -R 777 clickhouse","title":"Pre-Installation"},{"location":"services/analytics/plausible/#docker-compose","text":"Plausible will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : plausible : image : plausible/analytics:v1 restart : unless-stopped command : sh -c \"sleep 10 && /entrypoint.sh db createdb && /entrypoint.sh db migrate && /entrypoint.sh run\" depends_on : - db - events_db ports : - 10500:80 environment : - TZ=America/Guayaquil - BASE_URL=CHANGE_THIS_URL - PORT=80 - SECRET_KEY_BASE=CHANGE_THIS_SECRET_KEY - DISABLE_REGISTRATION=true - DATABASE_URL=postgres://plausible:CHANGE_THIS_DB_PASS@db/plausible?sslmode=disable - CLICKHOUSE_DATABASE_URL=http://events_db:8123/plausible_events_db db : image : postgres:14-alpine restart : unless-stopped volumes : - ./db-data:/var/lib/postgresql/data environment : - POSTGRES_USER=plausible - POSTGRES_PASSWORD=CHANGE_THIS_DB_PASS events_db : image : clickhouse/clickhouse-server:22-alpine restart : unless-stopped volumes : - ./events-data:/var/lib/clickhouse - ./clickhouse/clickhouse-config.xml:/etc/clickhouse-server/config.d/logging.xml:ro - ./clickhouse/clickhouse-user-config.xml:/etc/clickhouse-server/users.d/logging.xml:ro ulimits : nofile : soft : 262144 hard : 262144 environment : - CLICKHOUSE_DB=plausible_events_db Note Make sure to change CHANGE_THIS_URL with the URL of where this service will be hosted with protocol. For instance, https://analytics.example.com . Make sure to change CHANGE_THIS_DB_PASS with anything you want. Make sure to change CHANGE_THIS_SECRET_KEY with a random key. You may use the openssl rand -hex 64 command to generate one.","title":"Docker Compose"},{"location":"services/analytics/plausible/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 10500 /tcp","title":"Post-Installation"},{"location":"services/analytics/plausible/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/automation/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to automation related services. mkdir ~/automation For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/automation/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to automation related services. mkdir ~/automation For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/automation/automation-service/","text":"Custom Automation Service \u00b6 I decided to drop n8n in favor of my own custom automation service . This service is completely custom made for my needs so chances are this will not be of any use for you. If that is the case, you should probably stick to n8n . The only reason I went out of my way to create my own service was because I was finding myself using way too much the Code node in n8n. Given this, maintaining my workflows wasn't really that easy and at this point it would be a lot better for me to just maintain an actual code based workflow system rather than the workflows I had there. This service has an Docker image hosted on GitHub Packages which will be used. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/automation/automation-service Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : service : image : ghcr.io/moonstar-x/automation-service:latest restart : unless-stopped user : 1000:1000 volumes : - ./data:/opt/app/data - ./config:/opt/app/config ports : - 5678:5678 environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 5678 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Custom Automation Service"},{"location":"services/automation/automation-service/#custom-automation-service","text":"I decided to drop n8n in favor of my own custom automation service . This service is completely custom made for my needs so chances are this will not be of any use for you. If that is the case, you should probably stick to n8n . The only reason I went out of my way to create my own service was because I was finding myself using way too much the Code node in n8n. Given this, maintaining my workflows wasn't really that easy and at this point it would be a lot better for me to just maintain an actual code based workflow system rather than the workflows I had there. This service has an Docker image hosted on GitHub Packages which will be used.","title":"Custom Automation Service"},{"location":"services/automation/automation-service/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/automation/automation-service","title":"Pre-Installation"},{"location":"services/automation/automation-service/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : service : image : ghcr.io/moonstar-x/automation-service:latest restart : unless-stopped user : 1000:1000 volumes : - ./data:/opt/app/data - ./config:/opt/app/config ports : - 5678:5678 environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/automation/automation-service/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 5678 /tcp","title":"Post-Installation"},{"location":"services/automation/automation-service/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/data/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to data servers. mkdir ~/data For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/data/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to data servers. mkdir ~/data For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/data/gitea/","text":"Gitea \u00b6 Gitea is a self-hosted git server, useful for having a private VCS solution. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/gitea Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : gitea : image : gitea/gitea:latest restart : unless-stopped volumes : - ./data:/data ports : - 3000:3000 depends_on : - db environment : - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=gitea - MYSQL_USER=gitea - MYSQL_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3000 /tcp Once you have started the server once, edit the config file located inside the data volume: nano data/gitea/conf/app.ini And make sure to have the following lines: [service] DISABLE_REGISTRATION = true This will make sure that nobody else can register into your server without your knowledge. Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Gitea"},{"location":"services/data/gitea/#gitea","text":"Gitea is a self-hosted git server, useful for having a private VCS solution. This service has an official image on Docker Hub which we'll use.","title":"Gitea"},{"location":"services/data/gitea/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/gitea","title":"Pre-Installation"},{"location":"services/data/gitea/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : gitea : image : gitea/gitea:latest restart : unless-stopped volumes : - ./data:/data ports : - 3000:3000 depends_on : - db environment : - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=gitea - MYSQL_USER=gitea - MYSQL_PASSWORD=CHANGE_THIS Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/data/gitea/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3000 /tcp Once you have started the server once, edit the config file located inside the data volume: nano data/gitea/conf/app.ini And make sure to have the following lines: [service] DISABLE_REGISTRATION = true This will make sure that nobody else can register into your server without your knowledge.","title":"Post-Installation"},{"location":"services/data/gitea/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/data/jenkins/","text":"Jenkins \u00b6 Jenkins is a CI/CD service. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/jenkins Agent Dockerfile \u00b6 We'll use a custom Dockerfile to create an agent that has the necessary dependencies installed. First, create a new folder for the agent's data. mkdir agent Then, we'll generate an SSH key that Jenkins will use to connect to the agent. ssh-keygen agent/jenkins_agent_key Now, run the following command: id And check for the ID of the docker group. In this case, this value is 998 . Next, we'll add a Dockerfile for the agent: FROM jenkins/ssh-agent:jdk11 USER root RUN groupadd -g 998 docker RUN apt-get update -qq RUN apt-get install -qqy apt-transport-https ca-certificates curl gnupg2 software-properties-common RUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg RUN echo \\ \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\ $( lsb_release -cs ) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null RUN apt-get update -qq && apt-get -y install docker-ce RUN usermod -aG docker jenkins Make sure to add the generated private key as a Credential inside Jenkins as an SSH Username with private key with jenkins as the username. Docker Compose \u00b6 Jenkins will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jenkins : image : jenkins/jenkins:lts restart : unless-stopped volumes : - ./data:/var/jenkins_home ports : - 10800:8080 environment : - TZ=America/Guayaquil agent : build : ./agent/ restart : unless-stopped depends_on : - jenkins volumes : - /var/run/docker.sock:/var/run/docker.sock environment : - TZ=America/Guayaquil - JENKINS_AGENT_SSH_PUBKEY=ssh-rsa SECRET_REPLACE_THIS Post-Installation \u00b6 To avoid permission issues, create the data folder that will be used as a volume: mkdir data We'll need to allow the service's port on our firewall. sudo ufw allow 10800 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Jenkins"},{"location":"services/data/jenkins/#jenkins","text":"Jenkins is a CI/CD service. This service has an official image available on Docker Hub which we'll use.","title":"Jenkins"},{"location":"services/data/jenkins/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/jenkins","title":"Pre-Installation"},{"location":"services/data/jenkins/#agent-dockerfile","text":"We'll use a custom Dockerfile to create an agent that has the necessary dependencies installed. First, create a new folder for the agent's data. mkdir agent Then, we'll generate an SSH key that Jenkins will use to connect to the agent. ssh-keygen agent/jenkins_agent_key Now, run the following command: id And check for the ID of the docker group. In this case, this value is 998 . Next, we'll add a Dockerfile for the agent: FROM jenkins/ssh-agent:jdk11 USER root RUN groupadd -g 998 docker RUN apt-get update -qq RUN apt-get install -qqy apt-transport-https ca-certificates curl gnupg2 software-properties-common RUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg RUN echo \\ \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\ $( lsb_release -cs ) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null RUN apt-get update -qq && apt-get -y install docker-ce RUN usermod -aG docker jenkins Make sure to add the generated private key as a Credential inside Jenkins as an SSH Username with private key with jenkins as the username.","title":"Agent Dockerfile"},{"location":"services/data/jenkins/#docker-compose","text":"Jenkins will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jenkins : image : jenkins/jenkins:lts restart : unless-stopped volumes : - ./data:/var/jenkins_home ports : - 10800:8080 environment : - TZ=America/Guayaquil agent : build : ./agent/ restart : unless-stopped depends_on : - jenkins volumes : - /var/run/docker.sock:/var/run/docker.sock environment : - TZ=America/Guayaquil - JENKINS_AGENT_SSH_PUBKEY=ssh-rsa SECRET_REPLACE_THIS","title":"Docker Compose"},{"location":"services/data/jenkins/#post-installation","text":"To avoid permission issues, create the data folder that will be used as a volume: mkdir data We'll need to allow the service's port on our firewall. sudo ufw allow 10800 /tcp","title":"Post-Installation"},{"location":"services/data/jenkins/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/data/nextcloud/","text":"Nextcloud \u00b6 Nextcloud is a self-hosted cloud data server, useful for keeping documents in your own server. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/nextcloud Dockerfile \u00b6 Despite the service having an official image available, it lacks a dependency necessary to allow for SMB shares as external storage. The following is the (tiny) Dockerfile that will be used for this service: FROM nextcloud:stable RUN apt-get update && apt-get install -y procps smbclient && rm -rf /var/lib/apt/lists/* Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : nextcloud : build : . restart : unless-stopped volumes : - /media/sata_2tb/Nextcloud:/var/www/html ports : - 9020:80 depends_on : - db environment : - TZ=America/Guayaquil - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud - MYSQL_PASSWORD=CHANGE_THIS - MYSQL_HOST=db db : image : mariadb:10.5 restart : unless-stopped command : --transaction-isolation=READ-COMMITTED --binlog-format=ROW volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud - MYSQL_PASSWORD=CHANGE_THIS cron : image : nextcloud:stable restart : unless-stopped depends_on : - nextcloud volumes : - /media/sata_2tb/Nextcloud:/var/www/html entrypoint : /cron.sh environment : - TZ=America/Guayaquil Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 9020 /tcp We'll also need to add the user to the www-data group to allow access to the data being uploaded inside the service: sudo usermod -aG www-data $USER Additionally, you may need to change the /media/sata_2tb/Nextcloud/config/config.php file. Make sure to have the correct array of trusted_domains , to update the overwrite.cli.url to the correct URL where the service will be accessible from, and include the following line: 'overwriteprotocol' => 'https', Inside Nextcloud, some applications should be installed, notably the Group Shared Folder one, which allows to quickly share folders with multiple users internally. Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Nextcloud"},{"location":"services/data/nextcloud/#nextcloud","text":"Nextcloud is a self-hosted cloud data server, useful for keeping documents in your own server. This service has an official image on Docker Hub which we'll use.","title":"Nextcloud"},{"location":"services/data/nextcloud/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/data/nextcloud","title":"Pre-Installation"},{"location":"services/data/nextcloud/#dockerfile","text":"Despite the service having an official image available, it lacks a dependency necessary to allow for SMB shares as external storage. The following is the (tiny) Dockerfile that will be used for this service: FROM nextcloud:stable RUN apt-get update && apt-get install -y procps smbclient && rm -rf /var/lib/apt/lists/*","title":"Dockerfile"},{"location":"services/data/nextcloud/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : nextcloud : build : . restart : unless-stopped volumes : - /media/sata_2tb/Nextcloud:/var/www/html ports : - 9020:80 depends_on : - db environment : - TZ=America/Guayaquil - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud - MYSQL_PASSWORD=CHANGE_THIS - MYSQL_HOST=db db : image : mariadb:10.5 restart : unless-stopped command : --transaction-isolation=READ-COMMITTED --binlog-format=ROW volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud - MYSQL_PASSWORD=CHANGE_THIS cron : image : nextcloud:stable restart : unless-stopped depends_on : - nextcloud volumes : - /media/sata_2tb/Nextcloud:/var/www/html entrypoint : /cron.sh environment : - TZ=America/Guayaquil Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/data/nextcloud/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 9020 /tcp We'll also need to add the user to the www-data group to allow access to the data being uploaded inside the service: sudo usermod -aG www-data $USER Additionally, you may need to change the /media/sata_2tb/Nextcloud/config/config.php file. Make sure to have the correct array of trusted_domains , to update the overwrite.cli.url to the correct URL where the service will be accessible from, and include the following line: 'overwriteprotocol' => 'https', Inside Nextcloud, some applications should be installed, notably the Group Shared Folder one, which allows to quickly share folders with multiple users internally.","title":"Post-Installation"},{"location":"services/data/nextcloud/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/docker/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to docker related services. mkdir ~/docker For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/docker/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to docker related services. mkdir ~/docker For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/docker/fleet/","text":"Fleet \u00b6 Fleet is a web UI that displays maintained Docker images from our own repositories, it serves a central place to display all your docker images. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/fleet Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : fleet : image : ghcr.io/linuxserver/fleet:latest restart : unless-stopped volumes : - ./config:/config ports : - 8080:8080 depends_on : - db environment : - PUID=1000 - PGID=1000 - fleet_admin_authentication_type=DATABASE - fleet_database_url=jdbc:mariadb://db/fleet - fleet_database_username=fleet - fleet_database_password=CHANGE_THIS - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=fleet - MYSQL_USER=fleet - MYSQL_PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8080 /tcp The default user and password are: admin : admin , you should create a new user and remove this initial admin user. Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Fleet"},{"location":"services/docker/fleet/#fleet","text":"Fleet is a web UI that displays maintained Docker images from our own repositories, it serves a central place to display all your docker images. This service has an official image on Docker Hub which we'll use.","title":"Fleet"},{"location":"services/docker/fleet/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/fleet","title":"Pre-Installation"},{"location":"services/docker/fleet/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : fleet : image : ghcr.io/linuxserver/fleet:latest restart : unless-stopped volumes : - ./config:/config ports : - 8080:8080 depends_on : - db environment : - PUID=1000 - PGID=1000 - fleet_admin_authentication_type=DATABASE - fleet_database_url=jdbc:mariadb://db/fleet - fleet_database_username=fleet - fleet_database_password=CHANGE_THIS - TZ=America/Guayaquil db : image : mariadb:10 restart : unless-stopped volumes : - ./db:/var/lib/mysql environment : - MYSQL_ROOT_PASSWORD=CHANGE_THIS - MYSQL_DATABASE=fleet - MYSQL_USER=fleet - MYSQL_PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/docker/fleet/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8080 /tcp The default user and password are: admin : admin , you should create a new user and remove this initial admin user.","title":"Post-Installation"},{"location":"services/docker/fleet/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/docker/portainer/","text":"Portainer \u00b6 Portainer is a web UI for Docker which allows us to have an insight on all the containers running on our server. This service has an official image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/portainer Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : portainer : image : portainer/portainer-ce:latest restart : unless-stopped volumes : - ./data:/data - /var/run/docker.sock:/var/run/docker.sock ports : - 8000:8000 - 9000:9000 environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8000 /tcp sudo ufw allow 9000 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Portainer"},{"location":"services/docker/portainer/#portainer","text":"Portainer is a web UI for Docker which allows us to have an insight on all the containers running on our server. This service has an official image on Docker Hub which we'll use.","title":"Portainer"},{"location":"services/docker/portainer/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/docker/portainer","title":"Pre-Installation"},{"location":"services/docker/portainer/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : portainer : image : portainer/portainer-ce:latest restart : unless-stopped volumes : - ./data:/data - /var/run/docker.sock:/var/run/docker.sock ports : - 8000:8000 - 9000:9000 environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/docker/portainer/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8000 /tcp sudo ufw allow 9000 /tcp","title":"Post-Installation"},{"location":"services/docker/portainer/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to media servers. mkdir ~/media For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/media/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to media servers. mkdir ~/media For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/media/embystat/","text":"EmbyStat \u00b6 Warning This service requires Jellyfin , you must set that up before continuing with this one. EmbyStat is an analytics service for Jellyfin/Emby. There is no official docker image for EmbyStat , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/embystat Docker Compose \u00b6 EmbyStat will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : embystat : image : ghcr.io/linuxserver/embystat:latest restart : unless-stopped networks : - jellyfin volumes : - ./config:/config ports : - 6555:6555 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 6555 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"EmbyStat"},{"location":"services/media/embystat/#embystat","text":"Warning This service requires Jellyfin , you must set that up before continuing with this one. EmbyStat is an analytics service for Jellyfin/Emby. There is no official docker image for EmbyStat , however we'll use one from LinuxServer on Docker Hub .","title":"EmbyStat"},{"location":"services/media/embystat/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/embystat","title":"Pre-Installation"},{"location":"services/media/embystat/#docker-compose","text":"EmbyStat will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : embystat : image : ghcr.io/linuxserver/embystat:latest restart : unless-stopped networks : - jellyfin volumes : - ./config:/config ports : - 6555:6555 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/embystat/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 6555 /tcp","title":"Post-Installation"},{"location":"services/media/embystat/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/freshrss/","text":"FreshRSS \u00b6 FreshRSS is an RSS feed reader. For this service we'll use an image from LinuxServer available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/freshrss Docker Compose \u00b6 FreshRSS will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : freshrss : image : lscr.io/linuxserver/freshrss:latest restart : unless-stopped ports : - 5200:80 volumes : - ./data:/config environment : - TZ=America/Guayaquil - PUID=1000 - PGID=1000 Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 5200 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"FreshRSS"},{"location":"services/media/freshrss/#freshrss","text":"FreshRSS is an RSS feed reader. For this service we'll use an image from LinuxServer available on Docker Hub which we'll use.","title":"FreshRSS"},{"location":"services/media/freshrss/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/freshrss","title":"Pre-Installation"},{"location":"services/media/freshrss/#docker-compose","text":"FreshRSS will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : freshrss : image : lscr.io/linuxserver/freshrss:latest restart : unless-stopped ports : - 5200:80 volumes : - ./data:/config environment : - TZ=America/Guayaquil - PUID=1000 - PGID=1000","title":"Docker Compose"},{"location":"services/media/freshrss/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 5200 /tcp","title":"Post-Installation"},{"location":"services/media/freshrss/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/jackett/","text":"Jackett \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Jackett is a torrent indexer that standardizes the shape of the data from multiple indexers to make it possible to use originally unsupported indexers on services like Sonarr . There is no official docker image for Jackett , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/jackett Docker Compose \u00b6 Jackett will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jackett : image : ghcr.io/linuxserver/jackett:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 9117:9117 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - AUTO_UPDATE=true networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 9117 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Jackett"},{"location":"services/media/jackett/#jackett","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Jackett is a torrent indexer that standardizes the shape of the data from multiple indexers to make it possible to use originally unsupported indexers on services like Sonarr . There is no official docker image for Jackett , however we'll use one from LinuxServer on Docker Hub .","title":"Jackett"},{"location":"services/media/jackett/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/jackett","title":"Pre-Installation"},{"location":"services/media/jackett/#docker-compose","text":"Jackett will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jackett : image : ghcr.io/linuxserver/jackett:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 9117:9117 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - AUTO_UPDATE=true networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/jackett/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 9117 /tcp","title":"Post-Installation"},{"location":"services/media/jackett/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/jdownloader/","text":"JDownloader \u00b6 JDownloader is a download client that makes downloading from direct links a breeze. There is no official image for JDownloader , however we'll use one available on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the download client's data will be saved. mkdir ~/media/jdownloader Docker Compose \u00b6 JDownloader will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jdownloader : image : jlesage/jdownloader-2:latest restart : unless-stopped volumes : - ./config:/config - /media/sata_2tb/Downloads:/output ports : - 3129:3129 - 5800:5800 environment : - TZ=America/Guayaquil - USER_ID=1000 - GROUP_ID=1000 Note In the case of the USER_ID and GROUP_ID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3129 /tcp sudo ufw allow 5800 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"JDownloader"},{"location":"services/media/jdownloader/#jdownloader","text":"JDownloader is a download client that makes downloading from direct links a breeze. There is no official image for JDownloader , however we'll use one available on Docker Hub .","title":"JDownloader"},{"location":"services/media/jdownloader/#pre-installation","text":"We'll create a folder in the main user's home where all the download client's data will be saved. mkdir ~/media/jdownloader","title":"Pre-Installation"},{"location":"services/media/jdownloader/#docker-compose","text":"JDownloader will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jdownloader : image : jlesage/jdownloader-2:latest restart : unless-stopped volumes : - ./config:/config - /media/sata_2tb/Downloads:/output ports : - 3129:3129 - 5800:5800 environment : - TZ=America/Guayaquil - USER_ID=1000 - GROUP_ID=1000 Note In the case of the USER_ID and GROUP_ID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/jdownloader/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3129 /tcp sudo ufw allow 5800 /tcp","title":"Post-Installation"},{"location":"services/media/jdownloader/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/jellyfin/","text":"Jellyfin \u00b6 Jellyfin is an open source version of the famous media server Emby . This media server has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/jellyfin We'll also need to create a custom network to allow other containers to communicate with this one. docker network create jellyfin Docker Compose \u00b6 Jellyfin will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jellyfin : image : jellyfin/jellyfin:latest user : 1000:1000 restart : unless-stopped networks : - jellyfin volumes : - ./config:/config - ./cache:/cache - /media/sata_2tb/Jellyfin:/media ports : - 8096:8096 environment : - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the user directive, 1000:1000 corresponds to the user's UID:GID . You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8086 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Jellyfin"},{"location":"services/media/jellyfin/#jellyfin","text":"Jellyfin is an open source version of the famous media server Emby . This media server has an official image available on Docker Hub which we'll use.","title":"Jellyfin"},{"location":"services/media/jellyfin/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/jellyfin We'll also need to create a custom network to allow other containers to communicate with this one. docker network create jellyfin","title":"Pre-Installation"},{"location":"services/media/jellyfin/#docker-compose","text":"Jellyfin will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : jellyfin : image : jellyfin/jellyfin:latest user : 1000:1000 restart : unless-stopped networks : - jellyfin volumes : - ./config:/config - ./cache:/cache - /media/sata_2tb/Jellyfin:/media ports : - 8096:8096 environment : - TZ=America/Guayaquil networks : jellyfin : external : true Note In the case of the user directive, 1000:1000 corresponds to the user's UID:GID . You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/jellyfin/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8086 /tcp","title":"Post-Installation"},{"location":"services/media/jellyfin/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/kavita/","text":"Kavita \u00b6 Kavita is an eBook server for PDFs and EPUBs. This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/kavita Docker Compose \u00b6 Kavita will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : kavita : image : kizaing/kavita:latest restart : unless-stopped ports : - 5000:5000 volumes : - ./data:/kavita/config - /media/sata_2tb/Nextcloud/data/__groupfolders/1:/books environment : - TZ=America/Guayaquil Note If you're curious about that weird volume for the books, currently this set up syncs up the books from Nextcloud through the use of a plugin named \"Shared Group Folders\" which allows multiple users to manage this folder with ease. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 5000 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Kavita"},{"location":"services/media/kavita/#kavita","text":"Kavita is an eBook server for PDFs and EPUBs. This service has an official image available on Docker Hub which we'll use.","title":"Kavita"},{"location":"services/media/kavita/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/kavita","title":"Pre-Installation"},{"location":"services/media/kavita/#docker-compose","text":"Kavita will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : kavita : image : kizaing/kavita:latest restart : unless-stopped ports : - 5000:5000 volumes : - ./data:/kavita/config - /media/sata_2tb/Nextcloud/data/__groupfolders/1:/books environment : - TZ=America/Guayaquil Note If you're curious about that weird volume for the books, currently this set up syncs up the books from Nextcloud through the use of a plugin named \"Shared Group Folders\" which allows multiple users to manage this folder with ease.","title":"Docker Compose"},{"location":"services/media/kavita/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 5000 /tcp","title":"Post-Installation"},{"location":"services/media/kavita/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/ombi/","text":"Ombi \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Ombi is a media request tracker, useful for when you share a Plex server or similar with family and friends. There is no official docker image for Ombi , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/ombi Docker Compose \u00b6 Ombi will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : ombi : image : ghcr.io/linuxserver/ombi:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 3579:3579 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 3579 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Ombi"},{"location":"services/media/ombi/#ombi","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Ombi is a media request tracker, useful for when you share a Plex server or similar with family and friends. There is no official docker image for Ombi , however we'll use one from LinuxServer on Docker Hub .","title":"Ombi"},{"location":"services/media/ombi/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/ombi","title":"Pre-Installation"},{"location":"services/media/ombi/#docker-compose","text":"Ombi will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : ombi : image : ghcr.io/linuxserver/ombi:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config ports : - 3579:3579 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/ombi/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 3579 /tcp","title":"Post-Installation"},{"location":"services/media/ombi/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/plex/","text":"Plex \u00b6 Plex is one of the most popular media server options out there. This media server has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/plex Docker Compose \u00b6 Plex will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : plex : image : plexinc/pms-docker:latest restart : unless-stopped network_mode : host volumes : - ./config:/config - ./transcode:/transcode - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/usb_8tb:/media/usb_8tb environment : - TZ=America/Guayaquil - PLEX_UID=1000 - PLEX_GID=1000 Note In the case of the PLEX_UID and PLEX_GID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 32400 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Plex"},{"location":"services/media/plex/#plex","text":"Plex is one of the most popular media server options out there. This media server has an official image available on Docker Hub which we'll use.","title":"Plex"},{"location":"services/media/plex/#pre-installation","text":"We'll create a folder in the main user's home where all the media server's data will be saved. mkdir ~/media/plex","title":"Pre-Installation"},{"location":"services/media/plex/#docker-compose","text":"Plex will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : plex : image : plexinc/pms-docker:latest restart : unless-stopped network_mode : host volumes : - ./config:/config - ./transcode:/transcode - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/usb_8tb:/media/usb_8tb environment : - TZ=America/Guayaquil - PLEX_UID=1000 - PLEX_GID=1000 Note In the case of the PLEX_UID and PLEX_GID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/plex/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 32400 /tcp","title":"Post-Installation"},{"location":"services/media/plex/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/radarr/","text":"Radarr \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Radarr is an RSS downloader focused on movies. There is no official docker image for Radarr , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/radarr Docker Compose \u00b6 Radarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : radarr : image : ghcr.io/linuxserver/radarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/usb_8tb:/media/usb_8tb - /media/sata_2tb/Downloads:/downloads ports : - 7878:7878 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 7878 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Radarr"},{"location":"services/media/radarr/#radarr","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Radarr is an RSS downloader focused on movies. There is no official docker image for Radarr , however we'll use one from LinuxServer on Docker Hub .","title":"Radarr"},{"location":"services/media/radarr/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/radarr","title":"Pre-Installation"},{"location":"services/media/radarr/#docker-compose","text":"Radarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : radarr : image : ghcr.io/linuxserver/radarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/usb_8tb:/media/usb_8tb - /media/sata_2tb/Downloads:/downloads ports : - 7878:7878 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/radarr/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 7878 /tcp","title":"Post-Installation"},{"location":"services/media/radarr/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/sonarr/","text":"Sonarr \u00b6 Warning This service requires Transmission , you must set that up before continuing with this one. Sonarr is an RSS downloader focused on TV Shows. There is no official docker image for Sonarr , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/sonarr Docker Compose \u00b6 Sonarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : sonarr : image : ghcr.io/linuxserver/sonarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/usb_8tb:/media/usb_8tb - /media/sata_2tb/Downloads:/downloads ports : - 8989:8989 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8989 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Sonarr"},{"location":"services/media/sonarr/#sonarr","text":"Warning This service requires Transmission , you must set that up before continuing with this one. Sonarr is an RSS downloader focused on TV Shows. There is no official docker image for Sonarr , however we'll use one from LinuxServer on Docker Hub .","title":"Sonarr"},{"location":"services/media/sonarr/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/sonarr","title":"Pre-Installation"},{"location":"services/media/sonarr/#docker-compose","text":"Sonarr will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : sonarr : image : ghcr.io/linuxserver/sonarr:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - /media/usb_1tb:/media/usb_1tb - /media/usb_4tb:/media/usb_4tb - /media/usb_8tb:/media/usb_8tb - /media/sata_2tb/Downloads:/downloads ports : - 8989:8989 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/sonarr/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8989 /tcp","title":"Post-Installation"},{"location":"services/media/sonarr/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/synclounge/","text":"Synclounge \u00b6 Synclounge is a tool that lets your Plex users watch something simultaneously. There is no official docker image for Synclounge , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/synclounge Docker Compose \u00b6 Synclounge will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : synclounge : image : ghcr.io/linuxserver/synclounge:latest restart : unless-stopped ports : - 8088:8088 environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8088 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Synclounge"},{"location":"services/media/synclounge/#synclounge","text":"Synclounge is a tool that lets your Plex users watch something simultaneously. There is no official docker image for Synclounge , however we'll use one from LinuxServer on Docker Hub .","title":"Synclounge"},{"location":"services/media/synclounge/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/synclounge","title":"Pre-Installation"},{"location":"services/media/synclounge/#docker-compose","text":"Synclounge will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : synclounge : image : ghcr.io/linuxserver/synclounge:latest restart : unless-stopped ports : - 8088:8088 environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/media/synclounge/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8088 /tcp","title":"Post-Installation"},{"location":"services/media/synclounge/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/tautulli/","text":"Tautulli \u00b6 Tautulli is a monitoring tool for Plex . This service has an official image available on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/tautulli Docker Compose \u00b6 Tautulli will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : tautulli : image : tautulli/tautulli:latest restart : unless-stopped volumes : - ./config:/config ports : - 8181:8181 environment : - TZ=America/Guayaquil - PUID=1000 - PGID=1000 Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8181 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Tautulli"},{"location":"services/media/tautulli/#tautulli","text":"Tautulli is a monitoring tool for Plex . This service has an official image available on Docker Hub which we'll use.","title":"Tautulli"},{"location":"services/media/tautulli/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/tautulli","title":"Pre-Installation"},{"location":"services/media/tautulli/#docker-compose","text":"Tautulli will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : tautulli : image : tautulli/tautulli:latest restart : unless-stopped volumes : - ./config:/config ports : - 8181:8181 environment : - TZ=America/Guayaquil - PUID=1000 - PGID=1000 Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami .","title":"Docker Compose"},{"location":"services/media/tautulli/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8181 /tcp","title":"Post-Installation"},{"location":"services/media/tautulli/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/media/transmission/","text":"Transmission \u00b6 Tranmission is a BitTorrent client. There is no official docker image for Transmission , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/transmission We'll also need to create a custom network to allow other containers to communicate with this one. docker network create downloader Any container that wants to communicate with this one should join the downloader network. Docker Compose \u00b6 Transmission will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : transmission : image : ghcr.io/linuxserver/transmission:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - ./watch:/watch - /media/sata_2tb/Downloads:/downloads ports : - 9091:9091 - 51413:51413 - 51413:51413/udp environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - TRANSMISSION_WEB_HOME=/flood-for-transmission/ - USER=<USER_HERE> - PASS=<PASS_HERE> networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note The password should be set inside the docker-compose.yml file and not manually updated in config/settings.json which will mess up with the s6 supervisor. Use a password you don't care too much about since it would basically be saved in plain text. Note You may change the contents of config/settings.json as long as the container is stopped. Post-Installation \u00b6 We'll need to allow the service's web UI port on our firewall. sudo ufw allow 9091 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Transmission"},{"location":"services/media/transmission/#transmission","text":"Tranmission is a BitTorrent client. There is no official docker image for Transmission , however we'll use one from LinuxServer on Docker Hub .","title":"Transmission"},{"location":"services/media/transmission/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/media/transmission We'll also need to create a custom network to allow other containers to communicate with this one. docker network create downloader Any container that wants to communicate with this one should join the downloader network.","title":"Pre-Installation"},{"location":"services/media/transmission/#docker-compose","text":"Transmission will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : transmission : image : ghcr.io/linuxserver/transmission:latest restart : unless-stopped networks : - downloader volumes : - ./config:/config - ./watch:/watch - /media/sata_2tb/Downloads:/downloads ports : - 9091:9091 - 51413:51413 - 51413:51413/udp environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - TRANSMISSION_WEB_HOME=/flood-for-transmission/ - USER=<USER_HERE> - PASS=<PASS_HERE> networks : downloader : external : true Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note The password should be set inside the docker-compose.yml file and not manually updated in config/settings.json which will mess up with the s6 supervisor. Use a password you don't care too much about since it would basically be saved in plain text. Note You may change the contents of config/settings.json as long as the container is stopped.","title":"Docker Compose"},{"location":"services/media/transmission/#post-installation","text":"We'll need to allow the service's web UI port on our firewall. sudo ufw allow 9091 /tcp","title":"Post-Installation"},{"location":"services/media/transmission/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/monitoring/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to system monitoring related services. mkdir ~/monitoring For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/monitoring/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to system monitoring related services. mkdir ~/monitoring For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/monitoring/librespeed/","text":"LibreSpeed \u00b6 LibreSpeed is a self-hosted speed test, useful to check our connection from outside into our server. There is no official docker image for LibreSpeed , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/librespeed Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : librespeed : image : ghcr.io/linuxserver/librespeed:latest restart : unless-stopped volumes : - ./config:/config ports : - 8050:80 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8050 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"LibreSpeed"},{"location":"services/monitoring/librespeed/#librespeed","text":"LibreSpeed is a self-hosted speed test, useful to check our connection from outside into our server. There is no official docker image for LibreSpeed , however we'll use one from LinuxServer on Docker Hub .","title":"LibreSpeed"},{"location":"services/monitoring/librespeed/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/librespeed","title":"Pre-Installation"},{"location":"services/monitoring/librespeed/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : librespeed : image : ghcr.io/linuxserver/librespeed:latest restart : unless-stopped volumes : - ./config:/config ports : - 8050:80 environment : - PUID=1000 - PGID=1000 - TZ=America/Guayaquil - PASSWORD=CHANGE_THIS Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Make sure to change CHANGE_THIS to a custom value.","title":"Docker Compose"},{"location":"services/monitoring/librespeed/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8050 /tcp","title":"Post-Installation"},{"location":"services/monitoring/librespeed/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/monitoring/scrutiny/","text":"Scrutiny \u00b6 Scrutiny is a S.M.A.R.T monitoring tool that uses smartd . There is no official docker image for Scrutiny , however we'll use one from LinuxServer on Docker Hub . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/scrutiny Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : scrutiny : image : ghcr.io/linuxserver/scrutiny:8e34ef8d-ls35 restart : unless-stopped cap_add : - SYS_RAWIO volumes : - ./config:/config - /run/udev:/run/udev:ro ports : - 8020:8080 devices : - /dev/sda:/dev/sda - /dev/sdb:/dev/sdb - /dev/sdc:/dev/sdc - /dev/sdd:/dev/sdd - /dev/sde:/dev/sde environment : - PUID=1000 - PGID=1000 - SCRUTINY_WEB=true - SCRUTINY_COLLECTOR=true - TZ=America/Guayaquil Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Under devices make sure you're passing your hard drives. You can check blkid to see which device blocks to pass. Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 8020 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure. Updating Results \u00b6 To manually update the results, run the following from inside the container's data folder: docker-compose run --rm scrutiny scrutiny-collector-metrics run","title":"Scrutiny"},{"location":"services/monitoring/scrutiny/#scrutiny","text":"Scrutiny is a S.M.A.R.T monitoring tool that uses smartd . There is no official docker image for Scrutiny , however we'll use one from LinuxServer on Docker Hub .","title":"Scrutiny"},{"location":"services/monitoring/scrutiny/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/monitoring/scrutiny","title":"Pre-Installation"},{"location":"services/monitoring/scrutiny/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : scrutiny : image : ghcr.io/linuxserver/scrutiny:8e34ef8d-ls35 restart : unless-stopped cap_add : - SYS_RAWIO volumes : - ./config:/config - /run/udev:/run/udev:ro ports : - 8020:8080 devices : - /dev/sda:/dev/sda - /dev/sdb:/dev/sdb - /dev/sdc:/dev/sdc - /dev/sdd:/dev/sdd - /dev/sde:/dev/sde environment : - PUID=1000 - PGID=1000 - SCRUTINY_WEB=true - SCRUTINY_COLLECTOR=true - TZ=America/Guayaquil Note In the case of the PUID and PGID environment variables, 1000 corresponds to the user's UID and GID respectively. You can find the values for your own user by running id $whoami . Note Under devices make sure you're passing your hard drives. You can check blkid to see which device blocks to pass.","title":"Docker Compose"},{"location":"services/monitoring/scrutiny/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 8020 /tcp","title":"Post-Installation"},{"location":"services/monitoring/scrutiny/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/monitoring/scrutiny/#updating-results","text":"To manually update the results, run the following from inside the container's data folder: docker-compose run --rm scrutiny scrutiny-collector-metrics run","title":"Updating Results"},{"location":"services/other/","text":"Initialization \u00b6 All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to other services. mkdir ~/other For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/other/#initialization","text":"All the services inside this section will be implemented on Docker . Since we'll use Docker Compose to execute the services, we'll create a folder on the main user's home folder dedicated to other services. mkdir ~/other For each service created, there will be a subfolder where a docker-compose.yml file will be located, alongside any data volumes required and even a Dockerfile if required.","title":"Initialization"},{"location":"services/other/rtmp-simulcast/","text":"RTMP Simulcast \u00b6 If you like to stream your video games to multiple platforms simultaneously, then RTMP Simulcast is for you. There are services out there that let you do this for free, but they have some cons: Depending on the service you use, your stream titles or descriptions could be used for advertising purposes, which basically means you lose complete control of what your stream description displays to your viewers. Since these services are used by multiple people at the same time, streaming platforms will most likely detect a huge pool of users streaming from the same IP which means that you'll be targeted by a low exposure algorithm that will, ironically, make your stream harder to find. You can bypass these problems by streaming simultaneously to your desired platforms yourself, but keep in mind, there are some difficulties as well: Doing this (ideally) requires you to have a second computer (performance doesn't matter too much, you could even use a Raspberry Pi for this), you could technically achieve the same result with a virtual machine inside the streaming computer but it would represent a huge performance drop. Since you would be streaming to multiple platforms yourself, you would need a much higher upload bandwidth (around the stream bitrate multiplied by the number of platforms you're streaming to). For instance, my stream gets rendered at a bitrate of 6000 kbps , if I wanted to stream to 3 different platforms at the same time, I would need around 20000 kbps . Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/rtmp-simulcast Configuration \u00b6 To configure this service, we'll first create a folder called config inside ~/other/rtmp-simulcast and create a file named rtmp.conf where the configuration for the simulcast will be located. mkdir ~/other/rtmp-simulcast/config nano ~/other/rtmp-simulcast/config/rtmp.conf And its content should be as follows: # RTMP Stream Simulcast rtmp { server { listen 1935; application live { live on; record off; push rtmp://ingest.server.com/application/stream_key } application local { live on; record off; } } } Note Replace rtmp://ingest.sever.com/application/stream_key with the actual ingest server of the platform you want to stream to. For example: rtmp://a.rtmp.youtube.com/live2/{my_stream_key} . You can push multiple ingest servers. Dockerfile \u00b6 Since the service does not have an official Docker image, we'll create a Dockerfile . The content of the Dockerfile file is as follows: FROM ubuntu:20.04 RUN apt-get update && apt-get install -y nginx libnginx-mod-rtmp WORKDIR /etc/nginx VOLUME /etc/nginx/rtmp-config RUN printf \"\\n\\nrtmp {\\n include /etc/nginx/rtmp-config/*.conf;\\n}\\n\" >> nginx.conf EXPOSE 1935 EXPOSE 80 CMD [ \"nginx\" , \"-g\" , \"daemon off;\" ] Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : rtmp : build : . restart : unless-stopped volumes : - ./config:/etc/nginx/rtmp-config ports : - 1935:1935 environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 1935 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure. Streaming Settings \u00b6 In your streaming software, change your streaming server to the following: rtmp://server_local_ip/live And you can place whatever you want as the stream key. For testing purposes, you can also stream to rtmp://server_local_ip/local and watch it to see how it performs. Watching Your Stream Locally \u00b6 If you wish to see how your server perceives your stream, you can use a RTMP player (VLC will do the trick), and open the stream at the url rtmp://server_local_ip/local/{stream_key} . Replace {stream_key} with the actual streaming key that you're currently using.","title":"RTMP Simulcast"},{"location":"services/other/rtmp-simulcast/#rtmp-simulcast","text":"If you like to stream your video games to multiple platforms simultaneously, then RTMP Simulcast is for you. There are services out there that let you do this for free, but they have some cons: Depending on the service you use, your stream titles or descriptions could be used for advertising purposes, which basically means you lose complete control of what your stream description displays to your viewers. Since these services are used by multiple people at the same time, streaming platforms will most likely detect a huge pool of users streaming from the same IP which means that you'll be targeted by a low exposure algorithm that will, ironically, make your stream harder to find. You can bypass these problems by streaming simultaneously to your desired platforms yourself, but keep in mind, there are some difficulties as well: Doing this (ideally) requires you to have a second computer (performance doesn't matter too much, you could even use a Raspberry Pi for this), you could technically achieve the same result with a virtual machine inside the streaming computer but it would represent a huge performance drop. Since you would be streaming to multiple platforms yourself, you would need a much higher upload bandwidth (around the stream bitrate multiplied by the number of platforms you're streaming to). For instance, my stream gets rendered at a bitrate of 6000 kbps , if I wanted to stream to 3 different platforms at the same time, I would need around 20000 kbps .","title":"RTMP Simulcast"},{"location":"services/other/rtmp-simulcast/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/rtmp-simulcast","title":"Pre-Installation"},{"location":"services/other/rtmp-simulcast/#configuration","text":"To configure this service, we'll first create a folder called config inside ~/other/rtmp-simulcast and create a file named rtmp.conf where the configuration for the simulcast will be located. mkdir ~/other/rtmp-simulcast/config nano ~/other/rtmp-simulcast/config/rtmp.conf And its content should be as follows: # RTMP Stream Simulcast rtmp { server { listen 1935; application live { live on; record off; push rtmp://ingest.server.com/application/stream_key } application local { live on; record off; } } } Note Replace rtmp://ingest.sever.com/application/stream_key with the actual ingest server of the platform you want to stream to. For example: rtmp://a.rtmp.youtube.com/live2/{my_stream_key} . You can push multiple ingest servers.","title":"Configuration"},{"location":"services/other/rtmp-simulcast/#dockerfile","text":"Since the service does not have an official Docker image, we'll create a Dockerfile . The content of the Dockerfile file is as follows: FROM ubuntu:20.04 RUN apt-get update && apt-get install -y nginx libnginx-mod-rtmp WORKDIR /etc/nginx VOLUME /etc/nginx/rtmp-config RUN printf \"\\n\\nrtmp {\\n include /etc/nginx/rtmp-config/*.conf;\\n}\\n\" >> nginx.conf EXPOSE 1935 EXPOSE 80 CMD [ \"nginx\" , \"-g\" , \"daemon off;\" ]","title":"Dockerfile"},{"location":"services/other/rtmp-simulcast/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : rtmp : build : . restart : unless-stopped volumes : - ./config:/etc/nginx/rtmp-config ports : - 1935:1935 environment : - TZ=America/Guayaquil Before starting, we need to build this image, do so with: docker-compose build","title":"Docker Compose"},{"location":"services/other/rtmp-simulcast/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 1935 /tcp","title":"Post-Installation"},{"location":"services/other/rtmp-simulcast/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"services/other/rtmp-simulcast/#streaming-settings","text":"In your streaming software, change your streaming server to the following: rtmp://server_local_ip/live And you can place whatever you want as the stream key. For testing purposes, you can also stream to rtmp://server_local_ip/local and watch it to see how it performs.","title":"Streaming Settings"},{"location":"services/other/rtmp-simulcast/#watching-your-stream-locally","text":"If you wish to see how your server perceives your stream, you can use a RTMP player (VLC will do the trick), and open the stream at the url rtmp://server_local_ip/local/{stream_key} . Replace {stream_key} with the actual streaming key that you're currently using.","title":"Watching Your Stream Locally"},{"location":"services/other/webframes/","text":"Webframes \u00b6 Webframes is a little webapp that frames other pages. This will be useful to have a central place where you can access all the aforementioned web services. This service has an image on Docker Hub which we'll use. Pre-Installation \u00b6 We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/webframes Docker Compose \u00b6 The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : webframes : image : moonstarx/webframes:latest restart : unless-stopped ports : - 80:4000 volumes : - ./data:/opt/app/backend/data environment : - TZ=America/Guayaquil Post-Installation \u00b6 We'll need to allow the service's port on our firewall. sudo ufw allow 80 /tcp Running \u00b6 Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Webframes"},{"location":"services/other/webframes/#webframes","text":"Webframes is a little webapp that frames other pages. This will be useful to have a central place where you can access all the aforementioned web services. This service has an image on Docker Hub which we'll use.","title":"Webframes"},{"location":"services/other/webframes/#pre-installation","text":"We'll create a folder in the main user's home where all the service's data will be saved. mkdir ~/other/webframes","title":"Pre-Installation"},{"location":"services/other/webframes/#docker-compose","text":"The service will be run using Docker Compose . The content of the docker-compose.yml file is as follows: version : \"3.9\" services : webframes : image : moonstarx/webframes:latest restart : unless-stopped ports : - 80:4000 volumes : - ./data:/opt/app/backend/data environment : - TZ=America/Guayaquil","title":"Docker Compose"},{"location":"services/other/webframes/#post-installation","text":"We'll need to allow the service's port on our firewall. sudo ufw allow 80 /tcp","title":"Post-Installation"},{"location":"services/other/webframes/#running","text":"Start up the service with: docker-compose up -d That's it! The service will auto-start on system startup and restart on failure.","title":"Running"},{"location":"setting-up/custom-scripts/","text":"Custom Scripts \u00b6 We will create some custom scripts that will help us with certain tasks. For this, we'll create the following folder: mkdir -p ~/.local/bin Then inside this folder we'll insert all the scripts that we'll add here. Make sure to make them executable with: chmod +x <file> docker-update \u00b6 We'll use this script to manually update docker-compose containers. Usage Run docker-update inside the folder where docker-compose.yml is located to update the container images used. #!/bin/bash echo \"Stopping containers...\" docker-compose stop echo \"Removing containers...\" docker-compose rm -f echo \"Pulling images...\" docker-compose pull echo \"Restarting containers...\" docker-compose up -d","title":"Custom Scripts"},{"location":"setting-up/custom-scripts/#custom-scripts","text":"We will create some custom scripts that will help us with certain tasks. For this, we'll create the following folder: mkdir -p ~/.local/bin Then inside this folder we'll insert all the scripts that we'll add here. Make sure to make them executable with: chmod +x <file>","title":"Custom Scripts"},{"location":"setting-up/custom-scripts/#docker-update","text":"We'll use this script to manually update docker-compose containers. Usage Run docker-update inside the folder where docker-compose.yml is located to update the container images used. #!/bin/bash echo \"Stopping containers...\" docker-compose stop echo \"Removing containers...\" docker-compose rm -f echo \"Pulling images...\" docker-compose pull echo \"Restarting containers...\" docker-compose up -d","title":"docker-update"},{"location":"setting-up/docker/","text":"Docker \u00b6 A good portion of our services will be run through Docker . We'll need to first install this. Installation \u00b6 First we'll need to install some dependencies: sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release We'll then need to add the Docker repository: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Finally, we'll update the repositories and install Docker : sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io Permissions \u00b6 We'll add the required permissions for our user into the docker group. sudo groupadd docker sudo gpasswd -a $USER docker Finally, reboot the server for the changes to apply. Docker Compose \u00b6 We'll be using Docker Compose to run our containers, to install it run the following: sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"Docker"},{"location":"setting-up/docker/#docker","text":"A good portion of our services will be run through Docker . We'll need to first install this.","title":"Docker"},{"location":"setting-up/docker/#installation","text":"First we'll need to install some dependencies: sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release We'll then need to add the Docker repository: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Finally, we'll update the repositories and install Docker : sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io","title":"Installation"},{"location":"setting-up/docker/#permissions","text":"We'll add the required permissions for our user into the docker group. sudo groupadd docker sudo gpasswd -a $USER docker Finally, reboot the server for the changes to apply.","title":"Permissions"},{"location":"setting-up/docker/#docker-compose","text":"We'll be using Docker Compose to run our containers, to install it run the following: sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"Docker Compose"},{"location":"setting-up/mounting-drives/","text":"Mounting Drives \u00b6 In this server there will be a 2TB SATA drive, and 2 USB 3.0 drives of 1TB and 4TB respectively. We need these drives to mount on system startup, for this, we'll need to set up the fstab . Getting Drives' UUIDs \u00b6 In order to get the UUIDs of the drives in question, it is necessary to plug them in and reboot the server. Once this is done, execute the following: lsblk -o NAME,FSTYPE,UUID This will give an output like the following: NAME FSTYPE UUID loop0 squashfs loop1 squashfs loop2 squashfs loop3 squashfs loop4 squashfs loop5 squashfs loop6 squashfs loop7 squashfs sda \u2514\u2500sda1 ext4 e8f133c2-af07-4a7a-a42f-21f857a9a06f sdb \u251c\u2500sdb1 vfat A12E-F096 \u2514\u2500sdb2 ext4 c1aafa14-c857-4d3e-8ae1-00c8cd462810 sdc ext4 418987da-2351-11e9-aec8-b8975ad7798b sdd \u2514\u2500sdd1 ext4 43fbd170-3eff-40ec-95fc-c6cc090a5bc9 sde \u2514\u2500sde1 ext4 fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 In this case, /dev/sda1 is the 1TB USB hard drive with ext4 format, /dev/sdc is the 2TB SATA drive with ext4 format, /dev/sdd1 is the 4TB USB hard drive with ext4 format, and lastly /dev/sde1 is the 8TB USB drive. We'll need the UUIDs later, so copy them somewhere. Preparing the Folders \u00b6 We'll mount the hard drives in /media , for this we'll create the required folders like so: sudo mkdir /media/sata_2tb /media/usb_1tb /media/usb_4tb /media/usb_8tb You may also change the permissions on these folders if it causes any problem. sudo chmod -R 777 /media/sata_2tb /media/usb_1tb /media/usb_4tb /media/usb_8tb Modifying fstab \u00b6 Danger Proceed at your own risk, messing up this file will most probably break your computer. You can still fix it by entering safe mode and logging in as root to rollback. We'll modify the /etc/fstab file. sudo nano /etc/fstab And we'll add a new line for each hard drive with the following structure: UUID=$UUID $DIR $FORMAT defaults 0 0 In our case, we'll add the following lines: UUID=e8f133c2-af07-4a7a-a42f-21f857a9a06f /media/usb_1tb ext4 defaults 0 0 UUID=418987da-2351-11e9-aec8-b8975ad7798b /media/sata_2tb ext4 defaults 0 0 UUID=fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 /media/usb_4tb ext4 defaults 0 0 UUID=43fbd170-3eff-40ec-95fc-c6cc090a5bc9 /media/usb_8tb ext4 defaults 0 0 Finally, reboot the server. The hard drives should now be automatically mounted.","title":"Mounting Drives"},{"location":"setting-up/mounting-drives/#mounting-drives","text":"In this server there will be a 2TB SATA drive, and 2 USB 3.0 drives of 1TB and 4TB respectively. We need these drives to mount on system startup, for this, we'll need to set up the fstab .","title":"Mounting Drives"},{"location":"setting-up/mounting-drives/#getting-drives-uuids","text":"In order to get the UUIDs of the drives in question, it is necessary to plug them in and reboot the server. Once this is done, execute the following: lsblk -o NAME,FSTYPE,UUID This will give an output like the following: NAME FSTYPE UUID loop0 squashfs loop1 squashfs loop2 squashfs loop3 squashfs loop4 squashfs loop5 squashfs loop6 squashfs loop7 squashfs sda \u2514\u2500sda1 ext4 e8f133c2-af07-4a7a-a42f-21f857a9a06f sdb \u251c\u2500sdb1 vfat A12E-F096 \u2514\u2500sdb2 ext4 c1aafa14-c857-4d3e-8ae1-00c8cd462810 sdc ext4 418987da-2351-11e9-aec8-b8975ad7798b sdd \u2514\u2500sdd1 ext4 43fbd170-3eff-40ec-95fc-c6cc090a5bc9 sde \u2514\u2500sde1 ext4 fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 In this case, /dev/sda1 is the 1TB USB hard drive with ext4 format, /dev/sdc is the 2TB SATA drive with ext4 format, /dev/sdd1 is the 4TB USB hard drive with ext4 format, and lastly /dev/sde1 is the 8TB USB drive. We'll need the UUIDs later, so copy them somewhere.","title":"Getting Drives' UUIDs"},{"location":"setting-up/mounting-drives/#preparing-the-folders","text":"We'll mount the hard drives in /media , for this we'll create the required folders like so: sudo mkdir /media/sata_2tb /media/usb_1tb /media/usb_4tb /media/usb_8tb You may also change the permissions on these folders if it causes any problem. sudo chmod -R 777 /media/sata_2tb /media/usb_1tb /media/usb_4tb /media/usb_8tb","title":"Preparing the Folders"},{"location":"setting-up/mounting-drives/#modifying-fstab","text":"Danger Proceed at your own risk, messing up this file will most probably break your computer. You can still fix it by entering safe mode and logging in as root to rollback. We'll modify the /etc/fstab file. sudo nano /etc/fstab And we'll add a new line for each hard drive with the following structure: UUID=$UUID $DIR $FORMAT defaults 0 0 In our case, we'll add the following lines: UUID=e8f133c2-af07-4a7a-a42f-21f857a9a06f /media/usb_1tb ext4 defaults 0 0 UUID=418987da-2351-11e9-aec8-b8975ad7798b /media/sata_2tb ext4 defaults 0 0 UUID=fedd9ed1-d4cf-4d3c-b105-7b3296f157b4 /media/usb_4tb ext4 defaults 0 0 UUID=43fbd170-3eff-40ec-95fc-c6cc090a5bc9 /media/usb_8tb ext4 defaults 0 0 Finally, reboot the server. The hard drives should now be automatically mounted.","title":"Modifying fstab"},{"location":"setting-up/networking/","text":"Networking \u00b6 Here's a list of ports that are exposed to the host machine. This serves as a reference to prevent setting services to ports that are already in use. Port Forwarding Tables \u00b6 Native Services \u00b6 Service Port Range Protocol SSH 22 TCP Samba (SMB/CIFS) 445 TCP Docker Services \u00b6 Service Port Range Protocol Portainer 8000, 9000 TCP Fleet 8080 TCP Media Services \u00b6 Service Port Range Protocol FreshRSS 5200 TCP Kavita 5000 TCP Jellyfin 8086 TCP EmbyStat 6555 TCP Plex 32400 TCP Tautulli 8181 TCP Synclounge 8088 TCP Ombi 3579 TCP Transmission 9091 TCP Sonarr 8989 TCP Radarr 7878 TCP Jackett 9117 TCP JDownloader 3129, 5800 TCP Data Services \u00b6 Service Port Range Protocol Nextcloud 9020 TCP Gitea 3000 TCP Jenkins 10800 TCP Monitoring Services \u00b6 Service Port Range Protocol LibreSpeed 8050 TCP Scrutiny 8020 TCP Automation Services \u00b6 Service Port Range Protocol Custom Automation Service 5678 TCP Analytics Services \u00b6 Service Port Range Protocol Plausible 10500 TCP Other Services \u00b6 Service Port Range Protocol RTMP Simulcast 1935 TCP Webframes 80 TCP Server Monitoring Services \u00b6 Service Port Range Protocol Prometheus 9090, 9100 TCP Grafana (Raspberry Pi) 3000 TCP Games \u00b6 Service Port Range Protocol TeamSpeak 3 (Voice) 9987 UDP TeamSpeak 3 (ServerQuery) 10011 TCP TeamSpeak 3 (FileTransfer) 30033 TCP Arma 3 2302-2345 TCP/UDP Assetto Corsa (Manager) 8772 TCP Assetto Corsa (Server) 9600 TCP/UDP Assetto Corsa (HTTP) 8081 TCP Minecraft 25565 TCP Valheim 2456, 2457 UDP Deprecated Port Forwarding Tables \u00b6 Deprecated Media Services \u00b6 Service Port Range Protocol Miniflux 5190 TCP Deprecated Data Services \u00b6 Service Port Range Protocol Drone 3080 TCP Drone (Runner) 3100 TCP Nexus 10600 TCP Nexus (Docker Registry) 10610 TCP Nexus (NPM Registry) 10620 TCP Deprecated Automation Services \u00b6 Service Port Range Protocol n8n 5678 TCP n8n MongoDB 56787 TCP Information \u00b6 If you don't know what internal IP the server is running on, you can always type on the terminal: ifconfig UFW \u00b6 UFW is a friendly frontend for iptables that makes it a lot easier to add connection rules to your firewall. One of the many wonders of UFW is the fact that rules are automatically saved when set, which is not true for iptables . Installation \u00b6 We'll need to install UFW and set it up. sudo apt-get install ufw sudo ufw default allow outgoing sudo ufw default deny incoming sudo ufw enable The commands should be pretty self-explanatory but, just in case, these default the firewall to allow any connections going from the server to the Internet and deny any incoming connections from the Internet to the server. Usage \u00b6 A very good command to check UFW 's status (if it's enabled or disabled) and see all the custom rules added and active is: sudo ufw status You can add a new rule by using: sudo ufw allow <PORT_RANGE>/<PROTOCOL> SSH \u00b6 Installation \u00b6 Since the server will run in headless mode, it would be very useful to be able to access it remotely from within (and even outside) the network. We'll use OpenSSH , it is generally installed with the OS but in case that it isn't, you can install it by running: sudo apt-get install openssh-client openssh-server Setting-up \u00b6 We now need to allow SSH connections through the firewall so we can access the server. sudo ufw allow ssh Google Authentication (2FA) \u00b6 Two Factor Authentication has become a must-have in terms of account security, almost all services out there have the option to add this security measure to ensure account security. Luckily, we can implement our own Two Factor Authentication to access the server through SSH . Installation \u00b6 To enable 2FA , we'll need to install the following package: sudo apt-get install libpam-google-authenticator Setting-up \u00b6 To set it up, simply run: google-authenticator When running this, you'll receive a secret key which is used to add your account manually to your phone's 2FA application. Alternatively, you also get a nicely printed QR code on the terminal window (which you may need to resize to see fully) that you can scan with your phone. You will also get some scratch codes that you should always keep somewhere safe, just in case you lose access to your phone or something happens, you can still login to your server. To continue, answer y to all the questions to set up 2FA with the default settings. We now need to enable 2FA on SSH , to do this, edit the following file: sudo nano /etc/ssh/sshd_config Look for the following lines and edit them accordingly: UsePAM yes ChallengeResponseAuthentication yes Save and close the editor and restart the SSH service. sudo systemctl restart ssh We now need to edit the PAM rule file: sudo nano /etc/pam.d/sshd At the end of the file, add the following line: auth required pam_google_authenticator.so Save and close the file. Testing \u00b6 In order to test that 2FA works properly, open up a new SSH session without closing the previous one and try logging in, you'll be prompted for your user password and for the 2FA code which is available on your phone. Info When using 2FA for SSH , all the users in the server will need to set-it up, otherwise they won't be able to access their accounts. In case you get locked out from one of these users, you can always login to a sudoer account (usually the admin one which is added when installing the OS) and force-login with: sudo -iu <user> .","title":"Networking"},{"location":"setting-up/networking/#networking","text":"Here's a list of ports that are exposed to the host machine. This serves as a reference to prevent setting services to ports that are already in use.","title":"Networking"},{"location":"setting-up/networking/#port-forwarding-tables","text":"","title":"Port Forwarding Tables"},{"location":"setting-up/networking/#native-services","text":"Service Port Range Protocol SSH 22 TCP Samba (SMB/CIFS) 445 TCP","title":"Native Services"},{"location":"setting-up/networking/#docker-services","text":"Service Port Range Protocol Portainer 8000, 9000 TCP Fleet 8080 TCP","title":"Docker Services"},{"location":"setting-up/networking/#media-services","text":"Service Port Range Protocol FreshRSS 5200 TCP Kavita 5000 TCP Jellyfin 8086 TCP EmbyStat 6555 TCP Plex 32400 TCP Tautulli 8181 TCP Synclounge 8088 TCP Ombi 3579 TCP Transmission 9091 TCP Sonarr 8989 TCP Radarr 7878 TCP Jackett 9117 TCP JDownloader 3129, 5800 TCP","title":"Media Services"},{"location":"setting-up/networking/#data-services","text":"Service Port Range Protocol Nextcloud 9020 TCP Gitea 3000 TCP Jenkins 10800 TCP","title":"Data Services"},{"location":"setting-up/networking/#monitoring-services","text":"Service Port Range Protocol LibreSpeed 8050 TCP Scrutiny 8020 TCP","title":"Monitoring Services"},{"location":"setting-up/networking/#automation-services","text":"Service Port Range Protocol Custom Automation Service 5678 TCP","title":"Automation Services"},{"location":"setting-up/networking/#analytics-services","text":"Service Port Range Protocol Plausible 10500 TCP","title":"Analytics Services"},{"location":"setting-up/networking/#other-services","text":"Service Port Range Protocol RTMP Simulcast 1935 TCP Webframes 80 TCP","title":"Other Services"},{"location":"setting-up/networking/#server-monitoring-services","text":"Service Port Range Protocol Prometheus 9090, 9100 TCP Grafana (Raspberry Pi) 3000 TCP","title":"Server Monitoring Services"},{"location":"setting-up/networking/#games","text":"Service Port Range Protocol TeamSpeak 3 (Voice) 9987 UDP TeamSpeak 3 (ServerQuery) 10011 TCP TeamSpeak 3 (FileTransfer) 30033 TCP Arma 3 2302-2345 TCP/UDP Assetto Corsa (Manager) 8772 TCP Assetto Corsa (Server) 9600 TCP/UDP Assetto Corsa (HTTP) 8081 TCP Minecraft 25565 TCP Valheim 2456, 2457 UDP","title":"Games"},{"location":"setting-up/networking/#deprecated-port-forwarding-tables","text":"","title":"Deprecated Port Forwarding Tables"},{"location":"setting-up/networking/#deprecated-media-services","text":"Service Port Range Protocol Miniflux 5190 TCP","title":"Deprecated Media Services"},{"location":"setting-up/networking/#deprecated-data-services","text":"Service Port Range Protocol Drone 3080 TCP Drone (Runner) 3100 TCP Nexus 10600 TCP Nexus (Docker Registry) 10610 TCP Nexus (NPM Registry) 10620 TCP","title":"Deprecated Data Services"},{"location":"setting-up/networking/#deprecated-automation-services","text":"Service Port Range Protocol n8n 5678 TCP n8n MongoDB 56787 TCP","title":"Deprecated Automation Services"},{"location":"setting-up/networking/#information","text":"If you don't know what internal IP the server is running on, you can always type on the terminal: ifconfig","title":"Information"},{"location":"setting-up/networking/#ufw","text":"UFW is a friendly frontend for iptables that makes it a lot easier to add connection rules to your firewall. One of the many wonders of UFW is the fact that rules are automatically saved when set, which is not true for iptables .","title":"UFW"},{"location":"setting-up/networking/#installation","text":"We'll need to install UFW and set it up. sudo apt-get install ufw sudo ufw default allow outgoing sudo ufw default deny incoming sudo ufw enable The commands should be pretty self-explanatory but, just in case, these default the firewall to allow any connections going from the server to the Internet and deny any incoming connections from the Internet to the server.","title":"Installation"},{"location":"setting-up/networking/#usage","text":"A very good command to check UFW 's status (if it's enabled or disabled) and see all the custom rules added and active is: sudo ufw status You can add a new rule by using: sudo ufw allow <PORT_RANGE>/<PROTOCOL>","title":"Usage"},{"location":"setting-up/networking/#ssh","text":"","title":"SSH"},{"location":"setting-up/networking/#installation_1","text":"Since the server will run in headless mode, it would be very useful to be able to access it remotely from within (and even outside) the network. We'll use OpenSSH , it is generally installed with the OS but in case that it isn't, you can install it by running: sudo apt-get install openssh-client openssh-server","title":"Installation"},{"location":"setting-up/networking/#setting-up","text":"We now need to allow SSH connections through the firewall so we can access the server. sudo ufw allow ssh","title":"Setting-up"},{"location":"setting-up/networking/#google-authentication-2fa","text":"Two Factor Authentication has become a must-have in terms of account security, almost all services out there have the option to add this security measure to ensure account security. Luckily, we can implement our own Two Factor Authentication to access the server through SSH .","title":"Google Authentication (2FA)"},{"location":"setting-up/networking/#installation_2","text":"To enable 2FA , we'll need to install the following package: sudo apt-get install libpam-google-authenticator","title":"Installation"},{"location":"setting-up/networking/#setting-up_1","text":"To set it up, simply run: google-authenticator When running this, you'll receive a secret key which is used to add your account manually to your phone's 2FA application. Alternatively, you also get a nicely printed QR code on the terminal window (which you may need to resize to see fully) that you can scan with your phone. You will also get some scratch codes that you should always keep somewhere safe, just in case you lose access to your phone or something happens, you can still login to your server. To continue, answer y to all the questions to set up 2FA with the default settings. We now need to enable 2FA on SSH , to do this, edit the following file: sudo nano /etc/ssh/sshd_config Look for the following lines and edit them accordingly: UsePAM yes ChallengeResponseAuthentication yes Save and close the editor and restart the SSH service. sudo systemctl restart ssh We now need to edit the PAM rule file: sudo nano /etc/pam.d/sshd At the end of the file, add the following line: auth required pam_google_authenticator.so Save and close the file.","title":"Setting-up"},{"location":"setting-up/networking/#testing","text":"In order to test that 2FA works properly, open up a new SSH session without closing the previous one and try logging in, you'll be prompted for your user password and for the 2FA code which is available on your phone. Info When using 2FA for SSH , all the users in the server will need to set-it up, otherwise they won't be able to access their accounts. In case you get locked out from one of these users, you can always login to a sudoer account (usually the admin one which is added when installing the OS) and force-login with: sudo -iu <user> .","title":"Testing"},{"location":"setting-up/os-installation/","text":"OS Installation \u00b6 The server will be running Ubuntu Server 20.04 LTS 64-bit in headless mode, meaning that no DE will be used. The installation is quick and assisted by its own install wizard. When asked what snapshot (initial server configuration) should be installed, simply choose none or default . As a general rule of thumb, after installing the OS it is recommended to update the sources ad packages: sudo apt-get update && sudo apt-get upgrade Configuring Date and Time \u00b6 By default, the OS will be installed with GMT+0 as the timezone. We'll change this to conform with our real timezone which is GMT-5 . sudo timedatectl set-timezone America/Guayaquil","title":"OS Installation"},{"location":"setting-up/os-installation/#os-installation","text":"The server will be running Ubuntu Server 20.04 LTS 64-bit in headless mode, meaning that no DE will be used. The installation is quick and assisted by its own install wizard. When asked what snapshot (initial server configuration) should be installed, simply choose none or default . As a general rule of thumb, after installing the OS it is recommended to update the sources ad packages: sudo apt-get update && sudo apt-get upgrade","title":"OS Installation"},{"location":"setting-up/os-installation/#configuring-date-and-time","text":"By default, the OS will be installed with GMT+0 as the timezone. We'll change this to conform with our real timezone which is GMT-5 . sudo timedatectl set-timezone America/Guayaquil","title":"Configuring Date and Time"},{"location":"setting-up/packages/","text":"Packages \u00b6 We'll install a handful of packages once we're done with the OS installation. Screen \u00b6 We'll also require screen which is a wonderful tool capable of improving multitasking on a single shell window with the ability to background processes. It also lets you recover shell windows when there's a connection loss. Installation \u00b6 Installing screen is as simple as running the following command: sudo apt-get install screen Configuration \u00b6 Create a ~/.screenrc file and add the following: termcapinfo xterm* ti@:te@ This enables the mouse wheel inside screen . Usage \u00b6 At first it may seem a little complicated and maybe even intimidating to use this tool but once you get used to it you'll realize how useful it really is. First start up screen by typing: screen -S <socket name> Here's a table with the keys and actions you can use with screen : Keys Action Ctrl-a c Creates a new window. Ctrl-a n Switches between windows. Ctrl-a d Detaches from screen. Ctrl-a n Switches between screens. To reattach to a screen : screen -r <screen pid> or, screen -rd <screen socket name> The Rest \u00b6 Install the rest of the packages with the following: sudo apt-get install net-tools neofetch nload progress","title":"Packages"},{"location":"setting-up/packages/#packages","text":"We'll install a handful of packages once we're done with the OS installation.","title":"Packages"},{"location":"setting-up/packages/#screen","text":"We'll also require screen which is a wonderful tool capable of improving multitasking on a single shell window with the ability to background processes. It also lets you recover shell windows when there's a connection loss.","title":"Screen"},{"location":"setting-up/packages/#installation","text":"Installing screen is as simple as running the following command: sudo apt-get install screen","title":"Installation"},{"location":"setting-up/packages/#configuration","text":"Create a ~/.screenrc file and add the following: termcapinfo xterm* ti@:te@ This enables the mouse wheel inside screen .","title":"Configuration"},{"location":"setting-up/packages/#usage","text":"At first it may seem a little complicated and maybe even intimidating to use this tool but once you get used to it you'll realize how useful it really is. First start up screen by typing: screen -S <socket name> Here's a table with the keys and actions you can use with screen : Keys Action Ctrl-a c Creates a new window. Ctrl-a n Switches between windows. Ctrl-a d Detaches from screen. Ctrl-a n Switches between screens. To reattach to a screen : screen -r <screen pid> or, screen -rd <screen socket name>","title":"Usage"},{"location":"setting-up/packages/#the-rest","text":"Install the rest of the packages with the following: sudo apt-get install net-tools neofetch nload progress","title":"The Rest"}]}